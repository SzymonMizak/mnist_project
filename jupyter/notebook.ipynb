{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e5afae",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a879b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48cf3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data and split into training-validation set and test set\n",
    "mnist = fetch_openml(\"mnist_784\", version = 1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.int8) # converting target to numbers instead of character\n",
    "X_prevalidsplit, X_test, y_prevalidsplit, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split set into training and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_prevalidsplit, y_prevalidsplit, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e171ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Xs\n",
    "scaler = StandardScaler()\n",
    "X_train_tr = scaler.fit_transform(X_train)\n",
    "X_valid_tr = scaler.transform(X_valid)\n",
    "X_test_tr = scaler.transform(X_test)\n",
    "\n",
    "# convert targets to one-hot vertors\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6a123",
   "metadata": {},
   "source": [
    "Define neural network model as object to use for hyperparameters tunning (N of hidden layers, N of neurons within layer, regularization, batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a272cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model generation function\n",
    "def nn_model(hidden_layers, dropout_rate, batch_norm):\n",
    "    # build model architecture\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=784)) # input layer\n",
    "    for l in hidden_layers:\n",
    "        model.add(tf.keras.layers.Dense(l, activation=\"relu\")) # hidden layers\n",
    "        if batch_norm == True:\n",
    "            model.add(tf.keras.layers.BatchNormalization) # optional batch normalization\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate)) # dropout layer\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\")) # output layer\n",
    "    return model\n",
    "\n",
    "# define callback to implement early stopping in training. Also saving checkpoint at best point in training\n",
    "stopping_callback = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# define wrapper object\n",
    "dnn_classifier = KerasClassifier(\n",
    "    model = nn_model, \n",
    "    loss=[\"categorical_crossentropy\"], \n",
    "    metrics=[\"accuracy\"],\n",
    "    optimizer=\"Adam\", \n",
    "    callbacks=[stopping_callback],\n",
    "    optimizer__learning_rate = 0.001, \n",
    "    model__hidden_layers = (512,), \n",
    "    model__dropout_rate = 0.2, \n",
    "    model__batch_norm = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3560751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters space for gridsearch\n",
    "nn_hyperparameters = {\n",
    "    \"optimizer__learning_rate\": [0.0001, 0.0003, 0.001, 0.003], \n",
    "    \"model__hidden_layers\": [(256,256),(256,256,256),(256,256,256,256), \n",
    "                             (512,512),(512,512,512),(512,512,512,512)],\n",
    "    \"model__dropout_rate\": [0, 0.2], \n",
    "    \"model__batch_norm\": [False, True]\n",
    "}\n",
    "\n",
    "# define GridSearchCv object \n",
    "grid_search_cv = GridSearchCV(dnn_classifier, nn_hyperparameters, cv = 3, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid search\n",
    "grid_search_cv.fit(\n",
    "    X_train_tr, \n",
    "    y_train,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_valid_tr, y_valid), \n",
    "    callbacks = [stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See best parameters\n",
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model with best parameters\n",
    "best_model = nn_model(hidden_layers=(512,512), dropout_rate=0.2, batch_norm=False)\n",
    "best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=[\"categorical_crossentropy\"], metrics=[\"accuracy\"])\n",
    "history = best_model.fit(    \n",
    "    X_train_tr, \n",
    "    y_train,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_valid_tr, y_valid), \n",
    "    callbacks = [stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fitted model to a file \n",
    "best_model.save(\"models/dnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c72b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if neccessary\n",
    "#tf.keras.models.load_model(\"models/dnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves for metric and loss\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "axes[0].plot(history.history[\"accuracy\"], color = \"orange\")\n",
    "axes[0].plot(history.history[\"val_accuracy\"])\n",
    "axes[1].plot(history.history[\"loss\"], color = \"orange\")\n",
    "axes[1].plot(history.history[\"val_loss\"])\n",
    "axes[0].set_title('Accuracy')\n",
    "axes[1].set_title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bd6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "predictions = best_model.predict(X_valid_tr)\n",
    "conf_matrix = tf.math.confusion_matrix(labels=tf.argmax(y_valid, axis=1), predictions=tf.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(conf_matrix, annot=True, linecolor=\"white\", linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "test_results = best_model.evaluate(X_test_tr, y_test, verbose=0)\n",
    "\n",
    "print(\"Testing accuracy of model is {} and loss is {}\".format(test_results[1], test_results[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
