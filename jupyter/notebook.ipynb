{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e5afae",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0a879b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48cf3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data and split into training-validation set and test set\n",
    "mnist = fetch_openml(\"mnist_784\", version = 1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.int8) # converting target to numbers instead of character\n",
    "X_prevalidsplit, X_test, y_prevalidsplit, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d4e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split set into training and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_prevalidsplit, y_prevalidsplit, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e171ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Xs\n",
    "scaler = StandardScaler()\n",
    "X_train_tr = scaler.fit_transform(X_train)\n",
    "X_valid_tr = scaler.transform(X_valid)\n",
    "X_test_tr = scaler.transform(X_test)\n",
    "\n",
    "# convert targets to one-hot vertors\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6a123",
   "metadata": {},
   "source": [
    "Define neural network model as object to use for hyperparameters tunning (N of hidden layers, N of neurons within layer, regularization, batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3a272cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model generation function\n",
    "def nn_model(hidden_layers, dropout_rate, batch_norm):\n",
    "    # build model architecture\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=784)) # input layer\n",
    "    for l in hidden_layers:\n",
    "        model.add(tf.keras.layers.Dense(l, activation=\"relu\")) # hidden layers\n",
    "        if batch_norm == True:\n",
    "            model.add(tf.keras.layers.BatchNormalization) # optional batch normalization\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate)) # dropout layer\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\")) # output layer\n",
    "    return model\n",
    "\n",
    "# define callback to implement early stopping in training. Also saving checkpoint at best point in training\n",
    "stopping_callback = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# define wrapper object\n",
    "dnn_classifier = KerasClassifier(\n",
    "    model = nn_model, \n",
    "    loss=[\"categorical_crossentropy\"], \n",
    "    metrics=[\"accuracy\"],\n",
    "    optimizer=\"Adam\", \n",
    "    callbacks=[stopping_callback],\n",
    "    optimizer__learning_rate = 0.001, \n",
    "    model__hidden_layers = (512,), \n",
    "    model__dropout_rate = 0.2, \n",
    "    model__batch_norm = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b3560751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters space for gridsearch\n",
    "nn_hyperparameters = {\n",
    "    \"optimizer__learning_rate\": [0.0001, 0.0003, 0.001, 0.003], \n",
    "    \"model__hidden_layers\": [(256,256),(256,256,256),(256,256,256,256), \n",
    "                             (512,512),(512,512,512),(512,512,512,512)],\n",
    "    \"model__dropout_rate\": [0, 0.2], \n",
    "    \"model__batch_norm\": [False, True]\n",
    "}\n",
    "\n",
    "# define GridSearchCv object \n",
    "grid_search_cv = GridSearchCV(dnn_classifier, nn_hyperparameters, cv = 3, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b26c8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 23:24:38.024286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-22 23:24:38.070465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-22 23:24:38.118177: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-22 23:24:38.120063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.5100 - accuracy: 0.8601 - val_loss: 0.2484 - val_accuracy: 0.9280\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.5199 - accuracy: 0.8574 - val_loss: 0.2523 - val_accuracy: 0.9302\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.5121 - accuracy: 0.8571 - val_loss: 0.2507 - val_accuracy: 0.9287\n",
      "   1/1000 [..............................] - ETA: 2s - loss: 0.0941 - accuracy: 1.0000Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.3217 - accuracy: 0.9064 - val_loss: 0.1928 - val_accuracy: 0.9488\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1894 - accuracy: 0.9442 - val_loss: 0.1877 - val_accuracy: 0.9459\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1909 - accuracy: 0.9448 - val_loss: 0.1944 - val_accuracy: 0.9454\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1886 - accuracy: 0.9453 - val_loss: 0.1894 - val_accuracy: 0.9478\n",
      "   1/1000 [..............................] - ETA: 3s - loss: 0.3924 - accuracy: 0.9062Epoch 3/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1175 - accuracy: 0.9652 - val_loss: 0.1533 - val_accuracy: 0.9575\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1280 - accuracy: 0.9631 - val_loss: 0.1574 - val_accuracy: 0.9551\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1320 - accuracy: 0.9617 - val_loss: 0.1661 - val_accuracy: 0.9554\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1293 - accuracy: 0.9638 - val_loss: 0.1661 - val_accuracy: 0.9538\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0710 - accuracy: 0.9794 - val_loss: 0.1470 - val_accuracy: 0.9620\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0940 - accuracy: 0.9729 - val_loss: 0.1462 - val_accuracy: 0.9584\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0972 - accuracy: 0.9737 - val_loss: 0.1553 - val_accuracy: 0.9572\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0956 - accuracy: 0.9736 - val_loss: 0.1552 - val_accuracy: 0.9573\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.1523 - val_accuracy: 0.9629\n",
      "Epoch 5/50\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0701 - accuracy: 0.9806 - val_loss: 0.1284 - val_accuracy: 0.9637\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0720 - accuracy: 0.9809 - val_loss: 0.1459 - val_accuracy: 0.9622\n",
      "  39/1000 [>.............................] - ETA: 2s - loss: 0.0495 - accuracy: 0.9864Epoch 6/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0738 - accuracy: 0.9794 - val_loss: 0.1467 - val_accuracy: 0.9585\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.1475 - val_accuracy: 0.9670\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0526 - accuracy: 0.9864 - val_loss: 0.1255 - val_accuracy: 0.9645\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0549 - accuracy: 0.9865 - val_loss: 0.1428 - val_accuracy: 0.9632\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0561 - accuracy: 0.9851 - val_loss: 0.1438 - val_accuracy: 0.9614\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.1664 - val_accuracy: 0.9653\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0394 - accuracy: 0.9898 - val_loss: 0.1271 - val_accuracy: 0.9651\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0417 - accuracy: 0.9895 - val_loss: 0.1438 - val_accuracy: 0.9652\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0433 - accuracy: 0.9892 - val_loss: 0.1390 - val_accuracy: 0.9639\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.1606 - val_accuracy: 0.9670\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0291 - accuracy: 0.9938 - val_loss: 0.1254 - val_accuracy: 0.9674\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.1454 - val_accuracy: 0.9634\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.1368 - val_accuracy: 0.9654\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.1626 - val_accuracy: 0.9673\n",
      "500/500 [==============================] - 3s 4ms/step loss: 0.0230 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.1278 - val_accuracy: 0.9672\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0231 - accuracy: 0.9959 - val_loss: 0.1462 - val_accuracy: 0.9669\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0244 - accuracy: 0.9951 - val_loss: 0.1385 - val_accuracy: 0.9658\n",
      "Epoch 10/50\n",
      " 245/1000 [======>.......................] - ETA: 4s - loss: 0.0143 - accuracy: 0.9983Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0159 - accuracy: 0.9976 - val_loss: 0.1282 - val_accuracy: 0.9705\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 0.1464 - val_accuracy: 0.9656\n",
      " 789/1000 [======================>.......] - ETA: 1s - loss: 0.3646 - accuracy: 0.8960Epoch 11/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.1430 - val_accuracy: 0.9665\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.3274 - accuracy: 0.9065 - val_loss: 0.1967 - val_accuracy: 0.9471\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0118 - accuracy: 0.9986 - val_loss: 0.1283 - val_accuracy: 0.9702\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 0.1488 - val_accuracy: 0.9662\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.1448 - val_accuracy: 0.9655\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0084 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1204 - accuracy: 0.9635 - val_loss: 0.1693 - val_accuracy: 0.9575\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 0.1350 - val_accuracy: 0.9696\n",
      "Epoch 13/50\n",
      " 590/1000 [================>.............] - ETA: 1s - loss: 0.0731 - accuracy: 0.9788Epoch 1/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.1462 - val_accuracy: 0.9681\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0720 - accuracy: 0.9787 - val_loss: 0.1471 - val_accuracy: 0.9631\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.1408 - val_accuracy: 0.9695\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.1616 - val_accuracy: 0.9660\n",
      "1000/1000 [==============================] - 7s 6ms/step - loss: 0.3226 - accuracy: 0.9064 - val_loss: 0.1808 - val_accuracy: 0.9473\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 1s 3ms/step loss: 0.0325 - accuracy: 1.00\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.1153 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.1443 - val_accuracy: 0.9660\n",
      "Epoch 5/50\n",
      " 626/1000 [=================>............] - ETA: 1s - loss: 0.1272 - accuracy: 0.9639Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 758/1000 [=====================>........] - ETA: 0s - loss: 0.1238 - accuracy: 0.9645Epoch 1/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1214 - accuracy: 0.9647 - val_loss: 0.1494 - val_accuracy: 0.9592\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.1568 - val_accuracy: 0.9656\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 6ms/step - loss: 0.2702 - accuracy: 0.9217 - val_loss: 0.1624 - val_accuracy: 0.9527\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 6ms/step - loss: 0.2746 - accuracy: 0.9215 - val_loss: 0.2086 - val_accuracy: 0.9454\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0748 - accuracy: 0.9781 - val_loss: 0.1424 - val_accuracy: 0.9635\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.1539 - val_accuracy: 0.9697\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1138 - accuracy: 0.9663 - val_loss: 0.1544 - val_accuracy: 0.9567\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1122 - accuracy: 0.9648 - val_loss: 0.1760 - val_accuracy: 0.9586\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0479 - accuracy: 0.9863 - val_loss: 0.1470 - val_accuracy: 0.9640\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1705 - val_accuracy: 0.9670\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0777 - accuracy: 0.9768 - val_loss: 0.2021 - val_accuracy: 0.9584\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0767 - accuracy: 0.9766 - val_loss: 0.1791 - val_accuracy: 0.9647\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 0.1402 - val_accuracy: 0.9647\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.1826 - val_accuracy: 0.9672\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0600 - accuracy: 0.9813 - val_loss: 0.1740 - val_accuracy: 0.9626\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0542 - accuracy: 0.9831 - val_loss: 0.1846 - val_accuracy: 0.9634\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.1557 - val_accuracy: 0.9665\n",
      " 120/1000 [==>...........................] - ETA: 3s - loss: 0.0290 - accuracy: 0.9901Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.1893 - val_accuracy: 0.9685\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0163 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.1761 - val_accuracy: 0.9642\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.1648 - val_accuracy: 0.9679\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.2044 - val_accuracy: 0.9578\n",
      "Epoch 8/50\n",
      " 226/1000 [=====>........................] - ETA: 4s - loss: 0.0356 - accuracy: 0.9894Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0615 - accuracy: 0.9836 - val_loss: 0.1794 - val_accuracy: 0.9634\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0371 - accuracy: 0.9881 - val_loss: 0.1857 - val_accuracy: 0.9660\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.1730 - val_accuracy: 0.9649\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 6ms/step - loss: 0.2646 - accuracy: 0.9231 - val_loss: 0.1841 - val_accuracy: 0.9479\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.1986 - val_accuracy: 0.9638\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0418 - accuracy: 0.9883 - val_loss: 0.2241 - val_accuracy: 0.9642\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.1620 - val_accuracy: 0.9687\n",
      " 131/1000 [==>...........................] - ETA: 3s - loss: 0.0195 - accuracy: 0.9936Epoch 10/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0192 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1079 - accuracy: 0.9678 - val_loss: 0.1676 - val_accuracy: 0.9582\n",
      "Epoch 3/50\n",
      " 853/1000 [========================>.....] - ETA: 0s - loss: 0.0100 - accuracy: 0.9971Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.2050 - val_accuracy: 0.9663\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.1967 - val_accuracy: 0.9643\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.3585 - accuracy: 0.90\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0785 - accuracy: 0.9758 - val_loss: 0.1547 - val_accuracy: 0.9613\n",
      " 661/1000 [==================>...........] - ETA: 1s - loss: 0.0287 - accuracy: 0.9919Epoch 4/50\n",
      " 460/1000 [============>.................] - ETA: 2s - loss: 0.0396 - accuracy: 0.9870Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0340 - accuracy: 0.9904 - val_loss: 0.2386 - val_accuracy: 0.9662\n",
      "1000/1000 [==============================] - 7s 6ms/step - loss: 0.3184 - accuracy: 0.9140 - val_loss: 0.2084 - val_accuracy: 0.9408\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1735 - accuracy: 0.94\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0598 - accuracy: 0.9816 - val_loss: 0.1699 - val_accuracy: 0.9601\n",
      "Epoch 5/50\n",
      " 683/1000 [===================>..........] - ETA: 2s - loss: 0.0486 - accuracy: 0.9853Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1823 - accuracy: 0.9499 - val_loss: 0.2393 - val_accuracy: 0.9385\n",
      " 698/1000 [===================>..........] - ETA: 2s - loss: 0.0491 - accuracy: 0.9853Epoch 3/50\n",
      "1000/1000 [==============================] - 11s 10ms/step - loss: 0.3277 - accuracy: 0.9129 - val_loss: 0.2224 - val_accuracy: 0.9357\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0504 - accuracy: 0.9845 - val_loss: 0.2483 - val_accuracy: 0.9553\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1666 - accuracy: 0.9569 - val_loss: 0.2228 - val_accuracy: 0.9417\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1985 - accuracy: 0.9466 - val_loss: 0.2023 - val_accuracy: 0.9451\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.3393 - accuracy: 0.9107 - val_loss: 0.2029 - val_accuracy: 0.9463\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 0.1810 - val_accuracy: 0.9628\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1392 - accuracy: 0.9642 - val_loss: 0.2054 - val_accuracy: 0.9517\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1910 - accuracy: 0.9478 - val_loss: 0.2554 - val_accuracy: 0.9398\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1609 - accuracy: 0.9564 - val_loss: 0.2073 - val_accuracy: 0.9487\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 0.1823 - val_accuracy: 0.9663\n",
      " 623/1000 [=================>............] - ETA: 1s - loss: 0.1310 - accuracy: 0.9662Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1318 - accuracy: 0.9660 - val_loss: 0.2214 - val_accuracy: 0.9553\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1412 - accuracy: 0.9616 - val_loss: 0.2126 - val_accuracy: 0.9484\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1715 - accuracy: 0.9564 - val_loss: 0.2041 - val_accuracy: 0.9532\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.1952 - val_accuracy: 0.9676\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.1287 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1234 - accuracy: 0.9688 - val_loss: 0.2158 - val_accuracy: 0.9571\n",
      "Epoch 7/50\n",
      " 532/1000 [==============>...............] - ETA: 1s - loss: 0.0850 - accuracy: 0.9773Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1214 - accuracy: 0.9687 - val_loss: 0.2441 - val_accuracy: 0.9545\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1346 - accuracy: 0.9637 - val_loss: 0.2189 - val_accuracy: 0.9473\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1003 - accuracy: 0.9745 - val_loss: 0.2592 - val_accuracy: 0.9556\n",
      " 374/1000 [==========>...................] - ETA: 3s - loss: 0.8392 - accuracy: 0.7709Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1211 - accuracy: 0.9705 - val_loss: 0.2269 - val_accuracy: 0.9559\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1258 - accuracy: 0.9663 - val_loss: 0.2068 - val_accuracy: 0.9525\n",
      " 579/1000 [================>.............] - ETA: 2s - loss: 0.0811 - accuracy: 0.9789Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 8ms/step - loss: 0.4891 - accuracy: 0.8636 - val_loss: 0.2353 - val_accuracy: 0.9342\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1016 - accuracy: 0.9755 - val_loss: 0.3674 - val_accuracy: 0.9419\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1127 - accuracy: 0.9715 - val_loss: 0.2867 - val_accuracy: 0.9500\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1228 - accuracy: 0.9722 - val_loss: 0.2548 - val_accuracy: 0.9525\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1737 - accuracy: 0.9478 - val_loss: 0.1833 - val_accuracy: 0.9502\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1030 - accuracy: 0.9764 - val_loss: 0.3588 - val_accuracy: 0.9507\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.1171 - accuracy: 0.96\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.1167 - accuracy: 0.96\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.1160 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1135 - accuracy: 0.9660 - val_loss: 0.1660 - val_accuracy: 0.9539\n",
      "Epoch 4/50\n",
      " 360/1000 [=========>....................] - ETA: 2s - loss: 0.0844 - accuracy: 0.9757Epoch 1/50\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0808 - accuracy: 0.9766 - val_loss: 0.1567 - val_accuracy: 0.9576\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.3170 - accuracy: 0.9092 - val_loss: 0.1940 - val_accuracy: 0.9518\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.4956 - accuracy: 0.8647 - val_loss: 0.2376 - val_accuracy: 0.9346\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.5011 - accuracy: 0.8609 - val_loss: 0.2377 - val_accuracy: 0.9321\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0574 - accuracy: 0.9837 - val_loss: 0.1523 - val_accuracy: 0.9606\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1110 - accuracy: 0.9666 - val_loss: 0.1630 - val_accuracy: 0.9559\n",
      " 621/1000 [=================>............] - ETA: 2s - loss: 0.0399 - accuracy: 0.9898Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1750 - accuracy: 0.9487 - val_loss: 0.1840 - val_accuracy: 0.9499\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1702 - accuracy: 0.9485 - val_loss: 0.1900 - val_accuracy: 0.9492\n",
      "  26/1000 [..............................] - ETA: 6s - loss: 0.1293 - accuracy: 0.9603Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0414 - accuracy: 0.9892 - val_loss: 0.1531 - val_accuracy: 0.9633\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0653 - accuracy: 0.9802 - val_loss: 0.1559 - val_accuracy: 0.9609\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1169 - accuracy: 0.9663 - val_loss: 0.1701 - val_accuracy: 0.9552\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1104 - accuracy: 0.9679 - val_loss: 0.1580 - val_accuracy: 0.9557\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0282 - accuracy: 0.9934 - val_loss: 0.1536 - val_accuracy: 0.9647\n",
      " 655/1000 [==================>...........] - ETA: 2s - loss: 0.0782 - accuracy: 0.9781Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 0.1594 - val_accuracy: 0.9623\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 9ms/step - loss: 0.0815 - accuracy: 0.9772 - val_loss: 0.1548 - val_accuracy: 0.9588\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0764 - accuracy: 0.9778 - val_loss: 0.1545 - val_accuracy: 0.9582\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 0.1591 - val_accuracy: 0.9648\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.1710 - val_accuracy: 0.9644\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0574 - accuracy: 0.9846 - val_loss: 0.1557 - val_accuracy: 0.9604\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0542 - accuracy: 0.9852 - val_loss: 0.1528 - val_accuracy: 0.9603\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.1628 - val_accuracy: 0.9653\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.1828 - val_accuracy: 0.9603\n",
      " 508/1000 [==============>...............] - ETA: 2s - loss: 0.0125 - accuracy: 0.9977Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 0.1583 - val_accuracy: 0.9626\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0384 - accuracy: 0.9897 - val_loss: 0.1604 - val_accuracy: 0.9601\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.1711 - val_accuracy: 0.9662\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0260 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.1681 - val_accuracy: 0.9660\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0290 - accuracy: 0.9931 - val_loss: 0.1557 - val_accuracy: 0.9643\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 0.1587 - val_accuracy: 0.9627\n",
      "Epoch 8/50\n",
      " 321/1000 [========>.....................] - ETA: 3s - loss: 0.0183 - accuracy: 0.9964Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.1915 - val_accuracy: 0.9628\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0192 - accuracy: 0.9959 - val_loss: 0.1665 - val_accuracy: 0.9639\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 0.1682 - val_accuracy: 0.9627\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0105 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.3218 - accuracy: 0.9046 - val_loss: 0.1884 - val_accuracy: 0.9511\n",
      "Epoch 2/50\n",
      " 520/1000 [==============>...............] - ETA: 2s - loss: 0.0110 - accuracy: 0.9981Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.1764 - val_accuracy: 0.9642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.1749 - val_accuracy: 0.9624\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0087 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1134 - accuracy: 0.9660 - val_loss: 0.1538 - val_accuracy: 0.9599\n",
      "Epoch 3/50\n",
      " 128/1000 [==>...........................] - ETA: 4s - loss: 0.0632 - accuracy: 0.9817Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.3186 - accuracy: 0.9093 - val_loss: 0.1661 - val_accuracy: 0.9514\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.1834 - val_accuracy: 0.9632\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.1135 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0661 - accuracy: 0.9791 - val_loss: 0.1547 - val_accuracy: 0.9621\n",
      " 774/1000 [======================>.......] - ETA: 1s - loss: 0.1124 - accuracy: 0.9671Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1123 - accuracy: 0.9664 - val_loss: 0.1452 - val_accuracy: 0.9576\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 6ms/step - loss: 0.2793 - accuracy: 0.9171 - val_loss: 0.1823 - val_accuracy: 0.9496\n",
      "Epoch 2/50\n",
      " 612/1000 [=================>............] - ETA: 1s - loss: 0.0346 - accuracy: 0.9894Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0411 - accuracy: 0.9873 - val_loss: 0.1569 - val_accuracy: 0.9618\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0669 - accuracy: 0.9803 - val_loss: 0.1343 - val_accuracy: 0.9619\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1258 - accuracy: 0.9622 - val_loss: 0.1746 - val_accuracy: 0.9536\n",
      " 934/1000 [===========================>..] - ETA: 0s - loss: 0.2818 - accuracy: 0.9168Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.2748 - accuracy: 0.9186 - val_loss: 0.1738 - val_accuracy: 0.9521\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.1804 - val_accuracy: 0.9622\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0430 - accuracy: 0.9871 - val_loss: 0.1526 - val_accuracy: 0.9615\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0815 - accuracy: 0.9743 - val_loss: 0.1752 - val_accuracy: 0.9568\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1175 - accuracy: 0.9641 - val_loss: 0.1562 - val_accuracy: 0.9574\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.1838 - val_accuracy: 0.9630\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.1528 - val_accuracy: 0.9614\n",
      " 697/1000 [===================>..........] - ETA: 1s - loss: 0.0818 - accuracy: 0.9741Epoch 6/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0664 - accuracy: 0.9791 - val_loss: 0.2042 - val_accuracy: 0.9571\n",
      " 713/1000 [====================>.........] - ETA: 1s - loss: 0.0202 - accuracy: 0.9943Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0900 - accuracy: 0.9727 - val_loss: 0.1533 - val_accuracy: 0.9595\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.1946 - val_accuracy: 0.9640\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.1661 - val_accuracy: 0.9627\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0661 - accuracy: 0.97\n",
      " 478/1000 [=============>................] - ETA: 2s - loss: 0.0209 - accuracy: 0.9937Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0596 - accuracy: 0.9818 - val_loss: 0.1991 - val_accuracy: 0.9641\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0671 - accuracy: 0.9790 - val_loss: 0.1478 - val_accuracy: 0.9658\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 0.1521 - val_accuracy: 0.9670\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0450 - accuracy: 0.9870 - val_loss: 0.1839 - val_accuracy: 0.9659\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0563 - accuracy: 0.9827 - val_loss: 0.1350 - val_accuracy: 0.9682\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.2779 - accuracy: 0.9190 - val_loss: 0.1834 - val_accuracy: 0.9463\n",
      " 851/1000 [========================>.....] - ETA: 0s - loss: 0.0161 - accuracy: 0.9955Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 0.1675 - val_accuracy: 0.9657\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1229 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0505 - accuracy: 0.9853 - val_loss: 0.1960 - val_accuracy: 0.9646\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.1713 - val_accuracy: 0.9614\n",
      "Epoch 7/50\n",
      " 316/1000 [========>.....................] - ETA: 2s - loss: 0.0374 - accuracy: 0.9890Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1221 - accuracy: 0.9639 - val_loss: 0.1479 - val_accuracy: 0.9600\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0352 - accuracy: 0.98\n",
      " 255/1000 [======>.......................] - ETA: 4s - loss: 0.4899 - accuracy: 0.8627Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0406 - accuracy: 0.9877 - val_loss: 0.1682 - val_accuracy: 0.9656\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0908 - accuracy: 0.9722 - val_loss: 0.1592 - val_accuracy: 0.9592\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.3527 - accuracy: 0.9087 - val_loss: 0.2665 - val_accuracy: 0.9325\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 8ms/step - loss: 0.3683 - accuracy: 0.9041 - val_loss: 0.3057 - val_accuracy: 0.9262\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.1871 - val_accuracy: 0.9640\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0811 - accuracy: 0.9775 - val_loss: 0.1359 - val_accuracy: 0.9643\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.2124 - accuracy: 0.9458 - val_loss: 0.2235 - val_accuracy: 0.9437\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2138 - accuracy: 0.9457 - val_loss: 0.1740 - val_accuracy: 0.9556\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.1770 - val_accuracy: 0.9679\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0565 - accuracy: 0.9825 - val_loss: 0.1655 - val_accuracy: 0.9617\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1734 - accuracy: 0.9535 - val_loss: 0.2536 - val_accuracy: 0.9455\n",
      " 750/1000 [=====================>........] - ETA: 1s - loss: 0.0327 - accuracy: 0.9912Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0332 - accuracy: 0.9908 - val_loss: 0.2311 - val_accuracy: 0.9639\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1689 - accuracy: 0.9567 - val_loss: 0.2457 - val_accuracy: 0.9492\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0501 - accuracy: 0.9847 - val_loss: 0.1617 - val_accuracy: 0.9643\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1289 - accuracy: 0.96\n",
      " 587/1000 [================>.............] - ETA: 2s - loss: 0.0339 - accuracy: 0.9906Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1605 - accuracy: 0.9620 - val_loss: 0.2018 - val_accuracy: 0.9576\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1400 - accuracy: 0.9638 - val_loss: 0.2289 - val_accuracy: 0.9470\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0393 - accuracy: 0.9893 - val_loss: 0.1426 - val_accuracy: 0.9656\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1339 - accuracy: 0.9671 - val_loss: 0.2576 - val_accuracy: 0.9503\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1279 - accuracy: 0.9669 - val_loss: 0.2475 - val_accuracy: 0.9504\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 9ms/step - loss: 0.3692 - accuracy: 0.9036 - val_loss: 0.2563 - val_accuracy: 0.9352\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.1562 - val_accuracy: 0.9683\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1178 - accuracy: 0.9700 - val_loss: 0.3050 - val_accuracy: 0.9496\n",
      " 588/1000 [================>.............] - ETA: 2s - loss: 0.0323 - accuracy: 0.9903Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1069 - accuracy: 0.9728 - val_loss: 0.2369 - val_accuracy: 0.9559\n",
      " 326/1000 [========>.....................] - ETA: 3s - loss: 0.1059 - accuracy: 0.9751Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2029 - accuracy: 0.9462 - val_loss: 0.2829 - val_accuracy: 0.9293\n",
      "  39/1000 [>.............................] - ETA: 5s - loss: 0.1178 - accuracy: 0.9720Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0371 - accuracy: 0.9898 - val_loss: 0.2244 - val_accuracy: 0.9679\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1730 - accuracy: 0.95\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1032 - accuracy: 0.9742 - val_loss: 0.2378 - val_accuracy: 0.9576\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1021 - accuracy: 0.9749 - val_loss: 0.2635 - val_accuracy: 0.9564\n",
      " 365/1000 [=========>....................] - ETA: 3s - loss: 0.0755 - accuracy: 0.9798Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1705 - accuracy: 0.9559 - val_loss: 0.1998 - val_accuracy: 0.9510\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1253 - accuracy: 0.96\n",
      " 805/1000 [=======================>......] - ETA: 1s - loss: 0.1374 - accuracy: 0.9627Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0991 - accuracy: 0.9760 - val_loss: 0.3190 - val_accuracy: 0.9570\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1392 - accuracy: 0.9623 - val_loss: 0.2325 - val_accuracy: 0.9485\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 11s 9ms/step - loss: 0.4787 - accuracy: 0.8667 - val_loss: 0.2201 - val_accuracy: 0.9366\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0848 - accuracy: 0.9798 - val_loss: 0.2253 - val_accuracy: 0.9595\n",
      "1000/1000 [==============================] - 10s 8ms/step - loss: 0.4775 - accuracy: 0.8656 - val_loss: 0.2307 - val_accuracy: 0.9363\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1455 - accuracy: 0.9639 - val_loss: 0.2340 - val_accuracy: 0.9552\n",
      "  44/1000 [>.............................] - ETA: 5s - loss: 0.1667 - accuracy: 0.9531Epoch 6/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1642 - accuracy: 0.95\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1624 - accuracy: 0.9522 - val_loss: 0.1781 - val_accuracy: 0.9487\n",
      "Epoch 3/50\n",
      "  11/1000 [..............................] - ETA: 5s - loss: 0.1068 - accuracy: 0.9773Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1180 - accuracy: 0.9714 - val_loss: 0.2415 - val_accuracy: 0.9556\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1603 - accuracy: 0.9517 - val_loss: 0.1814 - val_accuracy: 0.9506\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1016 - accuracy: 0.9708 - val_loss: 0.1603 - val_accuracy: 0.9544\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1189 - accuracy: 0.9728 - val_loss: 0.2097 - val_accuracy: 0.9559\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 13s 11ms/step - loss: 0.4754 - accuracy: 0.8683 - val_loss: 0.2214 - val_accuracy: 0.9370\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1017 - accuracy: 0.9698 - val_loss: 0.1634 - val_accuracy: 0.9572\n",
      " 188/1000 [====>.........................] - ETA: 5s - loss: 0.0934 - accuracy: 0.9757Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0684 - accuracy: 0.9803 - val_loss: 0.1643 - val_accuracy: 0.9566\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0903 - accuracy: 0.9764 - val_loss: 0.2017 - val_accuracy: 0.9600\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1612 - accuracy: 0.9533 - val_loss: 0.1693 - val_accuracy: 0.9523\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0689 - accuracy: 0.9799 - val_loss: 0.1604 - val_accuracy: 0.9588\n",
      " 660/1000 [==================>...........] - ETA: 2s - loss: 0.0454 - accuracy: 0.9878Epoch 5/50\n",
      "500/500 [==============================] - 4s 8ms/step loss: 0.0471 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0470 - accuracy: 0.9868 - val_loss: 0.1569 - val_accuracy: 0.9625\n",
      "Epoch 6/50\n",
      " 902/1000 [==========================>...] - ETA: 0s - loss: 0.0475 - accuracy: 0.9860Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1022 - accuracy: 0.9701 - val_loss: 0.1568 - val_accuracy: 0.9540\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0480 - accuracy: 0.9861 - val_loss: 0.1619 - val_accuracy: 0.9616\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0328 - accuracy: 0.9910 - val_loss: 0.1681 - val_accuracy: 0.9629\n",
      " 853/1000 [========================>.....] - ETA: 1s - loss: 0.0690 - accuracy: 0.9808Epoch 7/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0696 - accuracy: 0.9803 - val_loss: 0.1569 - val_accuracy: 0.9595\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0319 - accuracy: 0.9908 - val_loss: 0.1665 - val_accuracy: 0.9620\n",
      " 585/1000 [================>.............] - ETA: 3s - loss: 0.0191 - accuracy: 0.9954Epoch 7/50\n",
      "1000/1000 [==============================] - 14s 12ms/step - loss: 0.3342 - accuracy: 0.9016 - val_loss: 0.1831 - val_accuracy: 0.9496\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.1724 - val_accuracy: 0.9630\n",
      " 889/1000 [=========================>....] - ETA: 0s - loss: 0.0460 - accuracy: 0.9871Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.1608 - val_accuracy: 0.9582\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.1722 - val_accuracy: 0.9628\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1140 - accuracy: 0.9654 - val_loss: 0.1791 - val_accuracy: 0.9542\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.1807 - val_accuracy: 0.9638\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0318 - accuracy: 0.9914 - val_loss: 0.1525 - val_accuracy: 0.9631\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.1831 - val_accuracy: 0.9624\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0703 - accuracy: 0.9777 - val_loss: 0.1514 - val_accuracy: 0.9631\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 0.1870 - val_accuracy: 0.9639\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.1749 - val_accuracy: 0.9594\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.1932 - val_accuracy: 0.9620\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0485 - accuracy: 0.9850 - val_loss: 0.1621 - val_accuracy: 0.9611\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0134 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.1947 - val_accuracy: 0.9647\n",
      " 740/1000 [=====================>........] - ETA: 1s - loss: 0.0336 - accuracy: 0.9897Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.1738 - val_accuracy: 0.9631\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 1.4310 - accuracy: 0.627\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.1745 - val_accuracy: 0.9631\n",
      "Epoch 6/50\n",
      " 597/1000 [================>.............] - ETA: 2s - loss: 0.0104 - accuracy: 0.9974Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.1899 - val_accuracy: 0.9611\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 10s 9ms/step - loss: 0.3204 - accuracy: 0.9080 - val_loss: 0.1634 - val_accuracy: 0.9503\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.1662 - val_accuracy: 0.9663\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 10ms/step - loss: 0.3300 - accuracy: 0.9038 - val_loss: 0.1843 - val_accuracy: 0.9496\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.2205 - val_accuracy: 0.9593\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1117 - accuracy: 0.9663 - val_loss: 0.1414 - val_accuracy: 0.9598\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.1934 - val_accuracy: 0.9636\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1170 - accuracy: 0.9644 - val_loss: 0.1562 - val_accuracy: 0.9583\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.1968 - val_accuracy: 0.9647\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0707 - accuracy: 0.9776 - val_loss: 0.1354 - val_accuracy: 0.9619\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.1843 - val_accuracy: 0.9653\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0691 - accuracy: 0.97\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0702 - accuracy: 0.97\n",
      " 568/1000 [================>.............] - ETA: 2s - loss: 0.0421 - accuracy: 0.9872Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0703 - accuracy: 0.9782 - val_loss: 0.1472 - val_accuracy: 0.9636\n",
      "Epoch 4/50\n",
      " 101/1000 [==>...........................] - ETA: 5s - loss: 0.0410 - accuracy: 0.9879Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0476 - accuracy: 0.9844 - val_loss: 0.1425 - val_accuracy: 0.9640\n",
      " 464/1000 [============>.................] - ETA: 3s - loss: 0.0389 - accuracy: 0.9881Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.1513 - val_accuracy: 0.9647\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 11s 9ms/step - loss: 0.2859 - accuracy: 0.9147 - val_loss: 0.2021 - val_accuracy: 0.9427\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.1568 - val_accuracy: 0.9610\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 10ms/step - loss: 0.2854 - accuracy: 0.9153 - val_loss: 0.1755 - val_accuracy: 0.9506\n",
      " 379/1000 [==========>...................] - ETA: 3s - loss: 0.1297 - accuracy: 0.9610Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.1831 - val_accuracy: 0.9617\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1326 - accuracy: 0.9611 - val_loss: 0.1848 - val_accuracy: 0.9522\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 0.1622 - val_accuracy: 0.9640\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1335 - accuracy: 0.9606 - val_loss: 0.1740 - val_accuracy: 0.9541\n",
      "  42/1000 [>.............................] - ETA: 4s - loss: 0.0281 - accuracy: 0.9888Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0945 - accuracy: 0.9714 - val_loss: 0.1665 - val_accuracy: 0.9580\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0291 - accuracy: 0.9907 - val_loss: 0.2030 - val_accuracy: 0.9605\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.2007 - val_accuracy: 0.9613\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0990 - accuracy: 0.9703 - val_loss: 0.1682 - val_accuracy: 0.9581\n",
      " 401/1000 [===========>..................] - ETA: 4s - loss: 0.0860 - accuracy: 0.9764Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0828 - accuracy: 0.9768 - val_loss: 0.1746 - val_accuracy: 0.9581\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.1691 - val_accuracy: 0.9656\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 0.2178 - val_accuracy: 0.9591\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0783 - accuracy: 0.9775 - val_loss: 0.1562 - val_accuracy: 0.9636\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0656 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0656 - accuracy: 0.9797 - val_loss: 0.1627 - val_accuracy: 0.9615\n",
      "Epoch 6/50\n",
      "  79/1000 [=>............................] - ETA: 5s - loss: 0.0246 - accuracy: 0.9933Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.1814 - val_accuracy: 0.9657\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.5074 - accuracy: 0.83\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0634 - accuracy: 0.9807 - val_loss: 0.1509 - val_accuracy: 0.9643\n",
      "Epoch 6/50\n",
      " 659/1000 [==================>...........] - ETA: 2s - loss: 0.3329 - accuracy: 0.8979Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 0.1650 - val_accuracy: 0.9619\n",
      " 917/1000 [==========================>...] - ETA: 0s - loss: 0.3015 - accuracy: 0.9082Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 10ms/step - loss: 0.2910 - accuracy: 0.9118 - val_loss: 0.1918 - val_accuracy: 0.9470\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0526 - accuracy: 0.9847 - val_loss: 0.1723 - val_accuracy: 0.9621\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0503 - accuracy: 0.9852 - val_loss: 0.1774 - val_accuracy: 0.9673\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 14s 12ms/step - loss: 0.3613 - accuracy: 0.9017 - val_loss: 0.2615 - val_accuracy: 0.9376\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1357 - accuracy: 0.9609 - val_loss: 0.1951 - val_accuracy: 0.9460\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 0.1724 - val_accuracy: 0.9658\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0480 - accuracy: 0.9872 - val_loss: 0.1756 - val_accuracy: 0.9659\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2236 - accuracy: 0.9432 - val_loss: 0.2468 - val_accuracy: 0.9464\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0995 - accuracy: 0.9702 - val_loss: 0.1808 - val_accuracy: 0.9507\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.1841 - val_accuracy: 0.9653\n",
      "  70/1000 [=>............................] - ETA: 6s - loss: 0.0843 - accuracy: 0.9754Epoch 9/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 0.1720 - val_accuracy: 0.9653\n",
      " 595/1000 [================>.............] - ETA: 2s - loss: 0.0452 - accuracy: 0.9870Epoch 10/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1915 - accuracy: 0.9531 - val_loss: 0.2518 - val_accuracy: 0.9460\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0770 - accuracy: 0.9765 - val_loss: 0.1540 - val_accuracy: 0.9608\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0441 - accuracy: 0.9876 - val_loss: 0.2193 - val_accuracy: 0.9601\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.2263 - val_accuracy: 0.9641\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1635 - accuracy: 0.9579 - val_loss: 0.2127 - val_accuracy: 0.9538\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0637 - accuracy: 0.9808 - val_loss: 0.1582 - val_accuracy: 0.9615\n",
      " 372/1000 [==========>...................] - ETA: 4s - loss: 0.1389 - accuracy: 0.9682Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0389 - accuracy: 0.9905 - val_loss: 0.1884 - val_accuracy: 0.9654\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0363 - accuracy: 0.98\n",
      " 862/1000 [========================>.....] - ETA: 0s - loss: 0.1489 - accuracy: 0.9646Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step loss: 0.1506 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1509 - accuracy: 0.9646 - val_loss: 0.1963 - val_accuracy: 0.9495\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.1660 - val_accuracy: 0.9604\n",
      "Epoch 7/50\n",
      " 184/1000 [====>.........................] - ETA: 4s - loss: 0.0356 - accuracy: 0.9898Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 7ms/step - loss: 0.3639 - accuracy: 0.9008 - val_loss: 0.2567 - val_accuracy: 0.9338\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1280 - accuracy: 0.9687 - val_loss: 0.2957 - val_accuracy: 0.9388\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0487 - accuracy: 0.9861 - val_loss: 0.1705 - val_accuracy: 0.9654\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 11s 9ms/step - loss: 0.3643 - accuracy: 0.9009 - val_loss: 0.2317 - val_accuracy: 0.9371\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.2292 - accuracy: 0.9412 - val_loss: 0.2054 - val_accuracy: 0.9517\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1200 - accuracy: 0.9703 - val_loss: 0.2716 - val_accuracy: 0.9542\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0419 - accuracy: 0.9890 - val_loss: 0.2009 - val_accuracy: 0.9634\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2164 - accuracy: 0.9434 - val_loss: 0.2343 - val_accuracy: 0.9457\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1950 - accuracy: 0.9529 - val_loss: 0.2446 - val_accuracy: 0.9489\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1187 - accuracy: 0.9722 - val_loss: 0.2502 - val_accuracy: 0.9573\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0411 - accuracy: 0.9887 - val_loss: 0.1826 - val_accuracy: 0.9653\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1050 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1795 - accuracy: 0.9552 - val_loss: 0.2260 - val_accuracy: 0.9422\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1576 - accuracy: 0.9619 - val_loss: 0.2408 - val_accuracy: 0.9536\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1049 - accuracy: 0.9761 - val_loss: 0.2661 - val_accuracy: 0.9502\n",
      "Epoch 10/50\n",
      " 215/1000 [=====>........................] - ETA: 4s - loss: 0.1006 - accuracy: 0.9730Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1802 - accuracy: 0.9574 - val_loss: 0.2501 - val_accuracy: 0.9439\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1569 - accuracy: 0.9623 - val_loss: 0.2295 - val_accuracy: 0.9538\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1040 - accuracy: 0.9765 - val_loss: 0.2499 - val_accuracy: 0.9581\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1171 - accuracy: 0.97\n",
      " 726/1000 [====================>.........] - ETA: 1s - loss: 0.4725 - accuracy: 0.8688Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1287 - accuracy: 0.9702 - val_loss: 0.3280 - val_accuracy: 0.9477\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1561 - accuracy: 0.9623 - val_loss: 0.2162 - val_accuracy: 0.9572\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 16s 8ms/step - loss: 0.4069 - accuracy: 0.8854 - val_loss: 0.2215 - val_accuracy: 0.9413\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1116 - accuracy: 0.9728 - val_loss: 0.2587 - val_accuracy: 0.9571\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1397 - accuracy: 0.9678 - val_loss: 0.3353 - val_accuracy: 0.9385\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1501 - accuracy: 0.9556 - val_loss: 0.1755 - val_accuracy: 0.9538\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.1000 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 17s 12ms/step - loss: 0.4043 - accuracy: 0.8892 - val_loss: 0.2306 - val_accuracy: 0.9396\n",
      "Epoch 2/50\n",
      " 739/1000 [=====================>........] - ETA: 2s - loss: 0.1546 - accuracy: 0.9645Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1436 - accuracy: 0.9662 - val_loss: 0.1810 - val_accuracy: 0.9601\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0961 - accuracy: 0.9723 - val_loss: 0.1534 - val_accuracy: 0.9609\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1506 - accuracy: 0.9560 - val_loss: 0.1847 - val_accuracy: 0.9526\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1059 - accuracy: 0.9742 - val_loss: 0.2315 - val_accuracy: 0.9488\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0645 - accuracy: 0.9824 - val_loss: 0.1484 - val_accuracy: 0.9643\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 10ms/step - loss: 0.3946 - accuracy: 0.8922 - val_loss: 0.2068 - val_accuracy: 0.9419\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0946 - accuracy: 0.9727 - val_loss: 0.1599 - val_accuracy: 0.9595\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1015 - accuracy: 0.9758 - val_loss: 0.1959 - val_accuracy: 0.9627\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0450 - accuracy: 0.9889 - val_loss: 0.1425 - val_accuracy: 0.9653\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1498 - accuracy: 0.9575 - val_loss: 0.1665 - val_accuracy: 0.9549\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0641 - accuracy: 0.9822 - val_loss: 0.1577 - val_accuracy: 0.9606\n",
      " 435/1000 [============>.................] - ETA: 5s - loss: 0.0274 - accuracy: 0.9939Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0916 - accuracy: 0.9788 - val_loss: 0.3379 - val_accuracy: 0.9477\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0308 - accuracy: 0.9927 - val_loss: 0.1418 - val_accuracy: 0.9665\n",
      " 405/1000 [===========>..................] - ETA: 3s - loss: 0.0981 - accuracy: 0.9770Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0942 - accuracy: 0.9729 - val_loss: 0.1435 - val_accuracy: 0.9582\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0437 - accuracy: 0.9887 - val_loss: 0.1517 - val_accuracy: 0.9654\n",
      " 373/1000 [==========>...................] - ETA: 4s - loss: 0.0649 - accuracy: 0.9830Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1014 - accuracy: 0.9762 - val_loss: 0.2118 - val_accuracy: 0.9583\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0214 - accuracy: 0.9963 - val_loss: 0.1469 - val_accuracy: 0.9663\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 0.1346 - val_accuracy: 0.9623\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0278 - accuracy: 0.9935 - val_loss: 0.1567 - val_accuracy: 0.9654\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0798 - accuracy: 0.9815 - val_loss: 0.2533 - val_accuracy: 0.9594\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0146 - accuracy: 0.9974 - val_loss: 0.1540 - val_accuracy: 0.9658\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0438 - accuracy: 0.9889 - val_loss: 0.1289 - val_accuracy: 0.9648\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0252 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 0.1667 - val_accuracy: 0.9685\n",
      "Epoch 8/50\n",
      " 250/1000 [======>.......................] - ETA: 4s - loss: 0.0103 - accuracy: 0.9991Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0122 - accuracy: 0.9978 - val_loss: 0.1544 - val_accuracy: 0.9687\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0298 - accuracy: 0.9935 - val_loss: 0.1300 - val_accuracy: 0.9671\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.1758 - val_accuracy: 0.9674\n",
      " 437/1000 [============>.................] - ETA: 4s - loss: 0.0063 - accuracy: 0.9991Epoch 9/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0227 - accuracy: 0.9957 - val_loss: 0.1335 - val_accuracy: 0.9668\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.1525 - val_accuracy: 0.9693\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.1766 - val_accuracy: 0.9682\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 21s 15ms/step - loss: 0.2870 - accuracy: 0.9183 - val_loss: 0.2050 - val_accuracy: 0.9490\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0139 - accuracy: 0.9982 - val_loss: 0.1436 - val_accuracy: 0.9663\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.1590 - val_accuracy: 0.9702\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.1929 - val_accuracy: 0.9674\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1071 - accuracy: 0.9682 - val_loss: 0.1723 - val_accuracy: 0.9613\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.0086 - accuracy: 0.99\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.0528 - accuracy: 0.98\n",
      " 638/1000 [==================>...........] - ETA: 2s - loss: 0.0560 - accuracy: 0.9843Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.1430 - val_accuracy: 0.9682\n",
      "Epoch 10/50\n",
      " 214/1000 [=====>........................] - ETA: 5s - loss: 0.0058 - accuracy: 0.9993Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0589 - accuracy: 0.9830 - val_loss: 0.1592 - val_accuracy: 0.9643\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.1491 - val_accuracy: 0.9693\n",
      "1000/1000 [==============================] - 16s 14ms/step - loss: 0.2856 - accuracy: 0.9189 - val_loss: 0.1988 - val_accuracy: 0.9483\n",
      "181/500 [=========>....................] - ETA: 1sEpoch 2/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0941 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0395 - accuracy: 0.9888 - val_loss: 0.1781 - val_accuracy: 0.9631\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 14ms/step - loss: 0.2920 - accuracy: 0.9180 - val_loss: 0.1772 - val_accuracy: 0.9511\n",
      "Epoch 2/50\n",
      " 456/1000 [============>.................] - ETA: 4s - loss: 0.0231 - accuracy: 0.9930Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1025 - accuracy: 0.9704 - val_loss: 0.1590 - val_accuracy: 0.9613\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.1655 - val_accuracy: 0.9665\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1057 - accuracy: 0.9693 - val_loss: 0.1663 - val_accuracy: 0.9590\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 14s 12ms/step - loss: 0.2944 - accuracy: 0.9205 - val_loss: 0.2111 - val_accuracy: 0.9486\n",
      " 815/1000 [=======================>......] - ETA: 1s - loss: 0.0157 - accuracy: 0.9952Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0559 - accuracy: 0.9828 - val_loss: 0.1682 - val_accuracy: 0.9632\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.1832 - val_accuracy: 0.9662\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0638 - accuracy: 0.9815 - val_loss: 0.1568 - val_accuracy: 0.9608\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1294 - accuracy: 0.9635 - val_loss: 0.1931 - val_accuracy: 0.9537\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.1485 - val_accuracy: 0.9663\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.2005 - val_accuracy: 0.9647\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0365 - accuracy: 0.9891 - val_loss: 0.1505 - val_accuracy: 0.9617\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0987 - accuracy: 0.9738 - val_loss: 0.2064 - val_accuracy: 0.9614\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.1563 - val_accuracy: 0.9691\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.2306 - val_accuracy: 0.9646\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.1859 - val_accuracy: 0.9611\n",
      " 440/1000 [============>.................] - ETA: 4s - loss: 0.0664 - accuracy: 0.9808Epoch 6/50\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.0238 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0728 - accuracy: 0.9781 - val_loss: 0.2423 - val_accuracy: 0.9597\n",
      "Epoch 5/50\n",
      " 909/1000 [==========================>...] - ETA: 0s - loss: 0.0272 - accuracy: 0.9919Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.1934 - val_accuracy: 0.9650\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.1711 - val_accuracy: 0.9658\n",
      " 235/1000 [======>.......................] - ETA: 7s - loss: 0.0141 - accuracy: 0.9947Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0525 - accuracy: 0.9847 - val_loss: 0.2161 - val_accuracy: 0.9635\n",
      " 814/1000 [=======================>......] - ETA: 1s - loss: 0.0172 - accuracy: 0.9950Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.1961 - val_accuracy: 0.9666\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.1699 - val_accuracy: 0.9685\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 15s 12ms/step - loss: 0.2869 - accuracy: 0.9201 - val_loss: 0.1783 - val_accuracy: 0.9538\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0526 - accuracy: 0.9848 - val_loss: 0.2543 - val_accuracy: 0.9617\n",
      " 870/1000 [=========================>....] - ETA: 1s - loss: 0.0218 - accuracy: 0.9939Epoch 7/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.1863 - val_accuracy: 0.9667\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.1588 - val_accuracy: 0.9701\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1205 - accuracy: 0.9640 - val_loss: 0.1925 - val_accuracy: 0.9573\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0584 - accuracy: 0.9851 - val_loss: 0.2500 - val_accuracy: 0.9634\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.2109 - val_accuracy: 0.9676\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.1649 - val_accuracy: 0.9676\n",
      "500/500 [==============================] - 2s 4ms/step\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0848 - accuracy: 0.9740 - val_loss: 0.2124 - val_accuracy: 0.9548\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0802 - accuracy: 0.98\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0760 - accuracy: 0.97\n",
      " 286/1000 [=======>......................] - ETA: 4s - loss: 0.0747 - accuracy: 0.9799Epoch 1/50\n",
      " 515/1000 [==============>...............] - ETA: 2s - loss: 0.0701 - accuracy: 0.9803Epoch 1/50\n",
      " 636/1000 [==================>...........] - ETA: 2s - loss: 0.0723 - accuracy: 0.9797Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0792 - accuracy: 0.9780 - val_loss: 0.2288 - val_accuracy: 0.9611\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2832 - accuracy: 0.9224 - val_loss: 0.1959 - val_accuracy: 0.9486\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 13s 12ms/step - loss: 0.4999 - accuracy: 0.9004 - val_loss: 0.2515 - val_accuracy: 0.9372\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 14s 12ms/step - loss: 0.4300 - accuracy: 0.9022 - val_loss: 0.2405 - val_accuracy: 0.9383\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0672 - accuracy: 0.9816 - val_loss: 0.1836 - val_accuracy: 0.9626\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1166 - accuracy: 0.9653 - val_loss: 0.1404 - val_accuracy: 0.9613\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2110 - accuracy: 0.9431 - val_loss: 0.2630 - val_accuracy: 0.9355\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2066 - accuracy: 0.9454 - val_loss: 0.3321 - val_accuracy: 0.9254\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0454 - accuracy: 0.9865 - val_loss: 0.1844 - val_accuracy: 0.9633\n",
      "1000/1000 [==============================] - 11s 10ms/step - loss: 0.0866 - accuracy: 0.9740 - val_loss: 0.1902 - val_accuracy: 0.9552\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1724 - accuracy: 0.9528 - val_loss: 0.2537 - val_accuracy: 0.9364\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.2098 - accuracy: 0.9501 - val_loss: 0.2560 - val_accuracy: 0.9435\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0766 - accuracy: 0.9785 - val_loss: 0.1836 - val_accuracy: 0.9642\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1639 - accuracy: 0.9579 - val_loss: 0.2577 - val_accuracy: 0.9410\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1778 - accuracy: 0.9565 - val_loss: 0.2470 - val_accuracy: 0.9457\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.0673 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0665 - accuracy: 0.9821 - val_loss: 0.1542 - val_accuracy: 0.9679\n",
      "Epoch 6/50\n",
      "  81/1000 [=>............................] - ETA: 6s - loss: 0.0457 - accuracy: 0.9900Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1524 - accuracy: 0.9616 - val_loss: 0.2081 - val_accuracy: 0.9517\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1454 - accuracy: 0.9639 - val_loss: 0.3304 - val_accuracy: 0.9419\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0551 - accuracy: 0.9848 - val_loss: 0.2141 - val_accuracy: 0.9657\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1367 - accuracy: 0.9653 - val_loss: 0.2937 - val_accuracy: 0.9522\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 17s 14ms/step - loss: 0.4146 - accuracy: 0.9025 - val_loss: 0.3571 - val_accuracy: 0.9147\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1523 - accuracy: 0.9646 - val_loss: 0.2702 - val_accuracy: 0.9439\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.2452 - accuracy: 0.94\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0602 - accuracy: 0.9859 - val_loss: 0.2319 - val_accuracy: 0.9640\n",
      "267/500 [===============>..............] - ETA: 0sEpoch 1/50 0.2327 - accuracy: 0.94\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1349 - accuracy: 0.9668 - val_loss: 0.2620 - val_accuracy: 0.9511\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0865 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.2331 - accuracy: 0.9423 - val_loss: 0.2401 - val_accuracy: 0.9375\n",
      "Epoch 3/50\n",
      " 585/1000 [================>.............] - ETA: 2s - loss: 0.1203 - accuracy: 0.9709Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1326 - accuracy: 0.9698 - val_loss: 0.2481 - val_accuracy: 0.9542\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1878 - accuracy: 0.9512 - val_loss: 0.2421 - val_accuracy: 0.9414\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 17s 16ms/step - loss: 0.3824 - accuracy: 0.8946 - val_loss: 0.2149 - val_accuracy: 0.9414\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1256 - accuracy: 0.9713 - val_loss: 0.3354 - val_accuracy: 0.9489\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 19s 15ms/step - loss: 0.3788 - accuracy: 0.8943 - val_loss: 0.2150 - val_accuracy: 0.9431\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1689 - accuracy: 0.9582 - val_loss: 0.2809 - val_accuracy: 0.9377\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1344 - accuracy: 0.9604 - val_loss: 0.1681 - val_accuracy: 0.9566\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1039 - accuracy: 0.9755 - val_loss: 0.2780 - val_accuracy: 0.9539\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1311 - accuracy: 0.9612 - val_loss: 0.1813 - val_accuracy: 0.9555\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1591 - accuracy: 0.9622 - val_loss: 0.2380 - val_accuracy: 0.9497\n",
      " 552/1000 [===============>..............] - ETA: 6s - loss: 0.0801 - accuracy: 0.9763Epoch 6/50\n",
      "500/500 [==============================] - 5s 9ms/step loss: 0.1399 - accuracy: 0.967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0806 - accuracy: 0.9767 - val_loss: 0.1520 - val_accuracy: 0.9583\n",
      " 822/1000 [=======================>......] - ETA: 1s - loss: 0.1488 - accuracy: 0.9649Epoch 4/50\n",
      "   9/1000 [..............................] - ETA: 6s - loss: 0.0542 - accuracy: 0.9896Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1493 - accuracy: 0.9647 - val_loss: 0.2793 - val_accuracy: 0.9476\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0806 - accuracy: 0.9758 - val_loss: 0.1586 - val_accuracy: 0.9627\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0517 - accuracy: 0.9860 - val_loss: 0.1526 - val_accuracy: 0.9601\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1478 - accuracy: 0.9653 - val_loss: 0.2748 - val_accuracy: 0.9527\n",
      " 852/1000 [========================>.....] - ETA: 2s - loss: 0.0497 - accuracy: 0.9852Epoch 8/50\n",
      "1000/1000 [==============================] - 21s 19ms/step - loss: 0.3794 - accuracy: 0.8979 - val_loss: 0.2113 - val_accuracy: 0.9391\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.1747 - val_accuracy: 0.9620\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0316 - accuracy: 0.9921 - val_loss: 0.1507 - val_accuracy: 0.9628\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1362 - accuracy: 0.9697 - val_loss: 0.2779 - val_accuracy: 0.9506\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1355 - accuracy: 0.9609 - val_loss: 0.1610 - val_accuracy: 0.9556\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0309 - accuracy: 0.9917 - val_loss: 0.1809 - val_accuracy: 0.9643\n",
      " 592/1000 [================>.............] - ETA: 5s - loss: 0.0195 - accuracy: 0.9952Epoch 6/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1207 - accuracy: 0.9734 - val_loss: 0.2330 - val_accuracy: 0.9582\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0221 - accuracy: 0.9941 - val_loss: 0.1605 - val_accuracy: 0.9638\n",
      " 662/1000 [==================>...........] - ETA: 4s - loss: 0.0191 - accuracy: 0.9963Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0808 - accuracy: 0.9771 - val_loss: 0.1373 - val_accuracy: 0.9603\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 0.1860 - val_accuracy: 0.9639\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1344 - accuracy: 0.9715 - val_loss: 0.3342 - val_accuracy: 0.9490\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.1880 - val_accuracy: 0.9661\n",
      " 321/1000 [========>.....................] - ETA: 7s - loss: 0.1052 - accuracy: 0.9741Epoch 8/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0537 - accuracy: 0.9857 - val_loss: 0.1378 - val_accuracy: 0.9645\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.1982 - val_accuracy: 0.9665\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1215 - accuracy: 0.9724 - val_loss: 0.3122 - val_accuracy: 0.9547\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.1901 - val_accuracy: 0.9675\n",
      " 703/1000 [====================>.........] - ETA: 3s - loss: 0.0138 - accuracy: 0.9968Epoch 9/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.1486 - val_accuracy: 0.9628\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.1856 - val_accuracy: 0.9677\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1225 - accuracy: 0.9748 - val_loss: 0.3062 - val_accuracy: 0.9507\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 6s 11ms/steploss: 0.0192 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.1969 - val_accuracy: 0.9665\n",
      "Epoch 10/50\n",
      " 266/1000 [======>.......................] - ETA: 7s - loss: 0.0149 - accuracy: 0.9980Epoch 1/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.1637 - val_accuracy: 0.9631\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1139 - accuracy: 0.9768 - val_loss: 0.3910 - val_accuracy: 0.9525\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.2001 - val_accuracy: 0.9672\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1359 - accuracy: 0.9738 - val_loss: 0.3349 - val_accuracy: 0.9539\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 0.1536 - val_accuracy: 0.9668\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.0072 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 20s 16ms/step - loss: 0.2889 - accuracy: 0.9165 - val_loss: 0.1853 - val_accuracy: 0.9519\n",
      " 437/1000 [============>.................] - ETA: 6s - loss: 0.0065 - accuracy: 0.9988Epoch 2/50\n",
      "500/500 [==============================] - 4s 7ms/step- loss: 0.1021 - accuracy: 0.96\n",
      " 672/1000 [===================>..........] - ETA: 3s - loss: 0.0106 - accuracy: 0.9980Epoch 1/50\n",
      " 438/1000 [============>.................] - ETA: 6s - loss: 0.0981 - accuracy: 0.9694Epoch 1/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.1552 - val_accuracy: 0.9671\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1070 - accuracy: 0.9681 - val_loss: 0.1758 - val_accuracy: 0.9542\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 5s 9ms/step loss: 0.0567 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 18s 14ms/step - loss: 0.2861 - accuracy: 0.9178 - val_loss: 0.1719 - val_accuracy: 0.9518\n",
      "Epoch 2/50\n",
      "  95/1000 [=>............................] - ETA: 10s - loss: 0.0977 - accuracy: 0.9734Epoch 1/50\n",
      "1000/1000 [==============================] - 17s 14ms/step - loss: 0.2866 - accuracy: 0.9183 - val_loss: 0.1763 - val_accuracy: 0.9528\n",
      " 178/1000 [====>.........................] - ETA: 9s - loss: 0.1011 - accuracy: 0.9710Epoch 2/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0610 - accuracy: 0.9809 - val_loss: 0.1639 - val_accuracy: 0.9600\n",
      " 451/1000 [============>.................] - ETA: 7s - loss: 0.1030 - accuracy: 0.9685Epoch 4/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0980 - accuracy: 0.9712 - val_loss: 0.1686 - val_accuracy: 0.9566\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1025 - accuracy: 0.9692 - val_loss: 0.1445 - val_accuracy: 0.9638\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 22s 17ms/step - loss: 0.2818 - accuracy: 0.9192 - val_loss: 0.1808 - val_accuracy: 0.9472\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.1439 - val_accuracy: 0.9671\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.1501 - val_accuracy: 0.9638\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0613 - accuracy: 0.9809 - val_loss: 0.1617 - val_accuracy: 0.9592\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.1510 - val_accuracy: 0.9672\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1415 - accuracy: 0.9581 - val_loss: 0.1620 - val_accuracy: 0.9575\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.1462 - val_accuracy: 0.9649\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.1420 - val_accuracy: 0.9638\n",
      " 969/1000 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9911Epoch 5/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.1590 - val_accuracy: 0.9671\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0962 - accuracy: 0.9709 - val_loss: 0.1846 - val_accuracy: 0.9602\n",
      " 611/1000 [=================>............] - ETA: 5s - loss: 0.0328 - accuracy: 0.9890Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0330 - accuracy: 0.9888 - val_loss: 0.1501 - val_accuracy: 0.9663\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.1617 - val_accuracy: 0.9640\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.1667 - val_accuracy: 0.9681\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0894 - accuracy: 0.9741 - val_loss: 0.1730 - val_accuracy: 0.9610\n",
      "  30/1000 [..............................] - ETA: 13s - loss: 0.0142 - accuracy: 0.9979Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.1491 - val_accuracy: 0.9692\n",
      " 713/1000 [====================>.........] - ETA: 4s - loss: 0.0179 - accuracy: 0.9948Epoch 7/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.1457 - val_accuracy: 0.9667\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.1550 - val_accuracy: 0.9682\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0662 - accuracy: 0.9807 - val_loss: 0.2191 - val_accuracy: 0.9607\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.2102 - val_accuracy: 0.9671\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.1666 - val_accuracy: 0.9638\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.2267 - val_accuracy: 0.9642\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0649 - accuracy: 0.9821 - val_loss: 0.1932 - val_accuracy: 0.9649\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.2009 - val_accuracy: 0.9669\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 4s 6ms/step loss: 0.0483 - accuracy: 0.989\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.1550 - val_accuracy: 0.9673\n",
      "Epoch 9/50\n",
      " 274/1000 [=======>......................] - ETA: 7s - loss: 0.0138 - accuracy: 0.9952Epoch 1/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0605 - accuracy: 0.9843 - val_loss: 0.2185 - val_accuracy: 0.9627\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.1975 - val_accuracy: 0.9715\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.1667 - val_accuracy: 0.9691\n",
      "500/500 [==============================] - 4s 6ms/step loss: 0.3383 - accuracy: 0.90\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.3038 - accuracy: 0.91\n",
      " 878/1000 [=========================>....] - ETA: 1s - loss: 0.2951 - accuracy: 0.9147Epoch 1/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.2867 - accuracy: 0.91\n",
      "  25/1000 [..............................] - ETA: 6s - loss: 1.0753 - accuracy: 0.6687Epoch 1/50\n",
      "1000/1000 [==============================] - 17s 12ms/step - loss: 0.2844 - accuracy: 0.9183 - val_loss: 0.1887 - val_accuracy: 0.9452\n",
      "Epoch 2/50\n",
      "   1/1000 [..............................] - ETA: 7s - loss: 0.0566 - accuracy: 1.0000Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 14ms/step - loss: 0.2811 - accuracy: 0.9172 - val_loss: 0.2027 - val_accuracy: 0.9429\n",
      " 790/1000 [======================>.......] - ETA: 2s - loss: 0.4313 - accuracy: 0.8892Epoch 2/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1414 - accuracy: 0.9594 - val_loss: 0.1813 - val_accuracy: 0.9528\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 17s 15ms/step - loss: 0.4376 - accuracy: 0.8945 - val_loss: 0.4333 - val_accuracy: 0.9176\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 22s 19ms/step - loss: 0.4081 - accuracy: 0.8956 - val_loss: 0.3517 - val_accuracy: 0.9202\n",
      " 582/1000 [================>.............] - ETA: 6s - loss: 0.0906 - accuracy: 0.9726Epoch 2/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1344 - accuracy: 0.9601 - val_loss: 0.2041 - val_accuracy: 0.9478\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0937 - accuracy: 0.9719 - val_loss: 0.1956 - val_accuracy: 0.9498\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.2472 - accuracy: 0.9410 - val_loss: 0.2188 - val_accuracy: 0.9472\n",
      " 856/1000 [========================>.....] - ETA: 1s - loss: 0.2390 - accuracy: 0.9393Epoch 3/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2401 - accuracy: 0.9392 - val_loss: 0.2720 - val_accuracy: 0.9319\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 17s 18ms/step - loss: 0.1047 - accuracy: 0.9702 - val_loss: 0.1712 - val_accuracy: 0.9617\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0844 - accuracy: 0.9750 - val_loss: 0.1732 - val_accuracy: 0.9564\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2133 - accuracy: 0.9488 - val_loss: 0.2394 - val_accuracy: 0.9494\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1919 - accuracy: 0.9505 - val_loss: 0.2438 - val_accuracy: 0.9392\n",
      " 666/1000 [==================>...........] - ETA: 5s - loss: 0.0669 - accuracy: 0.9810Epoch 4/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0818 - accuracy: 0.9763 - val_loss: 0.1681 - val_accuracy: 0.9636\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0694 - accuracy: 0.9809 - val_loss: 0.1929 - val_accuracy: 0.9653\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1750 - accuracy: 0.9597 - val_loss: 0.3032 - val_accuracy: 0.9516\n",
      " 458/1000 [============>.................] - ETA: 5s - loss: 0.0669 - accuracy: 0.9829Epoch 5/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1679 - accuracy: 0.9586 - val_loss: 0.2458 - val_accuracy: 0.9457\n",
      " 777/1000 [======================>.......] - ETA: 2s - loss: 0.0731 - accuracy: 0.9805Epoch 5/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0713 - accuracy: 0.9804 - val_loss: 0.1862 - val_accuracy: 0.9647\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0618 - accuracy: 0.9833 - val_loss: 0.1967 - val_accuracy: 0.9637\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1555 - accuracy: 0.9634 - val_loss: 0.2780 - val_accuracy: 0.9433\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1446 - accuracy: 0.9627 - val_loss: 0.2704 - val_accuracy: 0.9529\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0623 - accuracy: 0.9826 - val_loss: 0.2007 - val_accuracy: 0.9627\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0512 - accuracy: 0.9851 - val_loss: 0.2540 - val_accuracy: 0.9553\n",
      " 494/1000 [=============>................] - ETA: 5s - loss: 0.1311 - accuracy: 0.9669Epoch 8/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1424 - accuracy: 0.9667 - val_loss: 0.2605 - val_accuracy: 0.9423\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1434 - accuracy: 0.9647 - val_loss: 0.2826 - val_accuracy: 0.9579\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0509 - accuracy: 0.9858 - val_loss: 0.1948 - val_accuracy: 0.9637\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0527 - accuracy: 0.9857 - val_loss: 0.2016 - val_accuracy: 0.9684\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1156 - accuracy: 0.9712 - val_loss: 0.2607 - val_accuracy: 0.9564\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1299 - accuracy: 0.9677 - val_loss: 0.2329 - val_accuracy: 0.9569\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.1103 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0451 - accuracy: 0.9878 - val_loss: 0.2406 - val_accuracy: 0.9597\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0461 - accuracy: 0.9867 - val_loss: 0.1859 - val_accuracy: 0.9663\n",
      "449/500 [=========================>....] - ETA: 0sEpoch 1/50 0.1134 - accuracy: 0.97\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.0393 - accuracy: 0.98\n",
      " 125/1000 [==>...........................] - ETA: 8s - loss: 0.6615 - accuracy: 0.8217Epoch 1/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1121 - accuracy: 0.9727 - val_loss: 0.2408 - val_accuracy: 0.9612\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0454 - accuracy: 0.9875 - val_loss: 0.2590 - val_accuracy: 0.9613\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.1079 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 14s 12ms/step - loss: 0.4203 - accuracy: 0.8946 - val_loss: 0.2423 - val_accuracy: 0.9370\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1082 - accuracy: 0.9743 - val_loss: 0.3838 - val_accuracy: 0.9532\n",
      "Epoch 10/50\n",
      " 173/1000 [====>.........................] - ETA: 10s - loss: 0.2329 - accuracy: 0.9395Epoch 1/50\n",
      "1000/1000 [==============================] - 20s 17ms/step - loss: 0.3762 - accuracy: 0.8962 - val_loss: 0.1985 - val_accuracy: 0.9459\n",
      " 164/1000 [===>..........................] - ETA: 13s - loss: 0.9867 - accuracy: 0.7329Epoch 2/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0962 - accuracy: 0.9773 - val_loss: 0.2378 - val_accuracy: 0.9618\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2584 - accuracy: 0.9390 - val_loss: 0.2585 - val_accuracy: 0.9323\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 24s 20ms/step - loss: 0.3805 - accuracy: 0.8933 - val_loss: 0.2136 - val_accuracy: 0.9402\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1274 - accuracy: 0.9617 - val_loss: 0.1723 - val_accuracy: 0.9535\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1853 - accuracy: 0.9521 - val_loss: 0.2313 - val_accuracy: 0.9459\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1043 - accuracy: 0.9771 - val_loss: 0.2374 - val_accuracy: 0.9513\n",
      " 321/1000 [========>.....................] - ETA: 11s - loss: 0.1338 - accuracy: 0.9601Epoch 12/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0745 - accuracy: 0.9775 - val_loss: 0.1548 - val_accuracy: 0.9618\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1258 - accuracy: 0.9619 - val_loss: 0.1628 - val_accuracy: 0.9548\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0970 - accuracy: 0.9783 - val_loss: 0.2163 - val_accuracy: 0.9591\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1601 - accuracy: 0.9597 - val_loss: 0.2398 - val_accuracy: 0.9495\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.1724 - val_accuracy: 0.9628\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1404 - accuracy: 0.9650 - val_loss: 0.2643 - val_accuracy: 0.9498\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0763 - accuracy: 0.9765 - val_loss: 0.1680 - val_accuracy: 0.9585\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0930 - accuracy: 0.9783 - val_loss: 0.3166 - val_accuracy: 0.9532\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1467 - accuracy: 0.9656 - val_loss: 0.2371 - val_accuracy: 0.9534\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1094 - accuracy: 0.9779 - val_loss: 0.2950 - val_accuracy: 0.9551\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0338 - accuracy: 0.9913 - val_loss: 0.1669 - val_accuracy: 0.9649\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0482 - accuracy: 0.9866 - val_loss: 0.1527 - val_accuracy: 0.9628\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1301 - accuracy: 0.9693 - val_loss: 0.2699 - val_accuracy: 0.9477\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1029 - accuracy: 0.9787 - val_loss: 0.3001 - val_accuracy: 0.9575\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.1755 - val_accuracy: 0.9642\n",
      " 262/1000 [======>.......................] - ETA: 8s - loss: 0.0655 - accuracy: 0.9849Epoch 7/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.1869 - val_accuracy: 0.9627\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1142 - accuracy: 0.9730 - val_loss: 0.1994 - val_accuracy: 0.9616\n",
      " 813/1000 [=======================>......] - ETA: 3s - loss: 0.0165 - accuracy: 0.9954Epoch 9/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1026 - accuracy: 0.9782 - val_loss: 0.3419 - val_accuracy: 0.9612\n",
      " 869/1000 [=========================>....] - ETA: 2s - loss: 0.0164 - accuracy: 0.9954Epoch 17/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.1834 - val_accuracy: 0.9640\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 0.2093 - val_accuracy: 0.9631\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1129 - accuracy: 0.9744 - val_loss: 0.2568 - val_accuracy: 0.9609\n",
      " 647/1000 [==================>...........] - ETA: 5s - loss: 0.0120 - accuracy: 0.9972Epoch 10/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0799 - accuracy: 0.9842 - val_loss: 0.3939 - val_accuracy: 0.9563\n",
      "500/500 [==============================] - 4s 6ms/step loss: 0.0987 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.2207 - val_accuracy: 0.9589\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.2067 - val_accuracy: 0.9632\n",
      "Epoch 8/50\n",
      "462/500 [==========================>...] - ETA: 0sEpoch 1/50 0.0167 - accuracy: 0.99\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0176 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1122 - accuracy: 0.9755 - val_loss: 0.2167 - val_accuracy: 0.9515\n",
      "Epoch 11/50\n",
      " 177/1000 [====>.........................] - ETA: 11s - loss: 0.9020 - accuracy: 0.7595Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.1806 - val_accuracy: 0.9686\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0817 - accuracy: 0.9799 - val_loss: 0.2873 - val_accuracy: 0.9582\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 23s 21ms/step - loss: 0.3750 - accuracy: 0.8953 - val_loss: 0.1879 - val_accuracy: 0.9470\n",
      " 509/1000 [==============>...............] - ETA: 8s - loss: 0.0042 - accuracy: 0.9988Epoch 2/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1057 - accuracy: 0.9781 - val_loss: 0.2767 - val_accuracy: 0.9622\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.2569 - val_accuracy: 0.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 30s 24ms/step - loss: 0.2882 - accuracy: 0.9178 - val_loss: 0.1721 - val_accuracy: 0.9492\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 5s 9ms/step loss: 0.0974 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1276 - accuracy: 0.9632 - val_loss: 0.1423 - val_accuracy: 0.9572\n",
      "Epoch 3/50\n",
      " 847/1000 [========================>.....] - ETA: 2s - loss: 0.1036 - accuracy: 0.9673Epoch 1/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0933 - accuracy: 0.9805 - val_loss: 0.3398 - val_accuracy: 0.9597\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1057 - accuracy: 0.9667 - val_loss: 0.2038 - val_accuracy: 0.9504\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.0741 - accuracy: 0.978\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0724 - accuracy: 0.9790 - val_loss: 0.1533 - val_accuracy: 0.9578\n",
      "Epoch 4/50\n",
      " 695/1000 [===================>..........] - ETA: 3s - loss: 0.0632 - accuracy: 0.9796Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0689 - accuracy: 0.9778 - val_loss: 0.1520 - val_accuracy: 0.9582\n",
      " 668/1000 [===================>..........] - ETA: 4s - loss: 0.0420 - accuracy: 0.9884Epoch 4/50\n",
      "1000/1000 [==============================] - 21s 18ms/step - loss: 0.2850 - accuracy: 0.9159 - val_loss: 0.1746 - val_accuracy: 0.9517\n",
      "  74/1000 [=>............................] - ETA: 19s - loss: 0.0411 - accuracy: 0.9873Epoch 2/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0457 - accuracy: 0.9866 - val_loss: 0.1402 - val_accuracy: 0.9646\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 0.1591 - val_accuracy: 0.9666\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 27s 23ms/step - loss: 0.2902 - accuracy: 0.9141 - val_loss: 0.1608 - val_accuracy: 0.9539\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1056 - accuracy: 0.9674 - val_loss: 0.1567 - val_accuracy: 0.9586\n",
      "  86/1000 [=>............................] - ETA: 17s - loss: 0.0333 - accuracy: 0.9887Epoch 3/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.1546 - val_accuracy: 0.9633\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0426 - accuracy: 0.9856 - val_loss: 0.1651 - val_accuracy: 0.9607\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1107 - accuracy: 0.9663 - val_loss: 0.1817 - val_accuracy: 0.9511\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0674 - accuracy: 0.9783 - val_loss: 0.1365 - val_accuracy: 0.9657\n",
      " 604/1000 [=================>............] - ETA: 5s - loss: 0.0183 - accuracy: 0.9956Epoch 4/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.2086 - val_accuracy: 0.9553\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.1556 - val_accuracy: 0.9693\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0685 - accuracy: 0.9792 - val_loss: 0.1420 - val_accuracy: 0.9631\n",
      "  25/1000 [..............................] - ETA: 13s - loss: 0.0188 - accuracy: 0.9975Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 0.1516 - val_accuracy: 0.9633\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.1800 - val_accuracy: 0.9611\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.2039 - val_accuracy: 0.9602\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0549 - accuracy: 0.9830 - val_loss: 0.1425 - val_accuracy: 0.9640\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.1663 - val_accuracy: 0.9604\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0241 - accuracy: 0.9948 - val_loss: 0.1488 - val_accuracy: 0.9677\n",
      " 778/1000 [======================>.......] - ETA: 3s - loss: 0.0356 - accuracy: 0.9886Epoch 9/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.1496 - val_accuracy: 0.9697\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0404 - accuracy: 0.9874 - val_loss: 0.1317 - val_accuracy: 0.9665\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0361 - accuracy: 0.9883 - val_loss: 0.1770 - val_accuracy: 0.9610\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.1623 - val_accuracy: 0.9687\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.1702 - val_accuracy: 0.9676\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 0.1417 - val_accuracy: 0.9674\n",
      "   1/1000 [..............................] - ETA: 11s - loss: 1.2300e-04 - accuracy: 1.0000Epoch 7/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.1850 - val_accuracy: 0.9638\n",
      " 110/1000 [==>...........................] - ETA: 13s - loss: 0.0274 - accuracy: 0.9920Epoch 8/50\n",
      "500/500 [==============================] - 5s 9ms/step- loss: 0.0184 - accuracy: 0.992\n",
      " 699/1000 [===================>..........] - ETA: 4s - loss: 0.0264 - accuracy: 0.9919Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.1525 - val_accuracy: 0.9691\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.1298 - val_accuracy: 0.9702\n",
      " 133/1000 [==>...........................] - ETA: 10s - loss: 0.5762 - accuracy: 0.8280Epoch 8/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 0.1753 - val_accuracy: 0.9654\n",
      "1000/1000 [==============================] - 21s 17ms/step - loss: 0.2970 - accuracy: 0.9154 - val_loss: 0.2095 - val_accuracy: 0.9449\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0236 - accuracy: 0.9930 - val_loss: 0.1543 - val_accuracy: 0.9642\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.1610 - val_accuracy: 0.9722\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 5s 10ms/step loss: 0.0222 - accuracy: 0.995\n",
      " 726/1000 [====================>.........] - ETA: 3s - loss: 0.1529 - accuracy: 0.9567Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1510 - accuracy: 0.9570 - val_loss: 0.1971 - val_accuracy: 0.9468\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.1343 - val_accuracy: 0.9681\n",
      " 146/1000 [===>..........................] - ETA: 11s - loss: 0.5565 - accuracy: 0.8363Epoch 10/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.1903 - val_accuracy: 0.9672\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1146 - accuracy: 0.9680 - val_loss: 0.1595 - val_accuracy: 0.9605\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.1496 - val_accuracy: 0.9688\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 24s 20ms/step - loss: 0.2985 - accuracy: 0.9143 - val_loss: 0.1905 - val_accuracy: 0.9465\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.2006 - val_accuracy: 0.9618\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1514 - accuracy: 0.9564 - val_loss: 0.2177 - val_accuracy: 0.9432\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0886 - accuracy: 0.9747 - val_loss: 0.1458 - val_accuracy: 0.9611\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.1424 - val_accuracy: 0.9716\n",
      "   5/1000 [..............................] - ETA: 14s - loss: 0.0592 - accuracy: 0.9875Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 4s 7ms/step- loss: 0.0760 - accuracy: 0.978\n",
      " 570/1000 [================>.............] - ETA: 5s - loss: 0.1121 - accuracy: 0.9686Epoch 1/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1155 - accuracy: 0.9672 - val_loss: 0.1663 - val_accuracy: 0.9612\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.1643 - val_accuracy: 0.9663\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0748 - accuracy: 0.9776 - val_loss: 0.2214 - val_accuracy: 0.9586\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 24s 18ms/step - loss: 0.3014 - accuracy: 0.9123 - val_loss: 0.1803 - val_accuracy: 0.9482\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0719 - accuracy: 0.9805 - val_loss: 0.2247 - val_accuracy: 0.9478\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 13s 24ms/steploss: 0.1463 - accuracy: 0.965\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0975 - accuracy: 0.9736 - val_loss: 0.2432 - val_accuracy: 0.9557\n",
      "Epoch 5/50\n",
      " 540/1000 [===============>..............] - ETA: 5s - loss: 0.0756 - accuracy: 0.9799Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1480 - accuracy: 0.9588 - val_loss: 0.1528 - val_accuracy: 0.9581\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0664 - accuracy: 0.9827 - val_loss: 0.2606 - val_accuracy: 0.9521\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0761 - accuracy: 0.9787 - val_loss: 0.1878 - val_accuracy: 0.9653\n",
      "  76/1000 [=>............................] - ETA: 17s - loss: 0.0447 - accuracy: 0.9868Epoch 6/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1108 - accuracy: 0.9688 - val_loss: 0.1562 - val_accuracy: 0.9615\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 27s 21ms/step - loss: 0.4386 - accuracy: 0.8918 - val_loss: 0.3537 - val_accuracy: 0.9283\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0517 - accuracy: 0.9858 - val_loss: 0.2014 - val_accuracy: 0.9648\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0793 - accuracy: 0.9799 - val_loss: 0.1929 - val_accuracy: 0.9606\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0963 - accuracy: 0.9727 - val_loss: 0.1484 - val_accuracy: 0.9641\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2826 - accuracy: 0.9325 - val_loss: 0.3657 - val_accuracy: 0.9306\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0506 - accuracy: 0.9862 - val_loss: 0.2253 - val_accuracy: 0.9638\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0626 - accuracy: 0.9821 - val_loss: 0.1853 - val_accuracy: 0.9698\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 6s 11ms/steploss: 0.0684 - accuracy: 0.98\n",
      " 837/1000 [========================>.....] - ETA: 2s - loss: 0.0468 - accuracy: 0.9865Epoch 1/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0782 - accuracy: 0.9786 - val_loss: 0.1863 - val_accuracy: 0.9621\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.2334 - accuracy: 0.9462 - val_loss: 0.2559 - val_accuracy: 0.9399\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0480 - accuracy: 0.9863 - val_loss: 0.1952 - val_accuracy: 0.9638\n",
      "500/500 [==============================] - 5s 10ms/steploss: 0.4928 - accuracy: 0.87\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1832 - accuracy: 0.9558 - val_loss: 0.3185 - val_accuracy: 0.9451\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0691 - accuracy: 0.9807 - val_loss: 0.1709 - val_accuracy: 0.9611\n",
      "Epoch 7/50\n",
      "  18/1000 [..............................] - ETA: 13s - loss: 0.0602 - accuracy: 0.9826Epoch 1/50\n",
      "1000/1000 [==============================] - 23s 18ms/step - loss: 0.4470 - accuracy: 0.8891 - val_loss: 0.4649 - val_accuracy: 0.8884\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2000 - accuracy: 0.9548 - val_loss: 0.2457 - val_accuracy: 0.9518\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0615 - accuracy: 0.9829 - val_loss: 0.1905 - val_accuracy: 0.9643\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2665 - accuracy: 0.9359 - val_loss: 0.2509 - val_accuracy: 0.9383\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 24s 20ms/step - loss: 0.4462 - accuracy: 0.8869 - val_loss: 0.3310 - val_accuracy: 0.9241\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1365 - accuracy: 0.9673 - val_loss: 0.2039 - val_accuracy: 0.9583\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0539 - accuracy: 0.9860 - val_loss: 0.1789 - val_accuracy: 0.9623\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2475 - accuracy: 0.9439 - val_loss: 0.3083 - val_accuracy: 0.9205\n",
      " 301/1000 [========>.....................] - ETA: 9s - loss: 0.0577 - accuracy: 0.9874Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2733 - accuracy: 0.9370 - val_loss: 0.2474 - val_accuracy: 0.9440\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1322 - accuracy: 0.9701 - val_loss: 0.2662 - val_accuracy: 0.9433\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0541 - accuracy: 0.9868 - val_loss: 0.1569 - val_accuracy: 0.9697\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1955 - accuracy: 0.9530 - val_loss: 0.4214 - val_accuracy: 0.9380\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2190 - accuracy: 0.9483 - val_loss: 0.2245 - val_accuracy: 0.9440\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 4s 7ms/step- loss: 0.1464 - accuracy: 0.96\n",
      " 719/1000 [====================>.........] - ETA: 3s - loss: 0.1687 - accuracy: 0.9606Epoch 1/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1933 - accuracy: 0.9608 - val_loss: 0.2274 - val_accuracy: 0.9559\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1767 - accuracy: 0.9589 - val_loss: 0.3179 - val_accuracy: 0.9432\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1821 - accuracy: 0.9582 - val_loss: 0.2179 - val_accuracy: 0.9520\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1192 - accuracy: 0.9727 - val_loss: 0.2486 - val_accuracy: 0.9521\n",
      " 725/1000 [====================>.........] - ETA: 3s - loss: 0.1806 - accuracy: 0.9596Epoch 10/50\n",
      "1000/1000 [==============================] - 19s 14ms/step - loss: 0.5924 - accuracy: 0.8291 - val_loss: 0.2671 - val_accuracy: 0.9254\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1493 - accuracy: 0.9647 - val_loss: 0.3710 - val_accuracy: 0.9548\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1908 - accuracy: 0.9580 - val_loss: 0.2631 - val_accuracy: 0.9473\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2290 - accuracy: 0.9321 - val_loss: 0.2052 - val_accuracy: 0.9420\n",
      " 614/1000 [=================>............] - ETA: 6s - loss: 0.1406 - accuracy: 0.9689Epoch 3/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0908 - accuracy: 0.9778 - val_loss: 0.2066 - val_accuracy: 0.9567\n",
      " 759/1000 [=====================>........] - ETA: 3s - loss: 0.1607 - accuracy: 0.9650Epoch 11/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1391 - accuracy: 0.9684 - val_loss: 0.2199 - val_accuracy: 0.9534\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1575 - accuracy: 0.9653 - val_loss: 0.2508 - val_accuracy: 0.9515\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1644 - accuracy: 0.9507 - val_loss: 0.1772 - val_accuracy: 0.9523\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0930 - accuracy: 0.9775 - val_loss: 0.2295 - val_accuracy: 0.9610\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1266 - accuracy: 0.9619 - val_loss: 0.1657 - val_accuracy: 0.9567\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1179 - accuracy: 0.9724 - val_loss: 0.2456 - val_accuracy: 0.9552\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1192 - accuracy: 0.9711 - val_loss: 0.2410 - val_accuracy: 0.9507\n",
      "495/500 [============================>.] - ETA: 0sEpoch 8/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.0964 - accuracy: 0.9770\n",
      " 445/1000 [============>.................] - ETA: 6s - loss: 0.1010 - accuracy: 0.9746Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0991 - accuracy: 0.9711 - val_loss: 0.1614 - val_accuracy: 0.9583\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1408 - accuracy: 0.9703 - val_loss: 0.2291 - val_accuracy: 0.9535\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1166 - accuracy: 0.9715 - val_loss: 0.1973 - val_accuracy: 0.9597\n",
      " 795/1000 [======================>.......] - ETA: 1s - loss: 0.0815 - accuracy: 0.9764Epoch 9/50\n",
      "1000/1000 [==============================] - 13s 11ms/step - loss: 0.6064 - accuracy: 0.8260 - val_loss: 0.2535 - val_accuracy: 0.9291\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0806 - accuracy: 0.9765 - val_loss: 0.1467 - val_accuracy: 0.9619\n",
      " 338/1000 [=========>....................] - ETA: 8s - loss: 0.1124 - accuracy: 0.9761Epoch 7/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0989 - accuracy: 0.9760 - val_loss: 0.2661 - val_accuracy: 0.9560\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2295 - accuracy: 0.9325 - val_loss: 0.1982 - val_accuracy: 0.9445\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0638 - accuracy: 0.9809 - val_loss: 0.1449 - val_accuracy: 0.9640\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1381 - accuracy: 0.9702 - val_loss: 0.3423 - val_accuracy: 0.9472\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1625 - accuracy: 0.9510 - val_loss: 0.1701 - val_accuracy: 0.9532\n",
      " 904/1000 [==========================>...] - ETA: 1s - loss: 0.1016 - accuracy: 0.9761Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0529 - accuracy: 0.9848 - val_loss: 0.1459 - val_accuracy: 0.9647\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1023 - accuracy: 0.9759 - val_loss: 0.2828 - val_accuracy: 0.9560\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1211 - accuracy: 0.9733 - val_loss: 0.2723 - val_accuracy: 0.9525\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.1494 - val_accuracy: 0.9657\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1224 - accuracy: 0.9627 - val_loss: 0.1523 - val_accuracy: 0.9595\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1185 - accuracy: 0.9736 - val_loss: 0.2850 - val_accuracy: 0.9473\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1104 - accuracy: 0.9775 - val_loss: 0.2418 - val_accuracy: 0.9612\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0350 - accuracy: 0.9903 - val_loss: 0.1465 - val_accuracy: 0.9671\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0988 - accuracy: 0.9703 - val_loss: 0.1433 - val_accuracy: 0.9602\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 5s 10ms/steploss: 0.0797 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0293 - accuracy: 0.9919 - val_loss: 0.1417 - val_accuracy: 0.9684\n",
      "Epoch 12/50\n",
      "  29/1000 [..............................] - ETA: 5s - loss: 0.0262 - accuracy: 0.9935Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0787 - accuracy: 0.9767 - val_loss: 0.1344 - val_accuracy: 0.9641\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1148 - accuracy: 0.9769 - val_loss: 0.5581 - val_accuracy: 0.9459\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0628 - accuracy: 0.9818 - val_loss: 0.1297 - val_accuracy: 0.9672\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0230 - accuracy: 0.9943 - val_loss: 0.1477 - val_accuracy: 0.9679\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 14s 7ms/step - loss: 0.5905 - accuracy: 0.8342 - val_loss: 0.2629 - val_accuracy: 0.9250\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0532 - accuracy: 0.9843 - val_loss: 0.1329 - val_accuracy: 0.9659\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0189 - accuracy: 0.9955 - val_loss: 0.1535 - val_accuracy: 0.9680\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1041 - accuracy: 0.9778 - val_loss: 0.2575 - val_accuracy: 0.9536\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2327 - accuracy: 0.9314 - val_loss: 0.2005 - val_accuracy: 0.9428\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0424 - accuracy: 0.9873 - val_loss: 0.1339 - val_accuracy: 0.9671\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.1544 - val_accuracy: 0.9705\n",
      " 274/1000 [=======>......................] - ETA: 3s - loss: 0.1701 - accuracy: 0.9494Epoch 15/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0100 - accuracy: 0.99\n",
      " 713/1000 [====================>.........] - ETA: 1s - loss: 0.0321 - accuracy: 0.9916Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1677 - accuracy: 0.9510 - val_loss: 0.1751 - val_accuracy: 0.9498\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0331 - accuracy: 0.9911 - val_loss: 0.1317 - val_accuracy: 0.9684\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.1551 - val_accuracy: 0.9690\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1290 - accuracy: 0.9635 - val_loss: 0.1622 - val_accuracy: 0.9544\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 10s 9ms/step - loss: 0.3698 - accuracy: 0.8925 - val_loss: 0.1868 - val_accuracy: 0.9512\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.1297 - val_accuracy: 0.9677\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.1614 - val_accuracy: 0.9692\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1431 - accuracy: 0.95\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1035 - accuracy: 0.9696 - val_loss: 0.1549 - val_accuracy: 0.9586\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1432 - accuracy: 0.9568 - val_loss: 0.1618 - val_accuracy: 0.9585\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.1306 - val_accuracy: 0.9694\n",
      "Epoch 13/50\n",
      "  41/1000 [>.............................] - ETA: 5s - loss: 0.0160 - accuracy: 0.9962Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0838 - accuracy: 0.9753 - val_loss: 0.1464 - val_accuracy: 0.9617\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0920 - accuracy: 0.9712 - val_loss: 0.1428 - val_accuracy: 0.9632\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.1341 - val_accuracy: 0.9697\n",
      " 104/1000 [==>...........................] - ETA: 4s - loss: 0.0584 - accuracy: 0.9811Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 7ms/step - loss: 0.3656 - accuracy: 0.8905 - val_loss: 0.1981 - val_accuracy: 0.9427\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0678 - accuracy: 0.9802 - val_loss: 0.1464 - val_accuracy: 0.9620\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0630 - accuracy: 0.9812 - val_loss: 0.1402 - val_accuracy: 0.9649\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 0.1391 - val_accuracy: 0.9678\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1440 - accuracy: 0.9559 - val_loss: 0.1539 - val_accuracy: 0.9609\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0539 - accuracy: 0.9849 - val_loss: 0.1426 - val_accuracy: 0.9631\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.1450 - val_accuracy: 0.9645\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 0.1376 - val_accuracy: 0.9697\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0927 - accuracy: 0.9722 - val_loss: 0.1427 - val_accuracy: 0.9653\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0446 - accuracy: 0.9876 - val_loss: 0.1446 - val_accuracy: 0.9632\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0348 - accuracy: 0.9893 - val_loss: 0.1451 - val_accuracy: 0.9668\n",
      " 587/1000 [================>.............] - ETA: 2s - loss: 0.0610 - accuracy: 0.9811Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.1438 - val_accuracy: 0.9697\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0637 - accuracy: 0.9803 - val_loss: 0.1427 - val_accuracy: 0.9638\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0468 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.1471 - val_accuracy: 0.9665\n",
      "Epoch 8/50\n",
      " 729/1000 [====================>.........] - ETA: 1s - loss: 0.0457 - accuracy: 0.9861Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0348 - accuracy: 0.9905 - val_loss: 0.1461 - val_accuracy: 0.9666\n",
      " 218/1000 [=====>........................] - ETA: 3s - loss: 0.0173 - accuracy: 0.9938Epoch 11/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.1445 - val_accuracy: 0.9683\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.1405 - val_accuracy: 0.9672\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0294 - accuracy: 0.9925 - val_loss: 0.1514 - val_accuracy: 0.9663\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 8s 6ms/step - loss: 0.3604 - accuracy: 0.8957 - val_loss: 0.1820 - val_accuracy: 0.9511\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0340 - accuracy: 0.9898 - val_loss: 0.1498 - val_accuracy: 0.9674\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.1474 - val_accuracy: 0.9687\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0247 - accuracy: 0.9937 - val_loss: 0.1541 - val_accuracy: 0.9676\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0193 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1418 - accuracy: 0.9582 - val_loss: 0.1566 - val_accuracy: 0.9587\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.1541 - val_accuracy: 0.9679\n",
      "Epoch 8/50\n",
      " 348/1000 [=========>....................] - ETA: 3s - loss: 0.0212 - accuracy: 0.9941Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.1603 - val_accuracy: 0.9667\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0922 - accuracy: 0.9732 - val_loss: 0.1448 - val_accuracy: 0.9626\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.1615 - val_accuracy: 0.9675\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0174 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 8s 6ms/step - loss: 0.2951 - accuracy: 0.9163 - val_loss: 0.2018 - val_accuracy: 0.9488\n",
      "Epoch 2/50\n",
      " 891/1000 [=========================>....] - ETA: 0s - loss: 0.0623 - accuracy: 0.9805Epoch 1/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0630 - accuracy: 0.9803 - val_loss: 0.1468 - val_accuracy: 0.9656\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.1636 - val_accuracy: 0.9697\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1326 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1375 - accuracy: 0.9599 - val_loss: 0.2083 - val_accuracy: 0.9555\n",
      "Epoch 3/50\n",
      " 908/1000 [==========================>...] - ETA: 0s - loss: 0.0478 - accuracy: 0.9854Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.1548 - val_accuracy: 0.9649\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.2937 - accuracy: 0.9171 - val_loss: 0.1824 - val_accuracy: 0.9526\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0932 - accuracy: 0.9725 - val_loss: 0.1783 - val_accuracy: 0.9612\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1321 - accuracy: 0.9601 - val_loss: 0.1657 - val_accuracy: 0.9594\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.1453 - val_accuracy: 0.9701\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 6ms/step - loss: 0.2968 - accuracy: 0.9143 - val_loss: 0.1670 - val_accuracy: 0.9560\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0810 - accuracy: 0.9752 - val_loss: 0.1998 - val_accuracy: 0.9568\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0875 - accuracy: 0.9733 - val_loss: 0.1649 - val_accuracy: 0.9621\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.1611 - val_accuracy: 0.9672\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1389 - accuracy: 0.9592 - val_loss: 0.1464 - val_accuracy: 0.9600\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0678 - accuracy: 0.9792 - val_loss: 0.1969 - val_accuracy: 0.9620\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0794 - accuracy: 0.9760 - val_loss: 0.1681 - val_accuracy: 0.9625\n",
      " 442/1000 [============>.................] - ETA: 2s - loss: 0.0554 - accuracy: 0.9828Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.1647 - val_accuracy: 0.9688\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0946 - accuracy: 0.9718 - val_loss: 0.1500 - val_accuracy: 0.9644\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0612 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0569 - accuracy: 0.9828 - val_loss: 0.1786 - val_accuracy: 0.9685\n",
      "Epoch 7/50\n",
      " 136/1000 [===>..........................] - ETA: 3s - loss: 0.0484 - accuracy: 0.9876Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0663 - accuracy: 0.9794 - val_loss: 0.1723 - val_accuracy: 0.9644\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0752 - accuracy: 0.9797 - val_loss: 0.1541 - val_accuracy: 0.9664\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 0.1791 - val_accuracy: 0.9649\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0606 - accuracy: 0.9821 - val_loss: 0.2036 - val_accuracy: 0.9633\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0650 - accuracy: 0.9797 - val_loss: 0.1777 - val_accuracy: 0.9643\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.4288 - accuracy: 0.8982 - val_loss: 0.3119 - val_accuracy: 0.9334\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0486 - accuracy: 0.9854 - val_loss: 0.2065 - val_accuracy: 0.9629\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0506 - accuracy: 0.9847 - val_loss: 0.1860 - val_accuracy: 0.9709\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0056 - accuracy: 1.00\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0650 - accuracy: 0.9811 - val_loss: 0.1623 - val_accuracy: 0.9678\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2349 - accuracy: 0.9387 - val_loss: 0.2964 - val_accuracy: 0.9453\n",
      "Epoch 3/50\n",
      " 429/1000 [===========>..................] - ETA: 2s - loss: 0.0445 - accuracy: 0.9870Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.2434 - val_accuracy: 0.9632\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0536 - accuracy: 0.9838 - val_loss: 0.1754 - val_accuracy: 0.9679\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1914 - accuracy: 0.9480 - val_loss: 0.1979 - val_accuracy: 0.9513\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.4254 - accuracy: 0.89\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.1658 - accuracy: 0.95\n",
      " 610/1000 [=================>............] - ETA: 1s - loss: 0.1791 - accuracy: 0.9515Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.4195 - accuracy: 0.8978 - val_loss: 0.3359 - val_accuracy: 0.9287\n",
      "Epoch 2/50\n",
      " 178/1000 [====>.........................] - ETA: 3s - loss: 0.2951 - accuracy: 0.9364Epoch 1/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1897 - accuracy: 0.9509 - val_loss: 0.3956 - val_accuracy: 0.9387\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2478 - accuracy: 0.9360 - val_loss: 0.2246 - val_accuracy: 0.9430\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 6ms/step - loss: 0.4416 - accuracy: 0.8987 - val_loss: 0.2130 - val_accuracy: 0.9407\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2096 - accuracy: 0.9509 - val_loss: 0.2439 - val_accuracy: 0.9542\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.5464 - accuracy: 0.8435 - val_loss: 0.2411 - val_accuracy: 0.9325\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2037 - accuracy: 0.9463 - val_loss: 0.2229 - val_accuracy: 0.9510\n",
      " 903/1000 [==========================>...] - ETA: 0s - loss: 0.2053 - accuracy: 0.9430Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2091 - accuracy: 0.9423 - val_loss: 0.2499 - val_accuracy: 0.9441\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1668 - accuracy: 0.9590 - val_loss: 0.2742 - val_accuracy: 0.9491\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2005 - accuracy: 0.9402 - val_loss: 0.1820 - val_accuracy: 0.9489\n",
      " 596/1000 [================>.............] - ETA: 2s - loss: 0.2012 - accuracy: 0.9462Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1856 - accuracy: 0.9528 - val_loss: 0.1945 - val_accuracy: 0.9556\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2180 - accuracy: 0.9431 - val_loss: 0.2182 - val_accuracy: 0.9526\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1572 - accuracy: 0.9609 - val_loss: 0.2930 - val_accuracy: 0.9507\n",
      " 803/1000 [=======================>......] - ETA: 1s - loss: 0.1392 - accuracy: 0.9587Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1363 - accuracy: 0.9595 - val_loss: 0.1575 - val_accuracy: 0.9559\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1739 - accuracy: 0.9560 - val_loss: 0.2391 - val_accuracy: 0.9561\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1867 - accuracy: 0.9501 - val_loss: 0.2113 - val_accuracy: 0.9518\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1740 - accuracy: 0.9610 - val_loss: 0.3801 - val_accuracy: 0.9433\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.1701 - accuracy: 0.95\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0988 - accuracy: 0.9709 - val_loss: 0.1519 - val_accuracy: 0.9598\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1805 - accuracy: 0.9562 - val_loss: 0.2624 - val_accuracy: 0.9503\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1751 - accuracy: 0.9556 - val_loss: 0.2120 - val_accuracy: 0.9546\n",
      "Epoch 6/50\n",
      " 224/1000 [=====>........................] - ETA: 3s - loss: 0.1382 - accuracy: 0.9653Epoch 1/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1572 - accuracy: 0.9613 - val_loss: 0.2590 - val_accuracy: 0.9533\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0742 - accuracy: 0.9776 - val_loss: 0.1453 - val_accuracy: 0.9601\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1633 - accuracy: 0.9588 - val_loss: 0.2980 - val_accuracy: 0.9501\n",
      " 394/1000 [==========>...................] - ETA: 3s - loss: 0.1544 - accuracy: 0.9648Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 9ms/step - loss: 0.5589 - accuracy: 0.8392 - val_loss: 0.2456 - val_accuracy: 0.9296\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1585 - accuracy: 0.9630 - val_loss: 0.5251 - val_accuracy: 0.9391\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.1358 - val_accuracy: 0.9647\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1609 - accuracy: 0.9601 - val_loss: 0.2493 - val_accuracy: 0.9527\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1543 - accuracy: 0.9644 - val_loss: 0.2496 - val_accuracy: 0.9546\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0409 - accuracy: 0.9883 - val_loss: 0.1437 - val_accuracy: 0.9636\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.2016 - accuracy: 0.9398 - val_loss: 0.1817 - val_accuracy: 0.9486\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1413 - accuracy: 0.95\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1460 - accuracy: 0.9645 - val_loss: 0.2556 - val_accuracy: 0.9548\n",
      "Epoch 9/50\n",
      " 683/1000 [===================>..........] - ETA: 1s - loss: 0.1393 - accuracy: 0.9570Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0322 - accuracy: 0.9913 - val_loss: 0.1409 - val_accuracy: 0.9663\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1374 - accuracy: 0.9568 - val_loss: 0.1650 - val_accuracy: 0.9539\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1635 - accuracy: 0.9629 - val_loss: 0.2785 - val_accuracy: 0.9553\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0996 - accuracy: 0.96\n",
      " 955/1000 [===========================>..] - ETA: 0s - loss: 0.0999 - accuracy: 0.9692Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.5471 - accuracy: 0.8439 - val_loss: 0.2516 - val_accuracy: 0.9274\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0231 - accuracy: 0.9938 - val_loss: 0.1502 - val_accuracy: 0.9674\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0999 - accuracy: 0.9693 - val_loss: 0.1531 - val_accuracy: 0.9591\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2034 - accuracy: 0.9397 - val_loss: 0.1896 - val_accuracy: 0.9463\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.1525 - val_accuracy: 0.9680\n",
      "   1/1000 [..............................] - ETA: 5s - loss: 0.0952 - accuracy: 0.9688Epoch 11/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0760 - accuracy: 0.9767 - val_loss: 0.1443 - val_accuracy: 0.9603\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 9ms/step - loss: 0.3554 - accuracy: 0.8962 - val_loss: 0.1971 - val_accuracy: 0.9468\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1367 - accuracy: 0.9590 - val_loss: 0.1665 - val_accuracy: 0.9543\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.1729 - val_accuracy: 0.9630\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0561 - accuracy: 0.9837 - val_loss: 0.1440 - val_accuracy: 0.9634\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1264 - accuracy: 0.9616 - val_loss: 0.1529 - val_accuracy: 0.9593\n",
      "104/500 [=====>........................] - ETA: 1sEpoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0400 - accuracy: 0.98\n",
      " 734/1000 [=====================>........] - ETA: 1s - loss: 0.0817 - accuracy: 0.9745Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1031 - accuracy: 0.9694 - val_loss: 0.1531 - val_accuracy: 0.9585\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0425 - accuracy: 0.9880 - val_loss: 0.1454 - val_accuracy: 0.9636\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0815 - accuracy: 0.9744 - val_loss: 0.1461 - val_accuracy: 0.9633\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0753 - accuracy: 0.9778 - val_loss: 0.1473 - val_accuracy: 0.9600\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 0.1491 - val_accuracy: 0.9647\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 8ms/step - loss: 0.3509 - accuracy: 0.8962 - val_loss: 0.1842 - val_accuracy: 0.9493\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0537 - accuracy: 0.9822 - val_loss: 0.1415 - val_accuracy: 0.9643\n",
      " 170/1000 [====>.........................] - ETA: 5s - loss: 0.0573 - accuracy: 0.9820Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0583 - accuracy: 0.9826 - val_loss: 0.1472 - val_accuracy: 0.9620\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0237 - accuracy: 0.9935 - val_loss: 0.1525 - val_accuracy: 0.9653\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1332 - accuracy: 0.9599 - val_loss: 0.1465 - val_accuracy: 0.9585\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 0.1773 - val_accuracy: 0.9593\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0429 - accuracy: 0.9880 - val_loss: 0.1466 - val_accuracy: 0.9632\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0175 - accuracy: 0.9955 - val_loss: 0.1641 - val_accuracy: 0.9642\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0788 - accuracy: 0.9749 - val_loss: 0.1435 - val_accuracy: 0.9622\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.1535 - val_accuracy: 0.9652\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0315 - accuracy: 0.9914 - val_loss: 0.1541 - val_accuracy: 0.9643\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.1707 - val_accuracy: 0.9653\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 0.1528 - val_accuracy: 0.9622\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.1836 - val_accuracy: 0.9616\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0333 - accuracy: 0.99\n",
      " 866/1000 [========================>.....] - ETA: 0s - loss: 0.0220 - accuracy: 0.9925Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0263 - accuracy: 0.9932 - val_loss: 0.1580 - val_accuracy: 0.9667\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.1556 - val_accuracy: 0.9658\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.1825 - val_accuracy: 0.9647\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.1600 - val_accuracy: 0.9679\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.1705 - val_accuracy: 0.9644\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.1962 - val_accuracy: 0.9637\n",
      "1000/1000 [==============================] - 11s 9ms/step - loss: 0.3547 - accuracy: 0.8964 - val_loss: 0.1782 - val_accuracy: 0.9497\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0261 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.1684 - val_accuracy: 0.9673\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.1791 - val_accuracy: 0.9653\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1311 - accuracy: 0.9605 - val_loss: 0.1506 - val_accuracy: 0.9573\n",
      "Epoch 3/50\n",
      "  19/1000 [..............................] - ETA: 9s - loss: 0.0848 - accuracy: 0.9655Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.1829 - val_accuracy: 0.9664\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.1567 - val_accuracy: 0.9720\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0845 - accuracy: 0.9742 - val_loss: 0.1409 - val_accuracy: 0.9613\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0518 - accuracy: 0.98\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0524 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 11s 8ms/step - loss: 0.2964 - accuracy: 0.9128 - val_loss: 0.1726 - val_accuracy: 0.9513\n",
      "Epoch 2/50\n",
      " 990/1000 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9826Epoch 1/50\n",
      " 463/1000 [============>.................] - ETA: 5s - loss: 0.1264 - accuracy: 0.9621Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.1472 - val_accuracy: 0.9641\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1306 - accuracy: 0.9612 - val_loss: 0.1533 - val_accuracy: 0.9553\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.1468 - val_accuracy: 0.9647\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 14s 11ms/step - loss: 0.2928 - accuracy: 0.9142 - val_loss: 0.1765 - val_accuracy: 0.9499\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 15s 11ms/step - loss: 0.2911 - accuracy: 0.9143 - val_loss: 0.1777 - val_accuracy: 0.9527\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0968 - accuracy: 0.9707 - val_loss: 0.1653 - val_accuracy: 0.9627\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.1533 - val_accuracy: 0.9653\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1295 - accuracy: 0.9614 - val_loss: 0.1602 - val_accuracy: 0.9558\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0789 - accuracy: 0.9776 - val_loss: 0.1458 - val_accuracy: 0.9637\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1278 - accuracy: 0.9617 - val_loss: 0.1418 - val_accuracy: 0.9603\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.1637 - val_accuracy: 0.9646\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0588 - accuracy: 0.9818 - val_loss: 0.1501 - val_accuracy: 0.9665\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0967 - accuracy: 0.9711 - val_loss: 0.1577 - val_accuracy: 0.9627\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0954 - accuracy: 0.9709 - val_loss: 0.1407 - val_accuracy: 0.9637\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.1671 - val_accuracy: 0.9676\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0568 - accuracy: 0.9836 - val_loss: 0.1612 - val_accuracy: 0.9622\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0784 - accuracy: 0.9767 - val_loss: 0.1910 - val_accuracy: 0.9606\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0761 - accuracy: 0.9782 - val_loss: 0.1624 - val_accuracy: 0.9603\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0650 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0492 - accuracy: 0.9854 - val_loss: 0.1802 - val_accuracy: 0.9652\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0669 - accuracy: 0.9805 - val_loss: 0.1731 - val_accuracy: 0.9614\n",
      "Epoch 6/50\n",
      "  43/1000 [>.............................] - ETA: 4s - loss: 0.0318 - accuracy: 0.9869Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0690 - accuracy: 0.9797 - val_loss: 0.1605 - val_accuracy: 0.9655\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0544 - accuracy: 0.9845 - val_loss: 0.2004 - val_accuracy: 0.9665\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0535 - accuracy: 0.9841 - val_loss: 0.1658 - val_accuracy: 0.9643\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0535 - accuracy: 0.9846 - val_loss: 0.1979 - val_accuracy: 0.9585\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 9ms/step - loss: 0.3871 - accuracy: 0.8989 - val_loss: 0.2840 - val_accuracy: 0.9321\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0440 - accuracy: 0.9879 - val_loss: 0.2070 - val_accuracy: 0.9647\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.1893 - val_accuracy: 0.9629\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0487 - accuracy: 0.9868 - val_loss: 0.1504 - val_accuracy: 0.9667\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2574 - accuracy: 0.9380 - val_loss: 0.2661 - val_accuracy: 0.9458\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0422 - accuracy: 0.98\n",
      " 512/1000 [==============>...............] - ETA: 2s - loss: 0.2062 - accuracy: 0.9514Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0482 - accuracy: 0.9870 - val_loss: 0.1889 - val_accuracy: 0.9659\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.4823 - accuracy: 0.86\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2040 - accuracy: 0.9504 - val_loss: 0.3037 - val_accuracy: 0.9494\n",
      "Epoch 4/50\n",
      " 742/1000 [=====================>........] - ETA: 1s - loss: 0.4154 - accuracy: 0.8921Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 6ms/step - loss: 0.4010 - accuracy: 0.8996 - val_loss: 0.2591 - val_accuracy: 0.9333\n",
      " 348/1000 [=========>....................] - ETA: 3s - loss: 0.4863 - accuracy: 0.8662Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2196 - accuracy: 0.9517 - val_loss: 0.2336 - val_accuracy: 0.9538\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 7ms/step - loss: 0.3711 - accuracy: 0.9006 - val_loss: 0.3028 - val_accuracy: 0.9321\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2215 - accuracy: 0.9417 - val_loss: 0.2592 - val_accuracy: 0.9409\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1745 - accuracy: 0.9612 - val_loss: 0.2894 - val_accuracy: 0.9501\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2482 - accuracy: 0.9412 - val_loss: 0.3223 - val_accuracy: 0.9430\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1499 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.2032 - accuracy: 0.9504 - val_loss: 0.2355 - val_accuracy: 0.9483\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1499 - accuracy: 0.9638 - val_loss: 0.2640 - val_accuracy: 0.9564\n",
      "Epoch 7/50\n",
      " 608/1000 [=================>............] - ETA: 2s - loss: 0.2061 - accuracy: 0.9512Epoch 1/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2043 - accuracy: 0.9509 - val_loss: 0.2449 - val_accuracy: 0.9482\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1817 - accuracy: 0.9553 - val_loss: 0.3068 - val_accuracy: 0.9443\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1511 - accuracy: 0.9641 - val_loss: 0.3947 - val_accuracy: 0.9541\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 12s 10ms/step - loss: 0.5330 - accuracy: 0.8436 - val_loss: 0.2379 - val_accuracy: 0.9345\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1923 - accuracy: 0.9542 - val_loss: 0.3262 - val_accuracy: 0.9425\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1688 - accuracy: 0.9585 - val_loss: 0.2216 - val_accuracy: 0.9512\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1458 - accuracy: 0.9661 - val_loss: 0.3661 - val_accuracy: 0.9476\n",
      " 605/1000 [=================>............] - ETA: 2s - loss: 0.1677 - accuracy: 0.9608Epoch 9/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1643 - accuracy: 0.9607 - val_loss: 0.2540 - val_accuracy: 0.9528\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1846 - accuracy: 0.9454 - val_loss: 0.1843 - val_accuracy: 0.9513\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1766 - accuracy: 0.9590 - val_loss: 0.2661 - val_accuracy: 0.9505\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1372 - accuracy: 0.9679 - val_loss: 0.4653 - val_accuracy: 0.9582\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1570 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1454 - accuracy: 0.9665 - val_loss: 0.2779 - val_accuracy: 0.9524\n",
      "Epoch 7/50\n",
      " 196/1000 [====>.........................] - ETA: 4s - loss: 0.1231 - accuracy: 0.9708Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1198 - accuracy: 0.9641 - val_loss: 0.1702 - val_accuracy: 0.9555\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1637 - accuracy: 0.9629 - val_loss: 0.2568 - val_accuracy: 0.9513\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1296 - accuracy: 0.9694 - val_loss: 0.2503 - val_accuracy: 0.9596\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0843 - accuracy: 0.9744 - val_loss: 0.1568 - val_accuracy: 0.9602\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1264 - accuracy: 0.9696 - val_loss: 0.2816 - val_accuracy: 0.9592\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 12s 10ms/step - loss: 0.5387 - accuracy: 0.8465 - val_loss: 0.2249 - val_accuracy: 0.9339\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1347 - accuracy: 0.9672 - val_loss: 0.2807 - val_accuracy: 0.9563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1296 - accuracy: 0.9678 - val_loss: 0.3287 - val_accuracy: 0.9564\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0559 - accuracy: 0.982\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0606 - accuracy: 0.9816 - val_loss: 0.1621 - val_accuracy: 0.9603\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1793 - accuracy: 0.9462 - val_loss: 0.1778 - val_accuracy: 0.9498\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1338 - accuracy: 0.9697 - val_loss: 0.2728 - val_accuracy: 0.9622\n",
      " 681/1000 [===================>..........] - ETA: 1s - loss: 0.1155 - accuracy: 0.9651Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0431 - accuracy: 0.9871 - val_loss: 0.1646 - val_accuracy: 0.9624\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1176 - accuracy: 0.9641 - val_loss: 0.1677 - val_accuracy: 0.9544\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.1779 - val_accuracy: 0.9622\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0824 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 10s 8ms/step - loss: 0.5369 - accuracy: 0.8468 - val_loss: 0.2275 - val_accuracy: 0.9354\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0824 - accuracy: 0.9748 - val_loss: 0.1655 - val_accuracy: 0.9585\n",
      " 547/1000 [===============>..............] - ETA: 3s - loss: 0.0254 - accuracy: 0.9933Epoch 5/50\n",
      " 658/1000 [==================>...........] - ETA: 2s - loss: 0.0252 - accuracy: 0.9929Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.1697 - val_accuracy: 0.9662\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1858 - accuracy: 0.9454 - val_loss: 0.1802 - val_accuracy: 0.9482\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0592 - accuracy: 0.9826 - val_loss: 0.1563 - val_accuracy: 0.9607\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 14s 11ms/step - loss: 0.3532 - accuracy: 0.8969 - val_loss: 0.1815 - val_accuracy: 0.9475\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.1786 - val_accuracy: 0.9657\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1259 - accuracy: 0.9628 - val_loss: 0.1613 - val_accuracy: 0.9555\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0419 - accuracy: 0.9871 - val_loss: 0.1604 - val_accuracy: 0.9630\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1259 - accuracy: 0.9610 - val_loss: 0.1654 - val_accuracy: 0.9548\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 7s 4ms/step loss: 0.0305 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0889 - accuracy: 0.9742 - val_loss: 0.1542 - val_accuracy: 0.9576\n",
      "Epoch 5/50\n",
      " 530/1000 [==============>...............] - ETA: 2s - loss: 0.0768 - accuracy: 0.9741Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 0.1727 - val_accuracy: 0.9632\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0787 - accuracy: 0.9743 - val_loss: 0.1504 - val_accuracy: 0.9629\n",
      " 866/1000 [========================>.....] - ETA: 0s - loss: 0.0639 - accuracy: 0.9820Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0652 - accuracy: 0.9818 - val_loss: 0.1418 - val_accuracy: 0.9624\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.1971 - val_accuracy: 0.9618\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 12s 11ms/step - loss: 0.3571 - accuracy: 0.8952 - val_loss: 0.1924 - val_accuracy: 0.9436\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.1512 - val_accuracy: 0.9634\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0465 - accuracy: 0.9867 - val_loss: 0.1543 - val_accuracy: 0.9611\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.1917 - val_accuracy: 0.9640\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1237 - accuracy: 0.9611 - val_loss: 0.1433 - val_accuracy: 0.9578\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.1576 - val_accuracy: 0.9654\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.1573 - val_accuracy: 0.9638\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.2090 - val_accuracy: 0.9646\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0782 - accuracy: 0.9750 - val_loss: 0.1560 - val_accuracy: 0.9599\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0311 - accuracy: 0.9899 - val_loss: 0.1906 - val_accuracy: 0.9643\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0249 - accuracy: 0.9930 - val_loss: 0.1613 - val_accuracy: 0.9645\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step loss: 0.0499 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0520 - accuracy: 0.9842 - val_loss: 0.1377 - val_accuracy: 0.9644\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.1771 - val_accuracy: 0.9652\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.1776 - val_accuracy: 0.9619\n",
      "Epoch 10/50\n",
      " 774/1000 [======================>.......] - ETA: 1s - loss: 0.0217 - accuracy: 0.9934Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0413 - accuracy: 0.9871 - val_loss: 0.1514 - val_accuracy: 0.9652\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.1684 - val_accuracy: 0.9663\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.1798 - val_accuracy: 0.9653\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0321 - accuracy: 0.98\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.3501 - accuracy: 0.89\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.1526 - val_accuracy: 0.9668\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.8980Epoch 7/50\n",
      "  42/1000 [>.............................] - ETA: 5s - loss: 0.0197 - accuracy: 0.9948Epoch 1/50\n",
      "1000/1000 [==============================] - 12s 9ms/step - loss: 0.3440 - accuracy: 0.8980 - val_loss: 0.1778 - val_accuracy: 0.9503\n",
      "Epoch 2/50\n",
      "  14/1000 [..............................] - ETA: 7s - loss: 1.8160 - accuracy: 0.4040Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.1579 - val_accuracy: 0.9659\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1260 - accuracy: 0.9619 - val_loss: 0.1594 - val_accuracy: 0.9551\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 11ms/step - loss: 0.3022 - accuracy: 0.9112 - val_loss: 0.1967 - val_accuracy: 0.9477\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 13s 11ms/step - loss: 0.3086 - accuracy: 0.9075 - val_loss: 0.1687 - val_accuracy: 0.9528\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.1739 - val_accuracy: 0.9655\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0769 - accuracy: 0.9758 - val_loss: 0.1477 - val_accuracy: 0.9613\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1418 - accuracy: 0.9571 - val_loss: 0.1754 - val_accuracy: 0.9523\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1410 - accuracy: 0.9596 - val_loss: 0.1671 - val_accuracy: 0.9585\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.1466 - val_accuracy: 0.9692\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 0.1463 - val_accuracy: 0.9632\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1046 - accuracy: 0.9681 - val_loss: 0.1928 - val_accuracy: 0.9536\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0643 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1018 - accuracy: 0.9693 - val_loss: 0.1749 - val_accuracy: 0.9563\n",
      "Epoch 4/50\n",
      " 231/1000 [=====>........................] - ETA: 5s - loss: 0.0722 - accuracy: 0.9771Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.1503 - val_accuracy: 0.9647\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0858 - accuracy: 0.9746 - val_loss: 0.2137 - val_accuracy: 0.9628\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0823 - accuracy: 0.9750 - val_loss: 0.1492 - val_accuracy: 0.9634\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 13s 11ms/step - loss: 0.3037 - accuracy: 0.9091 - val_loss: 0.2328 - val_accuracy: 0.9308\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.1624 - val_accuracy: 0.9638\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0742 - accuracy: 0.9792 - val_loss: 0.1964 - val_accuracy: 0.9592\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0699 - accuracy: 0.9786 - val_loss: 0.1855 - val_accuracy: 0.9613\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1429 - accuracy: 0.9579 - val_loss: 0.1695 - val_accuracy: 0.9506\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.1688 - val_accuracy: 0.9646\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0607 - accuracy: 0.9826 - val_loss: 0.1924 - val_accuracy: 0.9623\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0629 - accuracy: 0.9813 - val_loss: 0.1772 - val_accuracy: 0.9612\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1020 - accuracy: 0.9700 - val_loss: 0.1842 - val_accuracy: 0.9525\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.1714 - val_accuracy: 0.9653\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0517 - accuracy: 0.9858 - val_loss: 0.1902 - val_accuracy: 0.9608\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0566 - accuracy: 0.9841 - val_loss: 0.1717 - val_accuracy: 0.9672\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0871 - accuracy: 0.9752 - val_loss: 0.1685 - val_accuracy: 0.9615\n",
      " 697/1000 [===================>..........] - ETA: 2s - loss: 0.0497 - accuracy: 0.9860Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.1724 - val_accuracy: 0.9656\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0498 - accuracy: 0.9860 - val_loss: 0.2142 - val_accuracy: 0.9612\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0542 - accuracy: 0.9852 - val_loss: 0.1968 - val_accuracy: 0.9618\n",
      "  16/1000 [..............................] - ETA: 7s - loss: 0.0738 - accuracy: 0.9785Epoch 9/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0641 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0681 - accuracy: 0.9801 - val_loss: 0.1469 - val_accuracy: 0.9630\n",
      "Epoch 6/50\n",
      " 959/1000 [===========================>..] - ETA: 0s - loss: 0.0409 - accuracy: 0.9890Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.1874 - val_accuracy: 0.9653\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.2046 - val_accuracy: 0.9677\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.4751 - accuracy: 0.86\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0648 - accuracy: 0.9816 - val_loss: 0.1697 - val_accuracy: 0.9609\n",
      "Epoch 7/50\n",
      " 227/1000 [=====>........................] - ETA: 4s - loss: 0.0458 - accuracy: 0.9872Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 8ms/step - loss: 0.3864 - accuracy: 0.8983 - val_loss: 0.2593 - val_accuracy: 0.9332\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0456 - accuracy: 0.9873 - val_loss: 0.1795 - val_accuracy: 0.9668\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0541 - accuracy: 0.9850 - val_loss: 0.1760 - val_accuracy: 0.9631\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2477 - accuracy: 0.9389 - val_loss: 0.2176 - val_accuracy: 0.9491\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0417 - accuracy: 0.9898 - val_loss: 0.2268 - val_accuracy: 0.9659\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 9s 8ms/step - loss: 0.4000 - accuracy: 0.8970 - val_loss: 0.2781 - val_accuracy: 0.9362\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0488 - accuracy: 0.9868 - val_loss: 0.1617 - val_accuracy: 0.9690\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2153 - accuracy: 0.9479 - val_loss: 0.2688 - val_accuracy: 0.9378\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0418 - accuracy: 0.9892 - val_loss: 0.2020 - val_accuracy: 0.9697\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2407 - accuracy: 0.9385 - val_loss: 0.2395 - val_accuracy: 0.9449\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.1877 - accuracy: 0.95\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0392 - accuracy: 0.9887 - val_loss: 0.1961 - val_accuracy: 0.9631\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1964 - accuracy: 0.9540 - val_loss: 0.2579 - val_accuracy: 0.9473\n",
      "Epoch 5/50\n",
      "  53/1000 [>.............................] - ETA: 5s - loss: 0.1399 - accuracy: 0.9652Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2110 - accuracy: 0.9503 - val_loss: 0.2463 - val_accuracy: 0.9448\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0455 - accuracy: 0.9882 - val_loss: 0.1763 - val_accuracy: 0.9681\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1828 - accuracy: 0.9607 - val_loss: 0.3116 - val_accuracy: 0.9429\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1953 - accuracy: 0.9542 - val_loss: 0.2654 - val_accuracy: 0.9447\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.2191 - accuracy: 0.95\n",
      " 825/1000 [=======================>......] - ETA: 1s - loss: 0.1738 - accuracy: 0.9616Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1752 - accuracy: 0.9607 - val_loss: 0.2941 - val_accuracy: 0.9517\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 18s 10ms/step - loss: 0.3857 - accuracy: 0.8982 - val_loss: 0.2854 - val_accuracy: 0.9236\n",
      " 148/1000 [===>..........................] - ETA: 7s - loss: 0.1550 - accuracy: 0.9681Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1906 - accuracy: 0.9591 - val_loss: 0.2646 - val_accuracy: 0.9482\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 14s 12ms/step - loss: 0.4463 - accuracy: 0.8756 - val_loss: 0.2122 - val_accuracy: 0.9403\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1528 - accuracy: 0.9648 - val_loss: 0.2481 - val_accuracy: 0.9570\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2502 - accuracy: 0.9376 - val_loss: 0.2810 - val_accuracy: 0.9332\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1640 - accuracy: 0.9647 - val_loss: 0.2823 - val_accuracy: 0.9561\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.1684 - accuracy: 0.96\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 0.9482Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1760 - accuracy: 0.9624 - val_loss: 0.2961 - val_accuracy: 0.9466\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.2164 - accuracy: 0.9480 - val_loss: 0.2060 - val_accuracy: 0.9490\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1739 - accuracy: 0.9483 - val_loss: 0.1748 - val_accuracy: 0.9523\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 5ms/step loss: 0.6437 - accuracy: 0.81\n",
      " 936/1000 [===========================>..] - ETA: 0s - loss: 0.1164 - accuracy: 0.9665Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1884 - accuracy: 0.9558 - val_loss: 0.3107 - val_accuracy: 0.9478\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.1172 - accuracy: 0.9663 - val_loss: 0.1528 - val_accuracy: 0.9588\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 9ms/step - loss: 0.4493 - accuracy: 0.8732 - val_loss: 0.2206 - val_accuracy: 0.9372\n",
      " 154/1000 [===>..........................] - ETA: 6s - loss: 1.0587 - accuracy: 0.7027Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1917 - accuracy: 0.9573 - val_loss: 0.2214 - val_accuracy: 0.9414\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0853 - accuracy: 0.9753 - val_loss: 0.1421 - val_accuracy: 0.9634\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 13s 12ms/step - loss: 0.4406 - accuracy: 0.8747 - val_loss: 0.2320 - val_accuracy: 0.9339\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1749 - accuracy: 0.9482 - val_loss: 0.1787 - val_accuracy: 0.9503\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1599 - accuracy: 0.9643 - val_loss: 0.2354 - val_accuracy: 0.9537\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.1383 - val_accuracy: 0.9640\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1750 - accuracy: 0.9477 - val_loss: 0.1772 - val_accuracy: 0.9512\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1134 - accuracy: 0.9666 - val_loss: 0.1508 - val_accuracy: 0.9573\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1466 - accuracy: 0.9664 - val_loss: 0.3559 - val_accuracy: 0.9504\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0449 - accuracy: 0.9874 - val_loss: 0.1356 - val_accuracy: 0.9669\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1191 - accuracy: 0.9651 - val_loss: 0.1580 - val_accuracy: 0.9591\n",
      "  65/1000 [>.............................] - ETA: 7s - loss: 0.1602 - accuracy: 0.9659Epoch 4/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0824 - accuracy: 0.9761 - val_loss: 0.1469 - val_accuracy: 0.9614\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1588 - accuracy: 0.9653 - val_loss: 0.3505 - val_accuracy: 0.9494\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0358 - accuracy: 0.9908 - val_loss: 0.1435 - val_accuracy: 0.9649\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0857 - accuracy: 0.9762 - val_loss: 0.1447 - val_accuracy: 0.9630\n",
      "  26/1000 [..............................] - ETA: 6s - loss: 0.0285 - accuracy: 0.9928Epoch 5/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0581 - accuracy: 0.9833 - val_loss: 0.1368 - val_accuracy: 0.9643\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 4s 6ms/step loss: 0.0433 - accuracy: 0.98\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9884Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.1337 - val_accuracy: 0.9680\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0623 - accuracy: 0.9824 - val_loss: 0.1447 - val_accuracy: 0.9626\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0438 - accuracy: 0.9884 - val_loss: 0.1339 - val_accuracy: 0.9649\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.1356 - val_accuracy: 0.9697\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0460 - accuracy: 0.9868 - val_loss: 0.1423 - val_accuracy: 0.9656\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0336 - accuracy: 0.9914 - val_loss: 0.1354 - val_accuracy: 0.9654\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 17s 14ms/step - loss: 0.3118 - accuracy: 0.9109 - val_loss: 0.1854 - val_accuracy: 0.9527\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0143 - accuracy: 0.9972 - val_loss: 0.1388 - val_accuracy: 0.9688\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0355 - accuracy: 0.9902 - val_loss: 0.1391 - val_accuracy: 0.9651\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.1336 - val_accuracy: 0.9669\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1158 - accuracy: 0.9643 - val_loss: 0.1611 - val_accuracy: 0.9573\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0238 - accuracy: 0.9943 - val_loss: 0.1347 - val_accuracy: 0.9685\n",
      " 793/1000 [======================>.......] - ETA: 2s - loss: 0.0715 - accuracy: 0.9777Epoch 9/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.1446 - val_accuracy: 0.9695\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.1428 - val_accuracy: 0.9669\n",
      " 184/1000 [====>.........................] - ETA: 6s - loss: 0.0060 - accuracy: 0.9988Epoch 10/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0742 - accuracy: 0.9773 - val_loss: 0.1358 - val_accuracy: 0.9632\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.1425 - val_accuracy: 0.9683\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.1586 - val_accuracy: 0.9690\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.1417 - val_accuracy: 0.9686\n",
      " 205/1000 [=====>........................] - ETA: 8s - loss: 0.0134 - accuracy: 0.9968Epoch 11/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0511 - accuracy: 0.9838 - val_loss: 0.1498 - val_accuracy: 0.9644\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1498 - val_accuracy: 0.9711\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.1476 - val_accuracy: 0.9678\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.1637 - val_accuracy: 0.9650\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 0.1430 - val_accuracy: 0.9678\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.0093 - accuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 655/1000 [==================>...........] - ETA: 3s - loss: 0.0247 - accuracy: 0.9925Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.1574 - val_accuracy: 0.9663\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.1528 - val_accuracy: 0.9697\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.1916 - val_accuracy: 0.9628\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.1663 - val_accuracy: 0.9671\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.1716 - val_accuracy: 0.9705\n",
      "1000/1000 [==============================] - 14s 12ms/step - loss: 0.3135 - accuracy: 0.9087 - val_loss: 0.2077 - val_accuracy: 0.9502\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0294 - accuracy: 0.9910 - val_loss: 0.1573 - val_accuracy: 0.9686\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.0206 - accuracy: 0.99\n",
      " 755/1000 [=====================>........] - ETA: 2s - loss: 0.0165 - accuracy: 0.9953Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.1635 - val_accuracy: 0.9690\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1211 - accuracy: 0.9633 - val_loss: 0.1714 - val_accuracy: 0.9602\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.2153 - val_accuracy: 0.9663\n",
      "500/500 [==============================] - 2s 5ms/step loss: 0.5428 - accuracy: 0.84\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0743 - accuracy: 0.97\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9784Epoch 1/50\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0725 - accuracy: 0.9783 - val_loss: 0.1762 - val_accuracy: 0.9602\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 10s 9ms/step - loss: 0.3093 - accuracy: 0.9108 - val_loss: 0.1740 - val_accuracy: 0.9517\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0526 - accuracy: 0.9836 - val_loss: 0.1593 - val_accuracy: 0.9673\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1189 - accuracy: 0.9644 - val_loss: 0.1520 - val_accuracy: 0.9608\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 12ms/step - loss: 0.3057 - accuracy: 0.9161 - val_loss: 0.1733 - val_accuracy: 0.9522\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 13s 12ms/step - loss: 0.3117 - accuracy: 0.9154 - val_loss: 0.1595 - val_accuracy: 0.9541\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.1681 - val_accuracy: 0.9667\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1459 - accuracy: 0.9578 - val_loss: 0.1777 - val_accuracy: 0.9547\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0733 - accuracy: 0.9778 - val_loss: 0.1522 - val_accuracy: 0.9613\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1409 - accuracy: 0.9581 - val_loss: 0.1724 - val_accuracy: 0.9533\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.1621 - val_accuracy: 0.9689\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1153 - accuracy: 0.9675 - val_loss: 0.1819 - val_accuracy: 0.9603\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0521 - accuracy: 0.9844 - val_loss: 0.1493 - val_accuracy: 0.9645\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1121 - accuracy: 0.9698 - val_loss: 0.2241 - val_accuracy: 0.9607\n",
      " 269/1000 [=======>......................] - ETA: 10s - loss: 0.0186 - accuracy: 0.9947Epoch 4/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.1998 - val_accuracy: 0.9657\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0937 - accuracy: 0.9735 - val_loss: 0.2665 - val_accuracy: 0.9603\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0359 - accuracy: 0.9898 - val_loss: 0.1551 - val_accuracy: 0.9655\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1008 - accuracy: 0.9722 - val_loss: 0.1589 - val_accuracy: 0.9633\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.2236 - val_accuracy: 0.9606\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0847 - accuracy: 0.9764 - val_loss: 0.2312 - val_accuracy: 0.9628\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.1696 - val_accuracy: 0.9672\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0914 - accuracy: 0.9762 - val_loss: 0.2243 - val_accuracy: 0.9615\n",
      " 175/1000 [====>.........................] - ETA: 8s - loss: 0.1744 - accuracy: 0.9691Epoch 6/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1036 - accuracy: 0.9768 - val_loss: 0.2452 - val_accuracy: 0.9596\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.1696 - val_accuracy: 0.9688\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.1851 - val_accuracy: 0.9670\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0705 - accuracy: 0.9809 - val_loss: 0.1676 - val_accuracy: 0.9651\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.0220 - accuracy: 0.99\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.0412 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.1704 - val_accuracy: 0.9683\n",
      "Epoch 9/50\n",
      " 221/1000 [=====>........................] - ETA: 5s - loss: 0.0111 - accuracy: 0.9965Epoch 1/50\n",
      " 243/1000 [======>.......................] - ETA: 5s - loss: 0.0111 - accuracy: 0.9961Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0604 - accuracy: 0.9831 - val_loss: 0.2588 - val_accuracy: 0.9595\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.1982 - val_accuracy: 0.9662\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0620 - accuracy: 0.9836 - val_loss: 0.2267 - val_accuracy: 0.9666\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0465 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 13s 12ms/step - loss: 0.5035 - accuracy: 0.8910 - val_loss: 0.2454 - val_accuracy: 0.9376\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 14s 11ms/step - loss: 0.3150 - accuracy: 0.9152 - val_loss: 0.2319 - val_accuracy: 0.9506\n",
      "Epoch 2/50\n",
      " 383/1000 [==========>...................] - ETA: 6s - loss: 0.2700 - accuracy: 0.9287Epoch 1/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0614 - accuracy: 0.9838 - val_loss: 0.2891 - val_accuracy: 0.9643\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.1417 - accuracy: 0.9603 - val_loss: 0.2090 - val_accuracy: 0.9556\n",
      "  1/500 [..............................] - ETA: 2:14Epoch 3/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.2700 - accuracy: 0.9309 - val_loss: 0.3349 - val_accuracy: 0.9342\n",
      "  16/1000 [..............................] - ETA: 6s - loss: 0.1143 - accuracy: 0.9609Epoch 3/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.2295 - accuracy: 0.94\n",
      " 869/1000 [=========================>....] - ETA: 1s - loss: 0.2479 - accuracy: 0.9378Epoch 1/50\n",
      "1000/1000 [==============================] - 14s 11ms/step - loss: 0.5097 - accuracy: 0.8931 - val_loss: 0.2404 - val_accuracy: 0.9373\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1067 - accuracy: 0.9689 - val_loss: 0.1720 - val_accuracy: 0.9582\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.2532 - accuracy: 0.9365 - val_loss: 0.2610 - val_accuracy: 0.9367\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2733 - accuracy: 0.9298 - val_loss: 0.2591 - val_accuracy: 0.9384\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0952 - accuracy: 0.9721 - val_loss: 0.2094 - val_accuracy: 0.9567\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.2611 - accuracy: 0.9387 - val_loss: 0.3059 - val_accuracy: 0.9353\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 12ms/step - loss: 0.4540 - accuracy: 0.8952 - val_loss: 0.2993 - val_accuracy: 0.9216\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2623 - accuracy: 0.9349 - val_loss: 0.2366 - val_accuracy: 0.9467\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0899 - accuracy: 0.9754 - val_loss: 0.1513 - val_accuracy: 0.9664\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2298 - accuracy: 0.9449 - val_loss: 0.2768 - val_accuracy: 0.9402\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2702 - accuracy: 0.9298 - val_loss: 0.2833 - val_accuracy: 0.9313\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2353 - accuracy: 0.9443 - val_loss: 0.3453 - val_accuracy: 0.9448\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0623 - accuracy: 0.9824 - val_loss: 0.2590 - val_accuracy: 0.9587\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2229 - accuracy: 0.9485 - val_loss: 0.4986 - val_accuracy: 0.9233\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2599 - accuracy: 0.9357 - val_loss: 0.2539 - val_accuracy: 0.9394\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 3s 5ms/step loss: 0.0656 - accuracy: 0.98\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 0.0753 - accuracy: 0.9804Epoch 1/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.2339 - accuracy: 0.9448 - val_loss: 0.2868 - val_accuracy: 0.9464\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 0.0735 - accuracy: 0.9807 - val_loss: 0.1956 - val_accuracy: 0.9680\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.2371 - accuracy: 0.9427 - val_loss: 0.3239 - val_accuracy: 0.9367\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2297 - accuracy: 0.9506 - val_loss: 0.3435 - val_accuracy: 0.9427\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0615 - accuracy: 0.9847 - val_loss: 0.1712 - val_accuracy: 0.9690\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2298 - accuracy: 0.9460 - val_loss: 0.3228 - val_accuracy: 0.9408\n",
      " 556/1000 [===============>..............] - ETA: 3s - loss: 0.1892 - accuracy: 0.9568Epoch 6/50\n",
      "1000/1000 [==============================] - 19s 16ms/step - loss: 0.4173 - accuracy: 0.8823 - val_loss: 0.2039 - val_accuracy: 0.9402\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.2004 - accuracy: 0.9552 - val_loss: 0.2632 - val_accuracy: 0.9473\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0479 - accuracy: 0.9866 - val_loss: 0.2084 - val_accuracy: 0.9659\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2059 - accuracy: 0.9524 - val_loss: 0.3772 - val_accuracy: 0.9458\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1556 - accuracy: 0.9532 - val_loss: 0.1550 - val_accuracy: 0.9569\n",
      " 906/1000 [==========================>...] - ETA: 0s - loss: 0.2083 - accuracy: 0.9527Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2081 - accuracy: 0.9527 - val_loss: 0.2677 - val_accuracy: 0.9532\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0517 - accuracy: 0.9874 - val_loss: 0.2031 - val_accuracy: 0.9676\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.0943 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.2405 - accuracy: 0.9508 - val_loss: 0.3826 - val_accuracy: 0.9497\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.2212 - accuracy: 0.95\n",
      " 422/1000 [===========>..................] - ETA: 3s - loss: 0.2182 - accuracy: 0.9518Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0943 - accuracy: 0.9721 - val_loss: 0.1566 - val_accuracy: 0.9589\n",
      "Epoch 4/50\n",
      "  35/1000 [>.............................] - ETA: 9s - loss: 1.9560 - accuracy: 0.3938Epoch 1/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.2108 - accuracy: 0.9540 - val_loss: 0.3096 - val_accuracy: 0.9517\n",
      "500/500 [==============================] - 5s 9ms/step loss: 0.4895 - accuracy: 0.86\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0636 - accuracy: 0.9813 - val_loss: 0.1390 - val_accuracy: 0.9645\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 15ms/step - loss: 0.4139 - accuracy: 0.8818 - val_loss: 0.2116 - val_accuracy: 0.9395\n",
      " 925/1000 [==========================>...] - ETA: 0s - loss: 0.4371 - accuracy: 0.8770Epoch 2/50\n",
      " 258/1000 [======>.......................] - ETA: 8s - loss: 0.0424 - accuracy: 0.9890Epoch 1/50\n",
      "1000/1000 [==============================] - 19s 16ms/step - loss: 0.4239 - accuracy: 0.8811 - val_loss: 0.2108 - val_accuracy: 0.9417\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 0.1550 - val_accuracy: 0.9620\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1499 - accuracy: 0.9548 - val_loss: 0.1802 - val_accuracy: 0.9550\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1570 - accuracy: 0.9546 - val_loss: 0.1660 - val_accuracy: 0.9537\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 23s 19ms/step - loss: 0.3016 - accuracy: 0.9120 - val_loss: 0.1816 - val_accuracy: 0.9461\n",
      " 315/1000 [========>.....................] - ETA: 9s - loss: 0.0982 - accuracy: 0.9719Epoch 2/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.1533 - val_accuracy: 0.9639\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0927 - accuracy: 0.9717 - val_loss: 0.1662 - val_accuracy: 0.9592\n",
      " 527/1000 [==============>...............] - ETA: 4s - loss: 0.1080 - accuracy: 0.9680Epoch 4/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0974 - accuracy: 0.9711 - val_loss: 0.1428 - val_accuracy: 0.9613\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1116 - accuracy: 0.9665 - val_loss: 0.1356 - val_accuracy: 0.9622\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0598 - accuracy: 0.9823 - val_loss: 0.1649 - val_accuracy: 0.9613\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.1570 - val_accuracy: 0.9652\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.1439 - val_accuracy: 0.9613\n",
      " 454/1000 [============>.................] - ETA: 6s - loss: 0.0429 - accuracy: 0.9882Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0682 - accuracy: 0.9785 - val_loss: 0.1707 - val_accuracy: 0.9593\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0421 - accuracy: 0.9873 - val_loss: 0.1662 - val_accuracy: 0.9653\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.1622 - val_accuracy: 0.9660\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0429 - accuracy: 0.9879 - val_loss: 0.1551 - val_accuracy: 0.9617\n",
      " 379/1000 [==========>...................] - ETA: 9s - loss: 0.0134 - accuracy: 0.9968Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0425 - accuracy: 0.9862 - val_loss: 0.1610 - val_accuracy: 0.9640\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 0.1653 - val_accuracy: 0.9624\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.1652 - val_accuracy: 0.9666\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0297 - accuracy: 0.9919 - val_loss: 0.1586 - val_accuracy: 0.9634\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.0203 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.1752 - val_accuracy: 0.9654\n",
      "Epoch 6/50\n",
      " 628/1000 [=================>............] - ETA: 4s - loss: 0.0190 - accuracy: 0.9950Epoch 1/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.1772 - val_accuracy: 0.9660\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.1552 - val_accuracy: 0.9695\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.1567 - val_accuracy: 0.9661\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.1884 - val_accuracy: 0.9656\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 19s 15ms/step - loss: 0.3017 - accuracy: 0.9136 - val_loss: 0.1908 - val_accuracy: 0.9486\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 0.2028 - val_accuracy: 0.9674\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.1588 - val_accuracy: 0.9670\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.1100 - accuracy: 0.96\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.1895 - val_accuracy: 0.9663\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1108 - accuracy: 0.96\n",
      "500/500 [==============================] - 2s 4ms/step loss: 0.1097 - ac\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1097 - accuracy: 0.9666 - val_loss: 0.1643 - val_accuracy: 0.9617\n",
      "Epoch 3/50\n",
      "  30/1000 [..............................] - ETA: 7s - loss: 0.0570 - accuracy: 0.9833Epoch 1/50\n",
      " 120/1000 [==>...........................] - ETA: 6s - loss: 0.0553 - accuracy: 0.9826Epoch 1/50\n",
      " 248/1000 [======>.......................] - ETA: 5s - loss: 0.0600 - accuracy: 0.9814Epoch 1/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0685 - accuracy: 0.9786 - val_loss: 0.1514 - val_accuracy: 0.9603\n",
      " 706/1000 [====================>.........] - ETA: 4s - loss: 0.3302 - accuracy: 0.9043Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 17ms/step - loss: 0.3024 - accuracy: 0.9145 - val_loss: 0.1643 - val_accuracy: 0.9530\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 19s 17ms/step - loss: 0.2952 - accuracy: 0.9155 - val_loss: 0.1927 - val_accuracy: 0.9475\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 21s 18ms/step - loss: 0.2962 - accuracy: 0.9142 - val_loss: 0.1974 - val_accuracy: 0.9448\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 16s 15ms/step - loss: 0.0448 - accuracy: 0.9853 - val_loss: 0.1606 - val_accuracy: 0.9649\n",
      " 936/1000 [===========================>..] - ETA: 0s - loss: 0.1106 - accuracy: 0.9670Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1107 - accuracy: 0.9668 - val_loss: 0.1446 - val_accuracy: 0.9613\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1428 - accuracy: 0.9580 - val_loss: 0.2231 - val_accuracy: 0.9506\n",
      " 144/1000 [===>..........................] - ETA: 12s - loss: 0.0538 - accuracy: 0.9835Epoch 3/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1432 - accuracy: 0.9582 - val_loss: 0.1961 - val_accuracy: 0.9531\n",
      " 409/1000 [===========>..................] - ETA: 8s - loss: 0.0559 - accuracy: 0.9822Epoch 3/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0401 - accuracy: 0.9871 - val_loss: 0.1576 - val_accuracy: 0.9670\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0708 - accuracy: 0.9783 - val_loss: 0.1387 - val_accuracy: 0.9615\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1101 - accuracy: 0.9688 - val_loss: 0.2156 - val_accuracy: 0.9550\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1050 - accuracy: 0.9694 - val_loss: 0.2029 - val_accuracy: 0.9524\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.1755 - val_accuracy: 0.9678\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 0.1392 - val_accuracy: 0.9651\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0859 - accuracy: 0.9754 - val_loss: 0.1713 - val_accuracy: 0.9612\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0905 - accuracy: 0.9744 - val_loss: 0.1762 - val_accuracy: 0.9570\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.1764 - val_accuracy: 0.9651\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0367 - accuracy: 0.9886 - val_loss: 0.1519 - val_accuracy: 0.9642\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0821 - accuracy: 0.9765 - val_loss: 0.1860 - val_accuracy: 0.9654\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0855 - accuracy: 0.9755 - val_loss: 0.1705 - val_accuracy: 0.9637\n",
      " 901/1000 [==========================>...] - ETA: 1s - loss: 0.0294 - accuracy: 0.9916Epoch 6/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 0.1571 - val_accuracy: 0.9673\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0297 - accuracy: 0.9902 - val_loss: 0.1625 - val_accuracy: 0.9607\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0743 - accuracy: 0.9806 - val_loss: 0.1704 - val_accuracy: 0.9640\n",
      " 768/1000 [======================>.......] - ETA: 2s - loss: 0.0657 - accuracy: 0.9816Epoch 7/50\n",
      "500/500 [==============================] - 5s 10ms/steploss: 0.0199 - accuracy: 0.998\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0686 - accuracy: 0.9807 - val_loss: 0.2119 - val_accuracy: 0.9671\n",
      " 496/1000 [=============>................] - ETA: 6s - loss: 0.0542 - accuracy: 0.9853Epoch 7/50\n",
      " 892/1000 [=========================>....] - ETA: 1s - loss: 0.0615 - accuracy: 0.9833Epoch 1/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.1395 - val_accuracy: 0.9683\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0610 - accuracy: 0.9832 - val_loss: 0.2196 - val_accuracy: 0.9647\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0549 - accuracy: 0.9846 - val_loss: 0.2402 - val_accuracy: 0.9575\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.1636 - val_accuracy: 0.9665\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0582 - accuracy: 0.9848 - val_loss: 0.2135 - val_accuracy: 0.9640\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 18s 16ms/step - loss: 0.2944 - accuracy: 0.9168 - val_loss: 0.1901 - val_accuracy: 0.9472\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 5s 10ms/steploss: 0.0502 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0631 - accuracy: 0.9840 - val_loss: 0.2372 - val_accuracy: 0.9609\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1445 - accuracy: 0.9577 - val_loss: 0.2785 - val_accuracy: 0.9326\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0528 - accuracy: 0.9860 - val_loss: 0.2088 - val_accuracy: 0.9686\n",
      "Epoch 10/50\n",
      " 451/1000 [============>.................] - ETA: 5s - loss: 0.1080 - accuracy: 0.9684Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0579 - accuracy: 0.9858 - val_loss: 0.2560 - val_accuracy: 0.9641\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1164 - accuracy: 0.9674 - val_loss: 0.1455 - val_accuracy: 0.9636\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0570 - accuracy: 0.9873 - val_loss: 0.1942 - val_accuracy: 0.9682\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0544 - accuracy: 0.9868 - val_loss: 0.2610 - val_accuracy: 0.9647\n",
      "1000/1000 [==============================] - 19s 15ms/step - loss: 0.5062 - accuracy: 0.8902 - val_loss: 0.3317 - val_accuracy: 0.9277\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.2545 - accuracy: 0.93\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0892 - accuracy: 0.9762 - val_loss: 0.1711 - val_accuracy: 0.9619\n",
      "Epoch 5/50\n",
      " 305/1000 [========>.....................] - ETA: 7s - loss: 0.0718 - accuracy: 0.9805Epoch 1/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0475 - accuracy: 0.9878 - val_loss: 0.2149 - val_accuracy: 0.9705\n",
      "500/500 [==============================] - 4s 8ms/step loss: 0.0837 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2960 - accuracy: 0.9307 - val_loss: 0.2562 - val_accuracy: 0.9403\n",
      " 330/1000 [========>.....................] - ETA: 7s - loss: 0.5825 - accuracy: 0.8535Epoch 3/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0866 - accuracy: 0.9766 - val_loss: 0.1949 - val_accuracy: 0.9613\n",
      "Epoch 6/50\n",
      " 711/1000 [====================>.........] - ETA: 2s - loss: 0.5059 - accuracy: 0.8815Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 14ms/step - loss: 0.4700 - accuracy: 0.8911 - val_loss: 0.3303 - val_accuracy: 0.9276\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2244 - accuracy: 0.9433 - val_loss: 0.3112 - val_accuracy: 0.9425\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0597 - accuracy: 0.9840 - val_loss: 0.1992 - val_accuracy: 0.9632\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 21s 18ms/step - loss: 0.4813 - accuracy: 0.8861 - val_loss: 0.3226 - val_accuracy: 0.9284\n",
      " 920/1000 [==========================>...] - ETA: 1s - loss: 0.2064 - accuracy: 0.9504Epoch 2/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2687 - accuracy: 0.9339 - val_loss: 0.2600 - val_accuracy: 0.9378\n",
      " 162/1000 [===>..........................] - ETA: 10s - loss: 0.2749 - accuracy: 0.9275Epoch 3/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2053 - accuracy: 0.9504 - val_loss: 0.2361 - val_accuracy: 0.9460\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0705 - accuracy: 0.9808 - val_loss: 0.1754 - val_accuracy: 0.9603\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2644 - accuracy: 0.9378 - val_loss: 0.2319 - val_accuracy: 0.9440\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.2839 - accuracy: 0.9334 - val_loss: 0.3161 - val_accuracy: 0.9286\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2015 - accuracy: 0.9533 - val_loss: 0.2914 - val_accuracy: 0.9526\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0545 - accuracy: 0.9863 - val_loss: 0.2254 - val_accuracy: 0.9638\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.1748 - accuracy: 0.95\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2176 - accuracy: 0.9501 - val_loss: 0.4606 - val_accuracy: 0.9457\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2585 - accuracy: 0.9378 - val_loss: 0.3410 - val_accuracy: 0.9450\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.1755 - accuracy: 0.9574 - val_loss: 0.3497 - val_accuracy: 0.9492\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2135 - accuracy: 0.9500 - val_loss: 0.3100 - val_accuracy: 0.9357\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.2288 - accuracy: 0.9477 - val_loss: 0.2597 - val_accuracy: 0.9423\n",
      "Epoch 5/50\n",
      "  49/1000 [>.............................] - ETA: 12s - loss: 0.2645 - accuracy: 0.9464Epoch 1/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1987 - accuracy: 0.9563 - val_loss: 0.3342 - val_accuracy: 0.9444\n",
      " 118/1000 [==>...........................] - ETA: 14s - loss: 1.1690 - accuracy: 0.6769Epoch 8/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1771 - accuracy: 0.9580 - val_loss: 0.3318 - val_accuracy: 0.9328\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.2075 - accuracy: 0.9526 - val_loss: 0.2807 - val_accuracy: 0.9433\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1977 - accuracy: 0.9577 - val_loss: 0.4068 - val_accuracy: 0.9463\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 24s 20ms/step - loss: 0.4017 - accuracy: 0.8867 - val_loss: 0.2118 - val_accuracy: 0.9430\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1820 - accuracy: 0.9600 - val_loss: 0.3299 - val_accuracy: 0.9506\n",
      " 442/1000 [============>.................] - ETA: 9s - loss: 0.1530 - accuracy: 0.9533Epoch 8/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2049 - accuracy: 0.9524 - val_loss: 0.2180 - val_accuracy: 0.9553\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1682 - accuracy: 0.9625 - val_loss: 0.3260 - val_accuracy: 0.9506\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1432 - accuracy: 0.9564 - val_loss: 0.1765 - val_accuracy: 0.9554\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 3s 6ms/step- loss: 0.0818 - accuracy: 0.97\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1828 - accuracy: 0.9595 - val_loss: 0.3034 - val_accuracy: 0.9492\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1939 - accuracy: 0.9555 - val_loss: 0.2826 - val_accuracy: 0.9388\n",
      "Epoch 8/50\n",
      " 535/1000 [===============>..............] - ETA: 6s - loss: 0.0826 - accuracy: 0.9751Epoch 1/50\n",
      "500/500 [==============================] - 4s 8ms/step loss: 0.1762 - accuracy: 0.95\n",
      " 794/1000 [======================>.......] - ETA: 2s - loss: 0.1560 - accuracy: 0.9624Epoch 1/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0882 - accuracy: 0.9737 - val_loss: 0.1662 - val_accuracy: 0.9607\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1652 - accuracy: 0.9611 - val_loss: 0.2701 - val_accuracy: 0.9574\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 18s 15ms/step - loss: 0.4041 - accuracy: 0.8829 - val_loss: 0.2023 - val_accuracy: 0.9407\n",
      " 838/1000 [========================>.....] - ETA: 1s - loss: 0.1642 - accuracy: 0.9629Epoch 2/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.1716 - accuracy: 0.9613 - val_loss: 0.3962 - val_accuracy: 0.9514\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.1637 - val_accuracy: 0.9638\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.1395 - accuracy: 0.9567 - val_loss: 0.1682 - val_accuracy: 0.9584\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2016 - accuracy: 0.9590 - val_loss: 0.2700 - val_accuracy: 0.9528\n",
      "1000/1000 [==============================] - 37s 22ms/step - loss: 0.4046 - accuracy: 0.8855 - val_loss: 0.1966 - val_accuracy: 0.9429\n",
      "Epoch 11/50\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 0.1793 - val_accuracy: 0.9600\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0865 - accuracy: 0.9739 - val_loss: 0.1527 - val_accuracy: 0.9615\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1560 - accuracy: 0.9645 - val_loss: 0.3237 - val_accuracy: 0.9556\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1447 - accuracy: 0.9559 - val_loss: 0.1634 - val_accuracy: 0.9527\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 4s 8ms/step loss: 0.0479 - accuracy: 0.98\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.1790 - val_accuracy: 0.9617\n",
      "Epoch 7/50\n",
      " 905/1000 [==========================>...] - ETA: 1s - loss: 0.0863 - accuracy: 0.9744Epoch 1/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0545 - accuracy: 0.9836 - val_loss: 0.1494 - val_accuracy: 0.9643\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0871 - accuracy: 0.9741 - val_loss: 0.1512 - val_accuracy: 0.9588\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.1929 - val_accuracy: 0.9662\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.1486 - val_accuracy: 0.9661\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0543 - accuracy: 0.9839 - val_loss: 0.1431 - val_accuracy: 0.9631\n",
      " 206/1000 [=====>........................] - ETA: 11s - loss: 0.0206 - accuracy: 0.9944Epoch 5/50\n",
      "1000/1000 [==============================] - 28s 23ms/step - loss: 0.3065 - accuracy: 0.9103 - val_loss: 0.1608 - val_accuracy: 0.9537\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.1993 - val_accuracy: 0.9676\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.1724 - val_accuracy: 0.9663\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.1832 - val_accuracy: 0.9589\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.1108 - accuracy: 0.9661 - val_loss: 0.1444 - val_accuracy: 0.9581\n",
      " 384/1000 [==========>...................] - ETA: 11s - loss: 0.0154 - accuracy: 0.9963Epoch 3/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.2176 - val_accuracy: 0.9627\n",
      "500/500 [==============================] - 4s 8ms/step loss: 0.0249 - accuracy: 0.99\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0221 - accuracy: 0.9940 - val_loss: 0.1803 - val_accuracy: 0.9655\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.1524 - val_accuracy: 0.9672\n",
      "Epoch 7/50\n",
      " 330/1000 [========>.....................] - ETA: 8s - loss: 0.0113 - accuracy: 0.9978Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0722 - accuracy: 0.9766 - val_loss: 0.1375 - val_accuracy: 0.9637\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.2006 - val_accuracy: 0.9643\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.1645 - val_accuracy: 0.9640\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0564 - accuracy: 0.9824 - val_loss: 0.1631 - val_accuracy: 0.9627\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 26s 22ms/step - loss: 0.3099 - accuracy: 0.9089 - val_loss: 0.1585 - val_accuracy: 0.9535\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.1717 - val_accuracy: 0.9634\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.2071 - val_accuracy: 0.9661\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.1842 - val_accuracy: 0.9610\n",
      " 164/1000 [===>..........................] - ETA: 14s - loss: 0.0186 - accuracy: 0.9952Epoch 6/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1112 - accuracy: 0.9668 - val_loss: 0.1505 - val_accuracy: 0.9582\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.1628 - val_accuracy: 0.9678\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.1940 - val_accuracy: 0.9683\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.1938 - val_accuracy: 0.9590\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 5s 9ms/step loss: 0.0712 - accuracy: 0.979\n",
      "500/500 [==============================] - 5s 9ms/step loss: 0.0731 - accuracy: 0.979\n",
      " 547/1000 [===============>..............] - ETA: 5s - loss: 0.0262 - accuracy: 0.9916Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0734 - accuracy: 0.9765 - val_loss: 0.1369 - val_accuracy: 0.9629\n",
      "Epoch 4/50\n",
      " 402/1000 [===========>..................] - ETA: 6s - loss: 0.4369 - accuracy: 0.8736Epoch 1/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.1680 - val_accuracy: 0.9690\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.1469 - val_accuracy: 0.9637\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 21s 19ms/step - loss: 0.2975 - accuracy: 0.9124 - val_loss: 0.1687 - val_accuracy: 0.9513\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.1561 - val_accuracy: 0.9682\n",
      "1000/1000 [==============================] - 24s 20ms/step - loss: 0.3122 - accuracy: 0.9118 - val_loss: 0.2023 - val_accuracy: 0.9446\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.1167 - accuracy: 0.965\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.1414 - val_accuracy: 0.9662\n",
      " 196/1000 [====>.........................] - ETA: 9s - loss: 0.1614 - accuracy: 0.9554Epoch 6/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1177 - accuracy: 0.9639 - val_loss: 0.1730 - val_accuracy: 0.9528\n",
      " 503/1000 [==============>...............] - ETA: 5s - loss: 0.1553 - accuracy: 0.9568Epoch 3/50\n",
      "  12/1000 [..............................] - ETA: 9s - loss: 0.0641 - accuracy: 0.9870 Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1618 - accuracy: 0.9548 - val_loss: 0.1447 - val_accuracy: 0.9601\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0359 - accuracy: 0.9884 - val_loss: 0.1623 - val_accuracy: 0.9615\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0740 - accuracy: 0.9785 - val_loss: 0.1386 - val_accuracy: 0.9628\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1188 - accuracy: 0.9668 - val_loss: 0.1658 - val_accuracy: 0.9602\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 18s 17ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.1653 - val_accuracy: 0.9693\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 37s 32ms/step - loss: 0.3111 - accuracy: 0.9114 - val_loss: 0.2281 - val_accuracy: 0.9385\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0527 - accuracy: 0.9835 - val_loss: 0.1536 - val_accuracy: 0.9628\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1000 - accuracy: 0.9723 - val_loss: 0.1660 - val_accuracy: 0.9592\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.1724 - val_accuracy: 0.9653\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1565 - accuracy: 0.9561 - val_loss: 0.2537 - val_accuracy: 0.9374\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0460 - accuracy: 0.9868 - val_loss: 0.1384 - val_accuracy: 0.9647\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 5s 10ms/step loss: 0.0222 - accuracy: 0.999\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0877 - accuracy: 0.9768 - val_loss: 0.1915 - val_accuracy: 0.9618\n",
      "Epoch 6/50\n",
      " 735/1000 [=====================>........] - ETA: 4s - loss: 0.1142 - accuracy: 0.9683Epoch 1/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.1505 - val_accuracy: 0.9637\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1184 - accuracy: 0.9679 - val_loss: 0.2319 - val_accuracy: 0.9542\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0817 - accuracy: 0.9783 - val_loss: 0.2020 - val_accuracy: 0.9634\n",
      " 855/1000 [========================>.....] - ETA: 2s - loss: 0.3220 - accuracy: 0.9056Epoch 7/50\n",
      "1000/1000 [==============================] - 27s 22ms/step - loss: 0.3060 - accuracy: 0.9111 - val_loss: 0.1899 - val_accuracy: 0.9485\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.1665 - val_accuracy: 0.9644\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0956 - accuracy: 0.9738 - val_loss: 0.1981 - val_accuracy: 0.9573\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0706 - accuracy: 0.9812 - val_loss: 0.1755 - val_accuracy: 0.9674\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.1865 - val_accuracy: 0.9639\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1583 - accuracy: 0.9560 - val_loss: 0.1645 - val_accuracy: 0.9550\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 4s 7ms/step- loss: 0.0478 - accuracy: 0.988\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0840 - accuracy: 0.9771 - val_loss: 0.1827 - val_accuracy: 0.9647\n",
      "Epoch 6/50\n",
      " 548/1000 [===============>..............] - ETA: 7s - loss: 0.0217 - accuracy: 0.9940Epoch 1/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1221 - accuracy: 0.9660 - val_loss: 0.1766 - val_accuracy: 0.9558\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.1764 - val_accuracy: 0.9664\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0780 - accuracy: 0.9796 - val_loss: 0.1790 - val_accuracy: 0.9643\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 27s 22ms/step - loss: 0.5043 - accuracy: 0.8809 - val_loss: 0.4262 - val_accuracy: 0.9090\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.1092 - accuracy: 0.9725 - val_loss: 0.1701 - val_accuracy: 0.9619\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.2007 - val_accuracy: 0.9627\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0693 - accuracy: 0.9818 - val_loss: 0.1944 - val_accuracy: 0.9639\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 4s 7ms/step loss: 0.0732 - accuracy: 0.97\n",
      " 622/1000 [=================>............] - ETA: 4s - loss: 0.0652 - accuracy: 0.9830Epoch 1/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3245 - accuracy: 0.9282 - val_loss: 0.3378 - val_accuracy: 0.9383\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.0843 - accuracy: 0.9777 - val_loss: 0.2230 - val_accuracy: 0.9566\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 17s 18ms/step - loss: 0.0681 - accuracy: 0.9824 - val_loss: 0.2209 - val_accuracy: 0.9652\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2448 - accuracy: 0.9445 - val_loss: 0.3032 - val_accuracy: 0.9395\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0812 - accuracy: 0.9788 - val_loss: 0.1659 - val_accuracy: 0.9634\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 24s 21ms/step - loss: 0.5115 - accuracy: 0.8800 - val_loss: 0.4291 - val_accuracy: 0.9143\n",
      " 181/1000 [====>.........................] - ETA: 14s - loss: 0.2490 - accuracy: 0.9477Epoch 2/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0639 - accuracy: 0.9845 - val_loss: 0.2086 - val_accuracy: 0.9669\n",
      " 521/1000 [==============>...............] - ETA: 8s - loss: 0.2849 - accuracy: 0.9419Epoch 10/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.2670 - accuracy: 0.9436 - val_loss: 0.3065 - val_accuracy: 0.9302\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0758 - accuracy: 0.9802 - val_loss: 0.1643 - val_accuracy: 0.9675\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3049 - accuracy: 0.9317 - val_loss: 0.2977 - val_accuracy: 0.9335\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0525 - accuracy: 0.9874 - val_loss: 0.2350 - val_accuracy: 0.9701\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2159 - accuracy: 0.9493 - val_loss: 0.2655 - val_accuracy: 0.9505\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0611 - accuracy: 0.9842 - val_loss: 0.1702 - val_accuracy: 0.9669\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2389 - accuracy: 0.9451 - val_loss: 0.4015 - val_accuracy: 0.9334\n",
      " 158/1000 [===>..........................] - ETA: 16s - loss: 0.0356 - accuracy: 0.9897Epoch 4/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0493 - accuracy: 0.9887 - val_loss: 0.2953 - val_accuracy: 0.9668\n",
      "500/500 [==============================] - 4s 8ms/step loss: 0.2390 - accuracy: 0.94\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1727 - accuracy: 0.9589 - val_loss: 0.2405 - val_accuracy: 0.9542\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0586 - accuracy: 0.9849 - val_loss: 0.2564 - val_accuracy: 0.9610\n",
      "Epoch 10/50\n",
      " 271/1000 [=======>......................] - ETA: 10s - loss: 0.0806 - accuracy: 0.9825Epoch 1/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2378 - accuracy: 0.9491 - val_loss: 0.2463 - val_accuracy: 0.9509\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1945 - accuracy: 0.9557 - val_loss: 0.3701 - val_accuracy: 0.9486\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0678 - accuracy: 0.9842 - val_loss: 0.2458 - val_accuracy: 0.9668\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2122 - accuracy: 0.9548 - val_loss: 0.2518 - val_accuracy: 0.9530\n",
      " 185/1000 [====>.........................] - ETA: 11s - loss: 0.0573 - accuracy: 0.9894Epoch 6/50\n",
      "1000/1000 [==============================] - 26s 21ms/step - loss: 0.4947 - accuracy: 0.8817 - val_loss: 0.5008 - val_accuracy: 0.9107\n",
      " 485/1000 [=============>................] - ETA: 7s - loss: 0.1523 - accuracy: 0.9643Epoch 2/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1989 - accuracy: 0.9572 - val_loss: 0.5882 - val_accuracy: 0.9481\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0567 - accuracy: 0.9871 - val_loss: 0.2112 - val_accuracy: 0.9651\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.1755 - accuracy: 0.9601 - val_loss: 0.2753 - val_accuracy: 0.9448\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.3536 - accuracy: 0.9267 - val_loss: 0.4275 - val_accuracy: 0.9338\n",
      " 650/1000 [==================>...........] - ETA: 4s - loss: 0.1546 - accuracy: 0.9655Epoch 3/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1544 - accuracy: 0.9620 - val_loss: 0.4264 - val_accuracy: 0.9567\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 0.2071 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.1535 - accuracy: 0.9656 - val_loss: 0.3618 - val_accuracy: 0.9513\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 7s 12ms/steploss: 0.2789 - accuracy: 0.946\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2800 - accuracy: 0.9402 - val_loss: 0.4123 - val_accuracy: 0.9305\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1878 - accuracy: 0.9582 - val_loss: 0.3959 - val_accuracy: 0.9392\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1771 - accuracy: 0.9597 - val_loss: 0.4925 - val_accuracy: 0.9553\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.2635 - accuracy: 0.9427 - val_loss: 0.3501 - val_accuracy: 0.9472\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1893 - accuracy: 0.9582 - val_loss: 0.5435 - val_accuracy: 0.9337\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1631 - accuracy: 0.9645 - val_loss: 0.5161 - val_accuracy: 0.9569\n",
      "500/500 [==============================] - 4s 6ms/step loss: 0.2301 - accuracy: 0.95\n",
      "500/500 [==============================] - 3s 6ms/step loss: 0.2168 - accuracy: 0.95\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: 0.2172 - accuracy: 0.9524 - val_loss: 0.2532 - val_accuracy: 0.9457\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1849 - accuracy: 0.9595 - val_loss: 0.2808 - val_accuracy: 0.9455\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.2269 - accuracy: 0.9534 - val_loss: 0.3308 - val_accuracy: 0.9468\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1653 - accuracy: 0.9655 - val_loss: 0.3422 - val_accuracy: 0.9486\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.1504 - accuracy: 0.9665 - val_loss: 0.4730 - val_accuracy: 0.9476\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1445 - accuracy: 0.9660 - val_loss: 0.3350 - val_accuracy: 0.9492\n",
      "500/500 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "144 fits failed out of a total of 288.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "144 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1474, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/scikeras/wrappers.py\", line 742, in fit\n",
      "    self._fit(\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/scikeras/wrappers.py\", line 898, in _fit\n",
      "    X, y = self._initialize(X, y)\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/scikeras/wrappers.py\", line 835, in _initialize\n",
      "    self.model_ = self._build_keras_model()\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/scikeras/wrappers.py\", line 420, in _build_keras_model\n",
      "    model = final_build_fn(**build_params)\n",
      "  File \"/var/folders/rq/1rcgs6g91116_xcdkgbd_w7m0000gn/T/ipykernel_68423/2111520718.py\", line 9, in nn_model\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\", line 587, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/keras/engine/sequential.py\", line 178, in add\n",
      "    raise TypeError('The added layer must be an instance of class Layer. '\n",
      "TypeError: The added layer must be an instance of class Layer. Received: layer=<class 'keras.layers.normalization.batch_normalization.BatchNormalization'> of type <class 'type'>.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/szymonmizak/machine_learning/mnist_project/mnist_project_env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.96283333 0.96391667 0.9595     0.94702083 0.959625   0.95983333\n",
      " 0.96089583 0.95335417 0.96       0.96139583 0.96229167 0.94979167\n",
      " 0.96389583 0.96258333 0.95479167 0.94758333 0.96114583 0.963\n",
      " 0.95729167 0.95489583 0.96189583 0.9651875  0.9598125  0.95529167\n",
      " 0.96610417 0.96285417 0.95627083 0.94954167 0.9615625  0.96285417\n",
      " 0.961375   0.95008333 0.96008333 0.96072917 0.961875   0.9480625\n",
      " 0.9663125  0.96427083 0.959      0.93789583 0.9609375  0.9610625\n",
      " 0.9616875  0.94889583 0.96154167 0.96122917 0.962125   0.94995833\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3705 - accuracy: 0.8975 - val_loss: 0.2017 - val_accuracy: 0.9448\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1478 - accuracy: 0.9570 - val_loss: 0.1558 - val_accuracy: 0.9592\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0979 - accuracy: 0.9714 - val_loss: 0.1315 - val_accuracy: 0.9655\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0688 - accuracy: 0.9797 - val_loss: 0.1193 - val_accuracy: 0.9691\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0509 - accuracy: 0.9856 - val_loss: 0.1220 - val_accuracy: 0.9709\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0365 - accuracy: 0.9899 - val_loss: 0.1234 - val_accuracy: 0.9730\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0278 - accuracy: 0.9921 - val_loss: 0.1281 - val_accuracy: 0.9730\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.1250 - val_accuracy: 0.9743\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.1292 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(callbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f788a831f10&gt;], loss=[&#x27;categorical_crossentropy&#x27;], metrics=[&#x27;accuracy&#x27;], model=&lt;function nn_model at 0x7f787d8f5a60&gt;, model__batch_norm=False, model__dropout_rate=0.2, model__hidden_layers=(512,), optimizer=&#x27;Adam&#x27;, optimizer__learning_rate=0.001),\n",
       "             n_jobs=4,\n",
       "             param_grid={&#x27;model__batch_norm&#x27;: [False, True],\n",
       "                         &#x27;model__dropout_rate&#x27;: [0, 0.2],\n",
       "                         &#x27;model__hidden_layers&#x27;: [(256, 256), (256, 256, 256),\n",
       "                                                  (256, 256, 256, 256),\n",
       "                                                  (512, 512), (512, 512, 512),\n",
       "                                                  (512, 512, 512, 512)],\n",
       "                         &#x27;optimizer__learning_rate&#x27;: [0.0001, 0.0003, 0.001,\n",
       "                                                      0.003]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(callbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f788a831f10&gt;], loss=[&#x27;categorical_crossentropy&#x27;], metrics=[&#x27;accuracy&#x27;], model=&lt;function nn_model at 0x7f787d8f5a60&gt;, model__batch_norm=False, model__dropout_rate=0.2, model__hidden_layers=(512,), optimizer=&#x27;Adam&#x27;, optimizer__learning_rate=0.001),\n",
       "             n_jobs=4,\n",
       "             param_grid={&#x27;model__batch_norm&#x27;: [False, True],\n",
       "                         &#x27;model__dropout_rate&#x27;: [0, 0.2],\n",
       "                         &#x27;model__hidden_layers&#x27;: [(256, 256), (256, 256, 256),\n",
       "                                                  (256, 256, 256, 256),\n",
       "                                                  (512, 512), (512, 512, 512),\n",
       "                                                  (512, 512, 512, 512)],\n",
       "                         &#x27;optimizer__learning_rate&#x27;: [0.0001, 0.0003, 0.001,\n",
       "                                                      0.003]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function nn_model at 0x7f787d8f5a60&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=Adam\n",
       "\tloss=[&#x27;categorical_crossentropy&#x27;]\n",
       "\tmetrics=[&#x27;accuracy&#x27;]\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f788a831f10&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\toptimizer__learning_rate=0.001\n",
       "\tmodel__hidden_layers=(512,)\n",
       "\tmodel__dropout_rate=0.2\n",
       "\tmodel__batch_norm=False\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function nn_model at 0x7f787d8f5a60&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=Adam\n",
       "\tloss=[&#x27;categorical_crossentropy&#x27;]\n",
       "\tmetrics=[&#x27;accuracy&#x27;]\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x7f788a831f10&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\toptimizer__learning_rate=0.001\n",
       "\tmodel__hidden_layers=(512,)\n",
       "\tmodel__dropout_rate=0.2\n",
       "\tmodel__batch_norm=False\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=KerasClassifier(callbacks=[<keras.callbacks.EarlyStopping object at 0x7f788a831f10>], loss=['categorical_crossentropy'], metrics=['accuracy'], model=<function nn_model at 0x7f787d8f5a60>, model__batch_norm=False, model__dropout_rate=0.2, model__hidden_layers=(512,), optimizer='Adam', optimizer__learning_rate=0.001),\n",
       "             n_jobs=4,\n",
       "             param_grid={'model__batch_norm': [False, True],\n",
       "                         'model__dropout_rate': [0, 0.2],\n",
       "                         'model__hidden_layers': [(256, 256), (256, 256, 256),\n",
       "                                                  (256, 256, 256, 256),\n",
       "                                                  (512, 512), (512, 512, 512),\n",
       "                                                  (512, 512, 512, 512)],\n",
       "                         'optimizer__learning_rate': [0.0001, 0.0003, 0.001,\n",
       "                                                      0.003]})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run grid search\n",
    "grid_search_cv.fit(\n",
    "    X_train_tr, \n",
    "    y_train,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_valid_tr, y_valid), \n",
    "    callbacks = [stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "42e5bbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__batch_norm': False,\n",
       " 'model__dropout_rate': 0.2,\n",
       " 'model__hidden_layers': (512, 512),\n",
       " 'optimizer__learning_rate': 0.0001}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See best parameters\n",
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b286f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3731 - accuracy: 0.8934 - val_loss: 0.1960 - val_accuracy: 0.9457\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1474 - accuracy: 0.9564 - val_loss: 0.1510 - val_accuracy: 0.9594\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0999 - accuracy: 0.9705 - val_loss: 0.1280 - val_accuracy: 0.9653\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0676 - accuracy: 0.9797 - val_loss: 0.1166 - val_accuracy: 0.9676\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0514 - accuracy: 0.9850 - val_loss: 0.1151 - val_accuracy: 0.9714\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0371 - accuracy: 0.9899 - val_loss: 0.1174 - val_accuracy: 0.9730\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 0.1124 - val_accuracy: 0.9737\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 0.1256 - val_accuracy: 0.9734\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.1244 - val_accuracy: 0.9744\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.1219 - val_accuracy: 0.9751\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.1290 - val_accuracy: 0.9737\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.1375 - val_accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "# Refit model with best parameters\n",
    "best_model = nn_model(hidden_layers=(512,512), dropout_rate=0.2, batch_norm=False)\n",
    "best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=[\"categorical_crossentropy\"], metrics=[\"accuracy\"])\n",
    "history = best_model.fit(    \n",
    "    X_train_tr, \n",
    "    y_train,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_valid_tr, y_valid), \n",
    "    callbacks = [stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d38d39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fitted model to a file \n",
    "best_model.save(\"models/dnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c72b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if neccessary\n",
    "#tf.keras.models.load_model(\"models/dnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ba6f4df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves for metric and loss\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
    "axes[0].plot(history.history[\"accuracy\"], color = \"orange\")\n",
    "axes[0].plot(history.history[\"val_accuracy\"])\n",
    "axes[1].plot(history.history[\"loss\"], color = \"orange\")\n",
    "axes[1].plot(history.history[\"val_loss\"])\n",
    "axes[0].set_title('Accuracy')\n",
    "axes[1].set_title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "912bd6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "predictions = best_model.predict(X_valid_tr)\n",
    "conf_matrix = tf.math.confusion_matrix(labels=tf.argmax(y_valid, axis=1), predictions=tf.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f3e7cdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAHSCAYAAAAkMCseAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABjCUlEQVR4nO3deXxU1f3G8c+ZJEAChF0ggQqKWxEFCYhAQWQTJIpWoSIuFcuvVkSrFbWiFFGrrajYWgUEWRQQUEBkla2IlU3CIhBkFZIQ2cMOWc7vjwwIQpIJzuTOMc/b17yYuXdmzjPXOzMn33PuHWOtRURERMQVPq8DiIiIiBSGOi8iIiLiFHVeRERExCnqvIiIiIhT1HkRERERp6jzIiIiIk6JLII2dCy2iIgUN6YoG8vcsyXo37VRlS8p0tdQGEXReeHYguFF0UxQRN/4IACRJeI9ThKYrJOpgDt5QZmLgmt5QZmLgmt5we3MEjpF0nkRERGREMrJ9jpBkVLnRURExHU2x+sERUoTdkVERMQpqryIiIi4LkeVFxEREZGwpcqLiIiI42wxm/OizouIiIjrNGwkIiIiEr5UeREREXFdMRs2UuVFREREnKLKi4iIiOuK2Rl2VXkRERERp6jyIiIi4rpiNudFnRcRERHX6VBpERERkfBVZJ2XfiOn0+ov/+K3/Yedd/20JWu568Xh3Nl/GPe9NpoNO3b97DZPZmbRZ8gUEvsOpvvfR5G6JwOANVvT6DLgA/9lOPOSvvvZbRWkfbsbWfvtQpLXLaLPU4+EvL1g8Pl8LFs6iymTRnodJSCubeOhQwaSlrKKlUlzvY4SkBo14pgzewKrV81n1cp5PNqrh9eRAubSvuzaflGyZEm+/upzvln+BatWzqPfC096HalALu/LebE2J+iXcFZknZdbb6jHf3rflef6+MrlGPZkNyb260HPW5oy4MOZAT936p4Megwcc87ySV+tJrZ0Kaa+9H90b5PAoE8XAFAnvgpj/no/45//Pe/07sKAj2aRlR26/1E+n4+3B71Mp8Tu1Lu2FV27duaqqy4LWXvB0vvRh0hO3uh1jIC4uI1HjRrPLZ3u8TpGwLKysniqT3+uubYVzZon8vDDD4T9Nj7FpX3Ztf3ixIkTtGnXhYYJbWmY0I727W7k+sbXeR0rXy7vy5KryDovDS+vSWxMdJ7r619ag9jSpQC4pnY8Pxw4dHrdtMVruefvo+gy4AMGfDiT7ADH9has2khik6sBaHPdlSxN/h5rLdElooiMyH3pJzOzMBf6ogLUuFEDNm/extat28nMzGT8+Cncmtg+xK3+PPHx1enYoTXDh4/1OkpAXNzGXy5awr79B7yOEbD09F0krfwWgMOHj5CcvJH4uGoepyqYa/uya/sFwJEjRwGIiookMioKa63HifLn6r6cr5yc4F/CWIETdo0xVwK3AfH+RanAZ9ba9aEKNemrVTSvewkAW3buYdby9Yzocw9RERG8PGY205esI/GGqwt8nl0HDlOtYlkAIiN8lIkuyYEjx6hQJoY1W9PoN3I6O/cd5OXfdzrdmQmFuPhq7EhJO307JXUnjRs1CFl7wfDGwP488+xLlC1bxusoAXFxG7vs4otrUP/aq1myNMnrKAVybV92kc/nY+mSmdS5tBbvvjeCpcvCf784xaV9OV9hPswTbPl2XowxTwN3A+OApf7FNYCxxphx1tpXgx1o2YbvmfzVaj54qjsAS5O/Z/32H7jnlVEAnMjMomLZGAD+/O6npO7JICs7m537DtJlwAcAdLupIZ2bXZNvO/Vqx/Hp3x5iy849PD9iOs2uvoSSUTr4CuCWjm3YtWsPK5LW0LLFDV7HkTBTunQM4z8eyhN/6cehQ4e9jpMv7ctFIycnh4RG7ShXLpZPJgyjbt0rWLt2g9exCuTSvixnK+jbugdQ11qbeeZCY8wbwFrgvJ0XY0xPoCfA4MGDuffywDoF36Xsov+ombzT+y7Kl8kdYrIWEm+4mt63tzzn/m8+fAeQO+flhZHTGPZkt7PWX1S+DOn7DlG1QixZ2TkcPnaC8qXPHrq6pHplYkpGsSl1N3VrVQ8oZ2GlpaZTs0bc6ds14quTlpYekraCoWnTBBI7taPDzTdRqlRJYmPLMnLE29z/QG+vo+XJtW3sqsjISCZ8PJSxYycxefIMr+MUyMV92WUZGQdZ8N+vcifPh3nnxbV9uUA6w+5ZcoC48yyv7l93XtbaIdbaBGttQs+ePQMKsnPfQZ58bxIvPXgLF1eteHp54ysv5osVG9h38AgAGUeOkbY3I6DnbHnNZUxdnDuuOWdFMo2u/BXGGFL3HDg9QTdtbwbb0vcRV7lcQM95IZYtX0mdOrWpVasmUVFRdOlyG1M/nx2y9n6u5/q+Sq1LEqhzeRPu6f4n5s//Kuw/7F3bxq4aOmQg65M38dagIV5HCYiL+7JrKleuSLlysQCUKlWKNq1bsGHDZo9TFcy1fVnOVlBJ5HFgrjFmI7DDv+xXQB2gV2Eaeub9z1i+YTsHDh+j3dPv8HBi89MdiLtaNmDI519x4MgxXhnzRW4wn48xz93PpXGV6XXrb/jjoPFYa4mM8PHs3W2Jq1RwZ+P25tfw3PDPSew7mNjS0bz20K0AJG1KYfjMxURGROAzhme7taVCmZjCvJxCyc7O5rHH+zJ92hgifD5GjPyYdetCf3h2ceLiNv5w9Du0bHEDlStXZNuW5fR/8XU+GDHO61h5ata0Efd2v5PVa9axfFlux/D5519lxsx5Hif7ZXFtv6hevSrDh71FRIQPn8/HxIlTmTZ9jtex8vWL3JeL2ZwXU9CscGOMD2jM2RN2l1lrA61R2WMLhl94wiIWfeODAESWiC/gnuEh62Qq4E5eUOai4FpeUOai4FpecDpzqA9kPcuJtXODfohXybqti/Q1FEaBk1Fs7plqFhdBFhEREZEC6fAaERER1xWzYSP9tpGIiIg4RZUXERER14X5GXGDTZ0XERERxwV+DM0vg4aNREREpNCMMcONMbuMMd+eseyfxphkY8xqY8wkY0z5M9Y9a4zZZIzZYIxpf8bym/3LNhljngmkbXVeREREXGdzgn8p2Ajg5p8s+wK42lp7DfAd8CyAMebXwO+Auv7H/McYE2GMiQDeAToAvwbu9t83X+q8iIiISKFZaxcC+36ybLa1Nst/czG5v4cIuT/wPM5ae8JauxXYRO455BoDm6y1W6y1J8n9LcXbCmpbc15ERERcF54Tdh8EPvZfj+fsc8al8OPJb3f8ZPn1BT2xKi8iIiJyDmNMT2PM8jMugf1YYe5jnwOygI9CkU2VFxEREdeF4CR11tohQKF/udIY8wDQCWhtf/wNolSg5hl3q+FfRj7L86TOi4iIiOtywuNQaWPMzUAfoKW19ugZqz4Dxhhj3gDigMuApeT+BtRlxpja5HZafgd0K6gddV5ERESk0IwxY4EbgcrGmBSgH7lHF5UEvjDGACy21v7RWrvWGDMeWEfucNIjp37g2RjTC5gFRADDrbVrC2pbnRcRERHXefDbRtbau8+zeFg+938ZePk8y6cD0wvTtibsioiIiFNUeREREXFdeB4qHTLmx4nAIRPyBkRERMKMKcrGjn89NujftaVuuLtIX0NhaNhIREREnFIkw0aRJeILvlOYyDqZe3h55p4tHicJTFTlS3L/dWgbZ/q3sYv7hSuZXcsLylwUXMsLbmcuUsVs2EiVFxEREXGKJuyKiIi4rphVXtR5ERERcZz/fG/FhoaNRERExCmqvIiIiLiumA0bqfIiIiIiTlHlRURExHUe/LaRl1R5EREREaeo8iIiIuK6YjbnRZ0XERER12nYSERERCR8qfIiIiLiumI2bKTKi4iIiDhFlRcRERHXFbM5L+q8iIiIuE7DRuGvfbsbWfvtQpLXLaLPU4+ErJ2+r7xBi1t+R+fufzzv+nlffs3t9z3Mb+9/hC4P9mbFqm9/dpsZBw/x0GN/pWPXHjz02F/JOHgoZG3l57Hef2DlynkkJc1l9Oh3KFmyZEjb+7mGDhlIWsoqVibN9TpKwEqWLMnXX33ON8u/YNXKefR74UmvIxWoqN57wVKjRhxzZk9g9ar5rFo5j0d79fA6UoFc3Jdd2y9c3MZyNuc6Lz6fj7cHvUynxO7Uu7YVXbt25qqrLgtJW507tuW9N17Kc32ThvX5dOR/+GTkOwz465/p9+qggJ976YrVPPfSwHOWvz96PE0S6jP942E0SajPsA/H/+y2CisurhqPPPIgTZp0pEGD1kRERNC1y20hay8YRo0azy2d7vE6RqGcOHGCNu260DChLQ0T2tG+3Y1c3/g6r2PlqSjfe8GSlZXFU336c821rWjWPJGHH34g7DO7ti+7uF+4to0DkpMT/EsYc67z0rhRAzZv3sbWrdvJzMxk/Pgp3JrYPiRtJdSvR7nYsnmuj4mJxhgDwLHjx8F/HWD4RxPp2qM3t9/3MP9+f3TAbc7/8mtu69AGgNs6tGHewq8LbCsUIiMjiY4uRUREBDHR0aTtTA9pez/Xl4uWsG//Aa9jFNqRI0cBiIqKJDIqCmutx4nyVpTvvWBJT99F0srcKuXhw0dITt5IfFw1j1Plz7V92cX9wrVtLOdybs5LXHw1dqSknb6dkrqTxo0aeJZnzn+/YtB7I9i7/wD/ef1FAL5a8g3bU1IZ9/4grLX0ero/y1euIaF+vQKfb+/+A1SpXBGAypUqsPeMN9j52gqFtLR03nzzPbZsXsqxY8eZM+e/zJmzMGTtFWc+n4+lS2ZS59JavPveCJYuS/I6Up7C7b1XWBdfXIP6117NkqXhu41d5Pp+8YuhCbtSGG1aNqNNy2YsX7mGfw8dxfuD/s7/lq3gf0tXcOcDvQA4euwY3+9II6F+Pe7+w+OcPJnJ0WPHyDh4iN/enzs+/MSfHqTZ9Q3Pem5jzOlqS15thUL58uVITGzPZZc34cCBg4wbN5hu3e5gzJhPQ9JecZaTk0NCo3aUKxfLJxOGUbfuFaxdu8HrWL84pUvHMP7joTzxl34cOnTY6zgiwRfmwzzBdsGdF2PM7621H+SxrifQE2Dw4MEX2sR5paWmU7NG3OnbNeKrk5bm/ZBGQv16pKSls/9ABlh46N6udOnc8Zz7jR36FpA752XK9C94ue/ZkzQrVSjP7j37qFK5Irv37KNi+XL5tnVR5eC/ltatf8O2bdvZs2cfAJMnz+CGJgnqvIRQRsZBFvz3q9yJj2HaeQnX915BIiMjmfDxUMaOncTkyTO8jvOL4+p+IW77OXNe+ue1wlo7xFqbYK1N6Nmz589o4lzLlq+kTp3a1KpVk6ioKLp0uY2pn88OahuB2p6SdnqOwroNmzh5MpPy5WJp2vg6Jk2bzdGjxwD4Yfees4Z/8nNj8yZMmTEHgCkz5tDqNzfk21Yo7NieSuPrryM6uhQAN7VqTnLyxpC0VZxVrlyRcv7/h6VKlaJN6xZs2LDZ41R5C6f3XmEMHTKQ9cmbeGvQEK+j/CK5ul/84tic4F/CWL6VF2PM6rxWAVWDH6dg2dnZPPZ4X6ZPG0OEz8eIkR+zbt13IWnrqX6vsixpNQcOHKR15+78qce9ZGVlAdD19lv4YsEiPpsxl8jISEqVLMHrLz6DMYZm1zdky/c7uOf/ngAgJroUf3/hKSpVKF9gmw/d24Unn3+FTz+fRVy1ixg44K8AebYVCkuXJfHpp9NYunQWWVlZrFq5lqHvfxSStoLlw9Hv0LLFDVSuXJFtW5bT/8XX+WDEOK9j5at69aoMH/YWERE+fD4fEydOZdr0OV7HylNRvveCpVnTRtzb/U5Wr1nH8mW5X6jPP/8qM2bO8zhZ3lzbl13cL1zbxnIuk9/RDcaYH4D2wP6frgL+Z62NO/dR57CRJeIvPGERyzqZCkDmni0eJwlMVOVLcv91aBtn+rexi/uFK5ldywvKXBRcywtOZw7tIaE/cWzSq0E/VDH69meK9DUURkFzXj4HylhrV/50hTFmQSgCiYiIiOQn386LtTbP01Faa7sFP46IiIgUWpjPUQk2HSotIiLiumJ2qLRzZ9gVERGR4k2VFxEREdep8iIiIiISvlR5ERERcV0Y/6hrKKjzIiIi4joNG4mIiIiEL1VeREREXKfKi4iIiEj4UuVFRETEdTrDroiIiDhFw0YiIiIi4UuVFxEREdcVs/O8qPIiIiIiTlHlRURExHXFbM5LkXResk6mFkUzQRVV+RKvIxRKpoPb2MX9wrXMruUFZS4KruUFNzNL6KjyIiIi4jpVXkLQSIn4omgmKE717qMcyXyq4nJsznseJwlcdJs/Am7uF65kdi0vuJ3Ztc8LF7exi5mLVDE7z4sm7IqIiIhTNGwkIiLiOJujQ6VFREREwpYqLyIiIq7ThF0RERFxiibsioiIiIQvVV5ERERcpwm7IiIiIuFLlRcRERHXFbMJu6q8iIiIuC4nJ/iXAhhjhhtjdhljvj1jWUVjzBfGmI3+fyv4lxtjzNvGmE3GmNXGmOvOeMz9/vtvNMbcH8jLVedFRERELsQI4OafLHsGmGutvQyY678N0AG4zH/pCbwLuZ0doB9wPdAY6Heqw5MfdV5ERERcZ23wLwU2aRcC+36y+DZgpP/6SKDzGctH2VyLgfLGmOpAe+ALa+0+a+1+4AvO7RCdQ50XERERCZaq1tqd/uvpQFX/9Xhgxxn3S/Evy2t5vjRhV0RExHUhmLBrjOlJ7hDPKUOstUMCfby11hpjQnIMtzovIiIicg5/RyXgzorfD8aY6tbanf5hoV3+5alAzTPuV8O/LBW48SfLFxTUiHPDRkOHDCQtZRUrk+Z6HaVQHu3Vg6SkuaxcOY/ejz4Ukjb6jZ5Nq6ff47cvjTrv+q3p+7jv9XE0euxtRs5ZHpQ2T2Zm0WfYNBL7Daf7P8aSujcDgDXb0unyyof+y2jmrdwUlPbys+m7xSStmMPyZbNZ/PX0kLf3c5UsWZKvv/qcb5Z/waqV8+j3wpNeRypQ+3Y3svbbhSSvW0Sfpx7xOk6BXNzGl19+KcuXzT592bsnOWSfGcHg4jZ29XskXzk2+JcL8xlw6oih+4EpZyy/z3/UURMgwz+8NAtoZ4yp4J+o286/LF/OdV5GjRrPLZ3u8TpGodStewUP9uhG06a30LBhWzp2bMOll9YKeju3Nvk1/3nk9jzXlytdij533ch9rRsW+rlT92bQ460J5yyf9PVaYmNKMrX/g3S/6ToGTV4EQJ24Sox5uhvj/9qddx65nQFj55CVHfrzELRpexcJjdrR5IaOIW/r5zpx4gRt2nWhYUJbGia0o327G7m+8XUFP9AjPp+Ptwe9TKfE7tS7thVdu3bmqqsu8zpWvlzbxgDffbeZhEbtSGjUjsbX38zRo8eYPGWG17Hy5OI2dvF7pEA2J/iXAhhjxgJfA1cYY1KMMT2AV4G2xpiNQBv/bYDpwBZgEzAU+BOAtXYfMABY5r+86F+WL+eGjb5ctISLL67hdYxCufLKy1i2NIljx44DsPDLxXTu3IGBA98NajsNL6txuvJxPhXLxlCxbAxffrv1nHXTlq5nzIIkMrNyqFerGn/93U1E+Aru2y5YvZk/dmwCQJsGl/Hq+HlYa4kuEXX6PiczszHGXMAr+uU7cuQoAFFRkURGRWEDmOHvlcaNGrB58za2bt0OwPjxU7g1sT3r12/0OFn+XNrGP3XTTc3ZsuV7tm9P9TpKvlzbxi5+j4Qja+3deaxqfZ77WuC85Vpr7XBgeGHaLvDbyRhzpTGmtTGmzE+WF3gok+RauzaZZs2vp2LFCkRHl6LDzTdRs0ac17FO25K+l1nfbGDEk10Z/9fu+HyG6cuSA3rsrgOHqVahLACRET7KRJfkwJHcTtqarTu5Y8BI7nx5NH1/15rIiNAW+qy1zJg+liWLZ/BQDzf+qvL5fCxfNpudqauZO3chS5cleR0pT3Hx1diRknb6dkrqTuLiqnmYKDAubeOf6trlNj7+eLLXMQrk8jb+xQifYaMikW/lxRjTm9ye0npgmDHmMWvtqfGrV4CZIc73i5CcvInX//kOM6aP4ciRo6xatZbsIhhCCdTS5B2s37GLe14bC8CJzCwqlo0B4M9DPiN1z0GysrPZue8QXV75EIBurRrQ+Ya6+T5vvdrV+fT5+9mSvpfnR82iWd1alIwKXbGvZavbSUtLp0qVSsycMY4NGzbx5aIlIWsvGHJyckho1I5y5WL5ZMIw6ta9grVrN3gd6xfF1W0cFRVFp07teK7v372OUiBXt7G4q6Bvkj8ADa21h40xtYCJxpha1tpBQJ7jAGceXjV48OBgZXXaByPG8cGIcQAMGPAMqSk7C3hE0bFYEq//Nb1va37Oujd73grkznl5YfRshj1+11nrLypfhvT9h6haoSxZ2TkcPnaC8qVLnXWfS6pVIqZkCTal7aHuxaH7Sz0tLR2A3bv3MmXKDBo1qh/2nZdTMjIOsuC/X+VOiA3TD/201PSzKoY14quf3uYucGEbn+nmm1uRlLSGXbv2eB0lYK5t418Sq982Onu9tfYwgLV2G7mHM3UwxrxBPp0Xa+0Qa22CtTahZ8+eed2tWKlSpRIANWvG0blzB8aOm+Rxoh81vuJXfJG0kX2HcsetM44cJ23vwYAe27LeJUxdsg6AOUkbaXR5TYwxpO7JOD1BN23vQbb9sI+4SuVC8wKAmJhoypQpffp62zYtw/7Ds3LlipQrFwtAqVKlaNO6BRs2bPY4Vd6WLV9JnTq1qVWrJlFRUXTpchtTP5/tdax8ubaNz9S1a2cnhoxc3sa/KBo2OssPxpj61tqVAP4KTCdyJ9bUC3W48/lw9Du0bHEDlStXZNuW5fR/8fXTFY1wNv7joVSsVIGszCx6936OjIzAOgeF8czw6SzfuIMDh4/T7rmhPHzLDWRlZwNw12+uZU/GEbr9YwxHjp/EGMNH85P4tO99XFq9Er0Sm/LHf32KtZbICB/Pdr2JuEqxBbZ5e9OreW7kTBL7DSe2dCleezD3KJ+kzakMn72MyIgIfD7Ds11vokKZ6KC/5lOqVq3CxAnDAIiMjGDcuMnMmr0gZO0FQ/XqVRk+7C0iInz4fD4mTpzKtOlzvI6Vp+zsbB57vC/Tp40hwudjxMiPWbfuO69j5cu1bXxKTEw0bVq34E9/etrrKAVycRu7+j0iPzL5zQo3xtQAsqy159SGjTHNrLVfBdCGjSxR4Jl+w0bWydxZ/VGOZM705z025z2PkwQuus0fAXBxv3Als2t5we3Mrn1euLiNHcxcpIdYHnmpe9BLJaX7fhi2h4nmW3mx1qbksy6QjouIiIhIUDl3nhcRERH5iTCfoxJs6ryIiIi4TkcbiYiIiIQvVV5ERERcV8yGjVR5EREREaeo8iIiIuK6AH4F+pdElRcRERFxiiovIiIiritmc17UeREREXGcfphRREREJIyp8iIiIuK6YjZspMqLiIiIOEWVFxEREdcVs8qLOi8iIiKu03leRERERMKXsTbkpabiVcsSEREBU5SNHX7i1qB/15Z547MifQ2FocqLiIiIOKVI5rxElogvimaCIutkKuBO5lN5S5Ss4XGSwJ08kQLA8a8+8jhJ4Eo1uwfQfhFKp/YLV7Yx6POiKLi8XxQlqwm7IiIi4pRi1nnRsJGIiIg4RZUXERER1+m3jURERETClyovIiIirtOcFxEREZHwpcqLiIiI64pZ5UWdFxEREccVwdnyw4qGjURERMQpqryIiIi4rpgNG6nyIiIiIk5R5UVERMR1xazyos6LiIiI44rbDzNq2EhEREScosqLiIiI61R5CW81asQxZ/YEVq+az6qV83i0Vw+vIxWoZMmSfP3V53yz/AtWrZxHvxee9DrSeQ0Z/DopO1aStGLO6WV//3tf1qxewDfLv2DC+PcpVy42qG2+MPwzbnzsde54/t3zrp/29RrufOE9fvv8e9z38nA2bE//2W2ezMziqXcn0umZf3HPgPdJ3XMAgDVbUunSbzBd+g3mrhcGM/eb5J/dVkHat7uRtd8uJHndIvo89UjI2yssL/aJYAv3bXw+m75bTNKKOSxfNpvFX0/3Os45zrdf/PaOW1iZNJfjx7Zz3XXXeJiuYK58JkvenOu8ZGVl8VSf/lxzbSuaNU/k4Ycf4KqrLvM6Vr5OnDhBm3ZdaJjQloYJ7Wjf7kaub3yd17HOMWr0BDoldj9r2dy5C6nfoDUNE9qyceMWnu7TK6ht3tbsWt594p4818dXKc/wp+/nkwF/pGfib3hx5OcBP3fqngP0eG3kOcsnfZlEbOloPn/1Ubq3a8JbE3I/gOvEX8SYF/7A+P7/x3+e6MaAUZ+TlR26X2r1+Xy8PehlOiV2p961rejatXPY7cte7BPB5MI2zkubtneR0KgdTW7o6HWUc5xvv1i7bgNduv6BL79c4lGqwLnymVwoOSG4hDHnOi/p6btIWvktAIcPHyE5eSPxcdU8TlWwI0eOAhAVFUlkVFRYng1x0aIl7N9/4Kxlc+YsJDs7G4AlS1YQH189qG02vOJiYktH57m+fp2ap9dfc2kNfth/6PS6z79eTbcB79Ol32BeHPk52QH+JPz8pA3c2jT3L8O2Cb9m6fqtWGuJLhlFZETuW+JEZhbGmAt9WQFp3KgBmzdvY+vW7WRmZjJ+/BRuTWwf0jYLy4t9Iphc2MYuOt9+kZy8ie++2+JNoAvgwmdyYdgcG/RLOHOu83Kmiy+uQf1rr2bJ0iSvoxTI5/OxfNlsdqauZu7chSxdFv6Zf+qBB7oya9Z8z9qf9GUSzevVAWBL2m5mLV3LyGd/z/j+/0eEz8f0r9cE9Dy7DhyiWsVyAERG+CgTXYoDh48BsHpzCrf3fZc7X3iPvvfecrozEwpx8dXYkZJ2+nZK6k7iHOiIn8nrfaIgrm5jay0zpo9lyeIZPNQj78qkXLhfwmdycVbghF1jTGPAWmuXGWN+DdwMJFtrPR2ILV06hvEfD+WJv/Tj0KHDXkYJSE5ODgmN2lGuXCyfTBhG3bpXsHbtBq9jBeyZpx8lKyubMWM/9aT9peu3MunLlYx49gEAlqzfyvptO7lnwPsAHD+ZRcWyMQA8/q+PSdtzgMysbHbuy6BLv8EAdGtzPZ1/Uz/fdq65tAaTXnqYLWm76TtsCs2vqUPJKM1rPx+v94lfspatbictLZ0qVSoxc8Y4NmzYxJeLwn84xiWufyafI8wrJcGW76eyMaYf0AGINMZ8AVwPzAeeMcY0sNa+nMfjegI9AQYPHhzcxEBkZCQTPh7K2LGTmDx5RtCfP5QyMg6y4L9f5U4idOSNcu+9d9GxYxva39zVk/a/2/ED/Ud8zjt/7kb5MrkdFGshsdm1PHZn63Pu/9ajuTlT9xzghWFTGPb0/Wetv6h8WdL3ZVC1YixZ2TkcPnac8mXOHrq6JK4KMSVLsCllF3Vrx4XkdaWlplOzxo/PXSO+OmlpP39CclHwep8IlKvb+FTG3bv3MmXKDBo1qq/OS4i4+JksBQ8b3Qk0A1oAjwCdrbUDgPZAnp9a1toh1toEa21Cz549gxb2lKFDBrI+eRNvDRoS9OcOhcqVK54+IqNUqVK0ad2CDRs2e5wqMO3a3chfnnyYO377e44dO17k7e/cm8ET74zn5T90pla1SqeXX39VbeYsX8/eg0cAyDh8jDT/UUMFubH+FXz2v9UAfLF8HY2vrI0xhpTd+09P0E3bc4BtO/cQV7l8UF/PmZYtX0mdOrWpVasmUVFRdOlyG1M/nx2y9oLF632iMFzcxjEx0ZQpU/r09bZtWupLNchc/kzOUzGbsFtQPTzLWpsNHDXGbLbWHgSw1h4zxnjy0po1bcS93e9k9Zp1LF+W+yH0/POvMmPmPC/iBKR69aoMH/YWERE+fD4fEydOZdr0OQU/sIiNHvVvWrS4gcqVK7Jl8zJeHDCQPn16UbJECWZMHwvAkqUr6NXr2aC1+fR7n7B8w/ccOHyUtk++ycO33UiWfzJol1YJDP5sIQcOH+OV0bmjlBE+H2P7/YFL46vwyB2teHjgh+RYS2REBH/t3iGgzsbtLRrw3NBJdHrmX8SWjuYf//dbAJI27mD49HFERfgwxvDXeztSwT8UFQrZ2dk89nhfpk8bQ4TPx4iRH7Nu3Xcha+9CeLFPBJML2/inqlatwsQJwwCIjIxg3LjJzJq9wNtQP3G+/WL/vgO8+eYAqlSpyJTJI1m1ei2dOnUv+Mk84MpnsuTN5DfD2hizBGhlrT1qjPFZa3P8y8sB8621gRxbZiNLxAcnbRHIOpkKgCuZT+UtUbKGx0kCd/JECgDHv/rI4ySBK9Usd9Kk9ovQObVfuLKNQZ8XRcHh/SK0hyv+xP67bgz6pJcKExYU6WsojIIqLy2stScATnVc/KKA+8//EBERESlSYT7ME2z5dl5OdVzOs3wPsCckiURERETyoWNARUREHBfuJ5ULNqdPUiciIiLFjyovIiIirtOcFxEREXGJLWadFw0biYiIiFNUeREREXGdKi8iIiIi4UudFxEREcfZnOBfAmGM+bMxZq0x5ltjzFhjTCljTG1jzBJjzCZjzMfGmBL++5b0397kX1/rQl+vOi8iIiKu8+CHGY0x8UBvIMFaezUQAfwOeA1401pbB9gP9PA/pAew37/8Tf/9Log6LyIiInKhIoFoY0wkEAPsBG4CJvrXjwQ6+6/f5r+Nf31rY8wF/X6SOi8iIiKOC8WwkTGmpzFm+RmXnme1aW0q8DqwndxOSwbwDXDAWpvlv1sKcOpXNeOBHf7HZvnvX+lCXq+ONhIREZFzWGuHAEPyWm+MqUBuNaU2cACYANxcFNnUeREREXGcRyepawNstdbuBjDGfAo0A8obYyL91ZUaQKr//qlATSDFP8xUDth7IQ1r2EhERMRxHh1ttB1oYoyJ8c9daQ2sA+YDd/rvcz8wxX/9M/9t/OvnWWsv6Bcl1XkRERGRQrPWLiF34u0KYA25fYohwNPAE8aYTeTOaRnmf8gwoJJ/+RPAMxfatrnATk9hFK/f6RYREYELOormQv1w441B/66tumBBkb6GwlDlRURERJxSJBN2I0vEF3ynMJF1MndekSuZXcsLbmc+Nv99j5MEJrrVQ4Cb21iZQ8e1vPBj5hIla3icJHAnT6QUeZv6VWkRERGRMKZDpUVERBxnc8J2ekpIqPMiIiLiOA0biYiIiIQxVV5EREQcZ23xGjZS5UVEREScosqLiIiI44rbnBd1XkRERBxX3I420rCRiIiIOEWVFxEREceF/mcKw4sqLyIiIuIUVV5EREQcV9zmvKjzIiIi4rji1nnRsJGIiIg4RZUXERERx2nCbpgrWbIkX3/1Od8s/4JVK+fR74UnvY5UoKFDBpKWsoqVSXO9jhKQGjXimDN7AqtXzWfVynk82quH15EKVJTbuN+oGbR66h1+++IH510/bck67hrwAXe++AH3/eMjNqTs+tltnszMos/Qz0h8fijdX/2Q1D0ZAKzZupMuL43IvQwYwbyk7352W/lp3+5G1n67kOR1i+jz1CMhbStYXMzs8/lYtnQWUyaN9DpKgVz5vBgy+HVSdqwkacWc08t+e8ctrEyay/Fj27nuums8TCeF5Vzn5cSJE7Rp14WGCW1pmNCO9u1u5PrG13kdK1+jRo3nlk73eB0jYFlZWTzVpz/XXNuKZs0TefjhB7jqqsu8jpWvotzGt95wNf959M4818dXLsewJ+5m4gu/p2fHGxjw4eyAnzt1TwY9Bo47Z/mkr9YQG1OKqQP+QPfWDRk06b8A1ImvzJhn72N83wd4p/edDBjzBVnZoTnVps/n4+1BL9MpsTv1rm1F166dw36/cDEzQO9HHyI5eaPXMQLiyufFqNET6JTY/axla9dtoEvXP/Dll0s8ShU8NscE/RLOnOu8ABw5chSAqKhIIqOisGFeL/ty0RL27T/gdYyApafvImnltwAcPnyE5OSNxMdV8zhV/opyGze8rCaxMaXyXF//0nhiS+euv6Z2HD/sP3R63bQla7nn76Pp8tIIBnw0i+ycwDoaC1ZvIvGGugC0ue4KliZvx1pLdIkoIiNy38YnM7MI5cdN40YN2Lx5G1u3biczM5Px46dwa2L7ELb487mYOT6+Oh07tGb48LFeRwmIK58XixYtYf9PPiOSkzfx3XdbvAkkP0uhOy/GmFGhCFIYPp+P5ctmszN1NXPnLmTpsiSvI/1iXXxxDepfezVLlmobX4hJX62m+dW1Adiycy+zlm9gRJ9ujO/7AD7jY/rSdQE9z64Dh6lWIRaAyAgfZaJLcODIMQDWbE3jjv7DuXPACPp2a3u6MxNscfHV2JGSdvp2SupO4sLwS+pMLmZ+Y2B/nnn2JXIC7NiGE31eeMdaE/RLOMt3wq4x5rOfLgJaGWPKA1hrbw1Rrnzl5OSQ0Kgd5crF8smEYdStewVr127wIsovWunSMYz/eChP/KUfhw4d9jqOc5Zt2M7k/63hg790A2Bp8ves357OPX8fDcCJzCwqlo0B4M/vTiJ1bwZZWTns3H+QLi+NAKDbTQ3p3LRevu3Uqx3Hp/0eZMvOvTw/YjrNrr6E6NC9LAmhWzq2YdeuPaxIWkPLFjd4HadQ9HnhLf0w49lqAOuA9wFLbuclARiY34OMMT2BngCDBw/++SnzkJFxkAX//Sp3Qp46L0EVGRnJhI+HMnbsJCZPnuF1HOd8l7KL/qNn8s6jd1K+TG5XwgKJTa6m9+0tzrn/mw/fDuTOeXlh5AyGPfm7s9ZfVL4M6fsPUrVCWbKyczh87CTlS5/dRbmkeiViSpVgU9oeEkLwmtJS06lZI+707Rrx1UlLSw9BS8HjWuamTRNI7NSODjffRKlSJYmNLcvIEW9z/wO9vY6WL31eSFErqL6cAHwDPAdkWGsXAMestf+11v43rwdZa4dYaxOstQk9e/YMXlqgcuWKlCuXWz4vVaoUbVq3YMOGzUFtQ3KP3lmfvIm3Bg3xOopzdu47yJODp/DS72/h4qoVTy9vfMWv+GLFBvYdPAJAxpFjpO3NCOg5W15zKVO/XgvAnBUbaHTFrzDGkLrnwOkJuml7M9iWvpe4SrFBfkW5li1fSZ06talVqyZRUVF06XIbUz8PfDKyF1zL/FzfV6l1SQJ1Lm/CPd3/xPz5X4V9xwX0eREOcqwJ+iWc5Vt5sdbmAG8aYyb4//2hoMeEWvXqVRk+7C0iInz4fD4mTpzKtOlzCn6ghz4c/Q4tW9xA5coV2bZlOf1ffJ0PRpx7REm4aNa0Efd2v5PVa9axfFnuB/3zz7/KjJnzPE6Wt6Lcxs+8P5Xl3+3gwOFjtHvmXR5ObHa6A3FXi/oMmfY/Dhw5xitjvwAg0udjzF/v49K4yvS67Tf88e0JWGuJjIjg2d+1Ia5SuQLbvL3ZNTz3wTQSnx9KbEwpXnsoEYCkTakMn/UpkRE+fMbw7N1tqVAmJiSvOzs7m8ce78v0aWOI8PkYMfJj1q0L7aHZP5eLmV3jyufF6FH/poX/M2LL5mW8OGAg+/cd4M03B1ClSkWmTB7JqtVr6dSpe8FPJp4zhTlSxxhzC9DMWvvXQrRhI0vEFzqYV7JOpgLgSmbX8oLbmY/Nf9/jJIGJbvUQ4OY2VubQcS0v/Ji5RMkaHicJ3MkTKUBID/47x4YrOwT9sNsrkmeEbfmlUFUUa+00YFqIsoiIiMgFCPfzsgSbk+d5ERERkeJLv20kIiLiuDA/V2vQqfIiIiIiTlHlRURExHHFbc6LOi8iIiKOC/fzsgSbho1ERETEKaq8iIiIOC7cf0gx2FR5EREREaeo8iIiIuI4HSotIiIiEsZUeREREXFccTvaSJ0XERERx2nCroiIiEgYU+VFRETEcZqwKyIiIhLGjA19d62Y9QdFREQo0kkoy2t0Dvp3bULK5LCdSKNhIxEREccVtwm7RdJ5iSwRXxTNBEXWyVTAncyu5YUfM0c5lDnTse18ahsfG9vP4ySBi767P6D9IpRc/rxwMbOEjiovIiIijitu53nRhF0RERFxiiovIiIijituR8ao8yIiIuI4DRuJiIiIhDFVXkRERBxX3A6VVuVFREREnKLKi4iIiONyvA5QxFR5EREREaeo8iIiIuI4W7Q/peQ5dV5EREQcl1PMTvSiYSMRERFxijovIiIijsvBBP0SCGNMeWPMRGNMsjFmvTHmBmNMRWPMF8aYjf5/K/jva4wxbxtjNhljVhtjrrvQ16vOi4iIiFyoQcBMa+2VwLXAeuAZYK619jJgrv82QAfgMv+lJ/DuhTaqzouIiIjjLCbol4IYY8oBLYBhANbak9baA8BtwEj/3UYCnf3XbwNG2VyLgfLGmOoX8nqd67yULFmSr7/6nG+Wf8GqlfPo98KTXkcqUI0accyZPYHVq+azauU8Hu3Vw+tI+XIt7ymP9upBUtJcVq6cR+9HH/I6ToGKajv3m7yEVv+YxG/fmXHe9Vt3H+S+97+g0YDxjPwqOShtnszKps+Er0gc9Dndh84mdf9hANak7KXLuzNPX+atTwlKe/kpVy6WceOGsGbNf1m9egFNrm8Y8jZ/jqFDBpKWsoqVSXO9jhKwTd8tJmnFHJYvm83ir6d7HadArn7G5ScnBJcA1AZ2Ax8YY5KMMe8bY0oDVa21O/33SQeq+q/HAzvOeHyKf1mhOXe00YkTJ2jTrgtHjhwlMjKShQsmMXPmfJYsXeF1tDxlZWXxVJ/+JK38ljJlSrN0yUzmzF3I+vUbvY52Xq7lBahb9woe7NGNpk1v4eTJTKZ9/hHTps9h8+ZtXkfLU1Ft51vr1+Z3jS+j76Ql511fLroEfTpcx/zk1EI/d+r+w7wweQnDft/6rOWTVmwhtlQJpj7WiZlrvmfQnFX8465m1LmoHGN6tiMywsfuQ8fo8u5MWlweR2RE6P6OevONF5k9az6/+11PoqKiiImJDllbwTBq1Hj+858P+OCDQV5HKZQ2be9i7979XscIiIufcV4wxvQkd3jnlCHW2iFn3I4ErgMetdYuMcYM4schIgCstdYYE/RjoZyrvAAcOXIUgKioSCKjorA2vI8RS0/fRdLKbwE4fPgIyckbiY+r5nGqvLmWF+DKKy9j2dIkjh07TnZ2Ngu/XEznzh28jpWvotrODWtdRGx0iTzXVyxTiqvjKxHpO7dMPG3VNu4ZMpsu785kwNRlZOcE9vfYgg2pJNavDUCbX9dk6ZYfsNYSXSLydEflZFY2JsSnpoiNLUvz5tcz/IOxAGRmZpKRcTC0jf5MXy5awr79B7yO8Yvm4mdcQUIxbGStHWKtTTjjMuQnzaYAKdbaU38ZTSS3M/PDqeEg/7+7/OtTgZpnPL6Gf1mhOdl58fl8LF82m52pq5k7dyFLlyV5HSlgF19cg/rXXs2SpW5kdiXv2rXJNGt+PRUrViA6uhQdbr6JmjXivI4VsHDczlt2ZzBr7XZG9GjD+IdvxmcM01d/H9Bjdx08RrXYGAAiI3yUKRXFgaMngdyhozvemc6d/5lJ306NQlp1qV37V+zZs5dh77/JsqWzGPzeP8O+8uIiay0zpo9lyeIZPNTjHq/jFEo4vvdcYa1NB3YYY67wL2oNrAM+A+73L7sfmOK//hlwn/+ooyZAxhnDS4VSqGEjY0xzoDHwrbV29oU0GAw5OTkkNGpHuXKxfDJhGHXrXsHatRu8ihOw0qVjGP/xUJ74Sz8OHTrsdZwCuZQ3OXkTr//zHWZMH8ORI0dZtWot2dlu/NpHuG7npVt+YH3aPu4ZkvtWP5GVTcXSJQH487gvSd1/hKzsHHZmHKXLuzMB6Nbkcjo3uCTf561XoxKfPtKRLbszeH7SEprVqU7JqIiQvIbIiAgaNKjH448/z9JlSbwxsD99+vTib3/7Z0jaK65atrqdtLR0qlSpxMwZ49iwYRNfLjr/MGU4Cdf33oXw8NPuUeAjY0wJYAvwe3ILI+ONMT2A74Eu/vtOBzoCm4Cj/vtekHw7L8aYpdbaxv7rfwAeASYB/Ywx11lrX83jcafHyQYPHnyh2QqUkXGQBf/9ivbtbgz7zktkZCQTPh7K2LGTmDz5/BMnw4lreQE+GDGOD0aMA2DAgGdITbmgDn2RCuftbIHE+rXp3ebac9a9+bvfAHnPebkoNpr0g0epWi6GrOwcDh/PpHzM2UNXl1QpR0yJSDbtyqBufMWQvIaU1J2kpOw8XZ395NNp9HmqV0jaKs7S0tIB2L17L1OmzKBRo/ph33kJ5/fehfCq82KtXQkknGdV658usLlzPB4JRrsF1WujzrjeE2hrre0PtAPyrA2eOU7Ws2fPvO52QSpXrki5crEAlCpVijatW7Bhw+agthEKQ4cMZH3yJt4a9NMhw/DkWl6AKlUqAVCzZhydO3dg7LhJHicqWDhv58a1q/LFuh3sO3wcgIyjJ0g7cCSgx7a8Ip6pK7cCMGfdDhrVrooxhtT9h8nyV8TSDhxh256DxJUvHZoXAPzww25SUtK4/PJLAbjppuasX/9dyNorjmJioilTpvTp623btAz7PyYhvN97UrCCho18/jPj+QBjrd0NYK09YozJCnm686hevSrDh71FRIQPn8/HxIlTmTZ9jhdRAtasaSPu7X4nq9esY/my3BL888+/yoyZ8zxOdn6u5T1l/MdDqVipAlmZWfTu/VzYT8wsqu38zMT/sXzbLg4cPUG7gVN4uNXVZGXnTnK/q1Ed9hw6RrchszlyIhNjDB8t3sCnj3Tk0ovK0euma/jj6AVYa4mM8PFsx4YBdTZub3AJz01aTOKgz4mNLsFrdzYFIGn7boYvWk+kz4fPGJ69JYEK/qGoUHn8z88zauS/KFEiii1bt/PQQ0+EtL2f68PR79CyxQ1UrlyRbVuW0//F109XFMNR1apVmDhhGACRkRGMGzeZWbMXeBuqAK5+xuWnuP0wo8nvSB1jzDZyq1GG3CpyM2vtTmNMGWCRtbZ+AG3YyBIXdBi3J7JO5k58diWza3nhx8xRDmXOdGw7n9rGx8b28zhJ4KLv7g9ovwgllz8vHMxcpL2JaVXvDvpht7f8MDZse0T5Vl6stbXyWJUD3B70NCIiIlJoOWHbzQiNCzpJnbX2KLA1yFlERERECuTcGXZFRETkbIH+CvQvhTovIiIijgvv88wHn5Nn2BUREZHiS5UXERERx7lxPvHgUeVFREREnKLKi4iIiONyQv0T7WFGnRcRERHHacKuiIiISBhT5UVERMRxmrArIiIiEsZUeREREXGcfttIREREnFLcfh5Aw0YiIiLiFFVeREREHKdDpUVERETCmLE25P214tYhFBERKdJJKKPiuwf9u/a+1A/DdiKNKi8iIiLilCKZ8xJZIr4omgmKrJOpgDuZXcsLylwUXMsLP2Y+tnCEt0EKIbrFA4A729nl/cLFzEWpuJ2kThN2RUREHFfc5mdo2EhEREScosqLiIiI44rbGXZVeRERERGnqPIiIiLiOE3YFREREacUt86Lho1ERETEKaq8iIiIOM5qwq6IiIhI+FLlRURExHHFbc6LOi8iIiKOK26dFw0biYiIiFNUeREREXGcfttIREREJIyp8iIiIuI4/baRAzZ9t5ikFXNYvmw2i7+e7nWcAg0dMpC0lFWsTJrrdZSAtW93I2u/XUjyukX0eeoRr+MExMXMPp+PZUtnMWXSSK+jFKhGjTjmzJ7A6lXzWbVyHo/26hGytvqNmEarJwbx235Dz7t+2uJvuetv73Pn397nvldHsWHHDz+7zZOZWfQZPJnEv75L91dGkLrnAABrtqbRpf+w05d5Kzb87LYK4tq+7NpnMri3jeVsTnZeANq0vYuERu1ockNHr6MUaNSo8dzS6R6vYwTM5/Px9qCX6ZTYnXrXtqJr185cddVlXsfKl4uZAXo/+hDJyRu9jhGQrKwsnurTn2uubUWz5ok8/PADIdvGtzatx38e65rn+vjK5Rn21D1M/NtD9LylGQNGzwj4uVP3HKDHPz86Z/mkRauIjSnF1Fcepnubxgz6ZAEAdeKqMKbv7xnfrwfvPNaVAR/OJCs7dMd2uLovu/SZ7Oo2zk9OCC7hzNnOi0u+XLSEffsPeB0jYI0bNWDz5m1s3bqdzMxMxo+fwq2J7b2OlS8XM8fHV6djh9YMHz7W6ygBSU/fRdLKbwE4fPgIyckbiY+rFpK2Gl7+K2JLl8pzff06NYgtHQ3ANZfE8cP+Q6fXTVv8Lfe8PIIu/YcxYPQMsnMC+xhesHIjiU2vBqBNwytZmrwNay3RJaOIjMj9qDyZmUWoq/Mu7suu+SVuY3VezmCMud4YE+u/Hm2M6W+MmWqMec0YU65oIp7LWsuM6WNZsngGD/Vwp6Lhirj4auxISTt9OyV1J3Eh+pIKFhczvzGwP888+xI5AX65hpOLL65B/WuvZsnSJK+jMGnRappffSkAW3buYday9Yx4+l7G9+uBz2eYvnhtQM+z68AhqlWIBSAywkeZ6JIcOHwMgDVbUrnjhaHc2f99+na/+XRnJhRc3Jdd+0x2cRvL2QqasDscuNZ/fRBwFHgNaA18ANwRumh5a9nqdtLS0qlSpRIzZ4xjw4ZNfLloiRdRRC7ILR3bsGvXHlYkraFlixu8jlMopUvHMP7joTzxl34cOnTY0yzLkr9n8qJVfPB0dwCWrt/G+u/TueflEQCcyMyiYtnSAPz5nU9I3XOArOxsdu47SJf+wwDo1qYRnZtdk2879S6J59MX/8CWnXt4fvjnNKt3KSWjdLzDKfpM9l5xO1S6oHefz1qb5b+eYK29zn99kTFmZV4PMsb0BHoCDB48+GeH/Km0tHQAdu/ey5QpM2jUqL7eKEGUlppOzRpxp2/XiK9+epuHK9cyN22aQGKndnS4+SZKlSpJbGxZRo54m/sf6O11tHxFRkYy4eOhjB07icmTA59nEgrfpeyi/6jpvNO7C+XLxABgLSQ2rUfvO2485/5vPvJbIHfOywsfTGPYU2dXCC4qX5b0/QepWjGWrOwcDh87Qfky0Wfd55LqlYkpWYJNqbupW6t6SF6Xa/syuPeZ7OI2lrMVVPv81hjze//1VcaYBABjzOVAZl4PstYOsdYmWGsTevbsGaSouWJioilTpvTp623btGTt2tDP/i9Oli1fSZ06talVqyZRUVF06XIbUz+f7XWsfLmW+bm+r1LrkgTqXN6Ee7r/ifnzvwr7jgvkHjm3PnkTbw0a4mmOnXszePI/n/DSg4lcXK3S6eWNr6rFF98ks+/gEQAyjhwjbW9GQM/Zsv5lTP1f7pyeOd8k0+iKizHGkLr7wOkJuml7M9iWvpe4SqEbNXdtX3bxM9m1bRyIHBP8SzgrqPLyEDDIGNMX2AN8bYzZAezwrytyVatWYeKE3HJvZGQE48ZNZtbsBV5ECdiHo9+hZYsbqFy5Itu2LKf/i6/zwYhxXsfKU3Z2No893pfp08YQ4fMxYuTHrFv3ndex8uViZtc0a9qIe7vfyeo161i+LPeD/vnnX2XGzHlBb+uZIZNZ/t12Dhw+Rrun/s3Dt/6GrOxsAO668TqGfP4VB44c55WPZgG5c1TG9P09l8ZVplfnFvzxzXFYa4mMiODZbu0C6mzc3vxanhs2lcS/vkts6Whe63kbAEmbdjB8xmIiI3z4fIZn72lPhbIxQX/Np7i2L7v4mezaNg6EezPnfh5jbcEjZf5Ju7XJ7eykWGsLc1IFG1ki/gLjFb2sk6kAuJLZtbygzEXBtbzwY+ZjC0d4G6QQols8ALiznV3eLxzMXKS1i1cv7h70aS/PfP9h2NZfAppxZq09CKwKcRYRERG5AMVtwq7O8yIiIiJO0bF+IiIijsspZrUXdV5EREQcV9wm7GrYSERERJyiyouIiIjjitegkSovIiIi4hhVXkRERBynOS8iIiIiYUyVFxEREceF+28RBZs6LyIiIo4rbud50bCRiIiIXDBjTIQxJskY87n/dm1jzBJjzCZjzMfGmBL+5SX9tzf519e60DbVeREREXGcDcGlEB4D1p9x+zXgTWttHWA/0MO/vAew37/8Tf/9Log6LyIiInJBjDE1gFuA9/23DXATMNF/l5FAZ//12/y38a9v7b9/oWnOi4iIiOM8PFT6LaAPUNZ/uxJwwFqb5b+dAsT7r8cDOwCstVnGmAz//fcUtlFVXkRERByXgw36xRjT0xiz/IxLzzPbNMZ0AnZZa78p6tdbJJWXrJOpRdFMULmW2bW8oMxFwbW8ANEtHvA6QqG5tp1dywtuZnadtXYIMCSfuzQDbjXGdARKAbHAIKC8MSbSX32pAZz6n5cK1ARSjDGRQDlg74VkU+VFRETEcV5M2LXWPmutrWGtrQX8Dphnrb0HmA/c6b/b/cAU//XP/Lfxr59nrb2gY7yLpPISWSK+4DuFiVO9e1cyn8ob5UhegEzHtjG4u1+4khfcznzy+xUeJwlMiYuvA9zcxi5mLsaeBsYZY14CkoBh/uXDgNHGmE3APnI7PBdEE3ZFREQc5/VvG1lrFwAL/Ne3AI3Pc5/jwF3BaE+dFxEREcfpDLsiIiIiYUyVFxEREccVr7qLKi8iIiLiGFVeREREHOf1hN2ips6LiIiI42wxGzjSsJGIiIg4RZUXERERxxW3YSNVXkRERMQpqryIiIg4TiepExEREQljqryIiIg4rnjVXdR5ERERcZ6GjURERETCmHOVl6FDBnJLxzbs2r2H+g1aex0nYJu+W8yhw4fJzs4hKyuLJjd09DpSvh7t1YMHe3TDGMPwYWN4+1/vex0pX9ovioaL27l9uxt5440XifD5GP7BWP7xz3dC0s7zA99j4eIkKpaPZdLQf56zft7/lvPvkePxGR8RET6efvg+rrv6yp/VZsbBw/zl5UGk/bCHuKqVeb3vY5QrWyYkbRXE5/OxZPEM0lLTue32+0PaVjC49t4riA6VDnOjRo3nlk73eB3jgrRpexcJjdqF/Zukbt0reLBHN5o2vYWGDdvSsWMbLr20ltex8qX9omi4tp19Ph9vD3qZTondqXdtK7p27cxVV10WkrZua9uSd195Js/1TRpczSfvvcbE917lxSf/j35vDA34uZetWsdz/3z3nOXDPp7C9Q2uZtqIN7m+wdUM+/izn93Wher96EMkJ28MeTvB5NJ7T87mXOfly0VL2Lf/gNcxftGuvPIyli1N4tix42RnZ7Pwy8V07tzB61j50n5RNFzbzo0bNWDz5m1s3bqdzMxMxo+fwq2J7UPSVsI1V1GubJk818dEl8IYA8Cx4yfwXwXgg/FT+V2v57jj//rwzqgJAbc5/+tvuK1tCwBua9uC+f9bXmBboRAfX52OHVozfPjY0DYkebIh+C+cOdd5cZW1lhnTx7Jk8Qwe6hHef7muXZtMs+bXU7FiBaKjS9Hh5puoWSPO61i/SC7tFy6Ki6/GjpS007dTUncSF1fNszxzFy0j8cEneeT5f/Dik/8HwP+Wr+b71HTG/uslJr77Kus2bmX56vUBPd/e/RlUqVQBgMoVy7N3f0a+bYXKGwP788yzL5GT487gxS/tvZcTgks4y3fOizGmNzDJWrujiPL8YrVsdTtpaelUqVKJmTPGsWHDJr5ctMTrWOeVnLyJ1//5DjOmj+HIkaOsWrWW7Oxw35Xd5NJ+IT9f6+aNaN28EctXr+ffIyfw/mvP8b8Vq/l6xWruevhZAI4eP8721HQSrrmKbo/25WRmFkePHyfj0GHu/GPusNSfH7qbZgnXnvXcxhjOLLGcr61QuKVjG3bt2sOKpDW0bHFDSNoIBb333FbQhN0BwDPGmM3AWGCCtXZ3QU9qjOkJ9AQYPHjwzw75S5CWlg7A7t17mTJlBo0a1Q/rN8oHI8bxwYhxAAwY8AypKTs9TvTL5Np+4Zq01PSzqoY14quf3uZeSrjmKlJe38X+jINYa+nR9Ta6dGpzzv3G/OslIHfOy+TZ/+Xlpx4+a32lCuXYvXc/VSpVYPfe/VQqH5tvW1VD8FqaNk0gsVM7Otx8E6VKlSQ2tiwjR7zN/Q/0DkFrwfNLe++F+zBPsBU0bLQFqEFuJ6YhsM4YM9MYc78xpmxeD7LWDrHWJlhrE3r27BnEuG6KiYmmTJnSp6+3bdOStWs3eJwqf1WqVAKgZs04OnfuwNhxkzxO9Mvj4n7hmmXLV1KnTm1q1apJVFQUXbrcxtTPZ3uSZXtqOtbmfsGs27iVzMxMyseWpVnDa5k8awFHjx0H4Ic9+84a/snPjU0aMuWLhQBM+WIhrW5omG9bofBc31epdUkCdS5vwj3d/8T8+V+FfcdF7z33FVR5sdbaHGA2MNsYEwV0AO4GXgeqhDjfOT4c/Q4tW9xA5coV2bZlOf1ffP10hSBcVa1ahYkThgEQGRnBuHGTmTV7gbehCjD+46FUrFSBrMwsevd+joyMg15Hypf2i6Lh2nbOzs7mscf7Mn3aGCJ8PkaM/Jh1674LSVt9XnmbZavXcyDjEK27PcIj995JVnYWAF06teWLRUuZOmchkRGRlCxZgn8+1xtjDE0TrmHLjlTueewFIHey7atPP0KlCuUKbLPH727lLy8NYtLMBVSvWpmBzz0GkGdbksvF915BitvAvjnVOz/vSmOSrLUN8lgXY609GkAbNrJE/IXmK3JZJ1MBcCXzqbxRjuQFyHRsG4O7+4UrecHtzCe/X+FxksCUuPg6wM1t7GDmIu0t3nvxHUEfNxr9/adh2+MtaNioa14rAuy4iIiIiARVvsNG1trQ1FdFREQkaIrXdF2d50VEREQc49xvG4mIiMjZ9KvSIiIiImFMlRcRERHHFbeT1KnzIiIi4rjidp4XDRuJiIiIU1R5ERERcZwm7IqIiIiEMVVeREREHKcJuyIiIuIUTdgVERERCWOqvIiIiDjO2uI1bKTKi4iIiDhFlRcRERHHFbdDpdV5ERERcVxxm7BrimCcrHh1B0VERMAUZWOJv+oU9O/aqds/L9LXUBiqvIiIiDhO53kJRSMl4ouimaDIOpkKuJPZtbzwY+YSJWt4nCRwJ0+kAO5s51PbOMqRvACZDu/LrmQ+lffY5294nCRw0Z2eANzclyV0VHkRERFxXHGbsKtDpUVERMQpqryIiIg4rridpE6dFxEREccVt0OlNWwkIiIiTlHlRURExHHF7VBpVV5ERETEKaq8iIiIOK64HSqtzouIiIjjitvRRho2EhEREaeo8iIiIuK44jZspMqLiIiIOEWVFxEREccVt0Ol1XkRERFxXI4m7IqIiIjkzxhT0xgz3xizzhiz1hjzmH95RWPMF8aYjf5/K/iXG2PM28aYTcaY1caY6y60becqLyVLlmTBvE8oUbIkkZERfPrpNPq/ONDrWPlyMTOAz+djyeIZpKWmc9vt93sd5xxDBr9Ox45t2L17Dw2uawPA3//el063tOHkyUy2bPmeh/7wBBkZBz1Oen4u7heP9f4Dv3/wbqy1fPttMg899AQnTpzwOla+Nn23mEOHD5OdnUNWVhZNbujodaR81agRx4jhg7ioamWstbz//kf869/Dgt5Ov3ELWLj+eyqWieaTp7qcs37rD/vp9/EC1qfsoVeHxtzf6tqf3ebJrGz6jpnH+pQ9lCtditfubUN8xbKs2b6LARMW5t7JWv7YPoGb6tX+2e3lp1y5WAYPfp26da/AWkvPPzzJ4iXfhLTNUPKo7pIFPGmtXWGMKQt8Y4z5AngAmGutfdUY8wzwDPA00AG4zH+5HnjX/2+hOVd5OXHiBG3adaFhQlsaJrSjfbsbub7xBXfeioSLmQF6P/oQyckbvY6Rp1GjJ9ApsftZy+bOXUj9Bq1pmNCWjRu38HSfXh6lK5hr+0VcXDUeeeRBmjTpSIMGrYmIiKBrl9u8jhWQNm3vIqFRu7DvuABkZWXxVJ/+XHNtK5o1T+Thhx/gqqsuC3o7tza6nP/8Ie/tUS6mFH06N+O+GwvfaUndd4ge//nsnOWTliQTG1OSqX+9m+4t6jHo88UA1KlWgTGP38H4J+/knZ4dGTBxIVnZof2pwTffeJHZs+ZTr15LGjZsy/ow/qwLV9bandbaFf7rh4D1QDxwGzDSf7eRQGf/9duAUTbXYqC8Mab6hbTtXOcF4MiRowBERUUSGRXlxMl5XMscH1+djh1aM3z4WK+j5GnRoiXs33/grGVz5iwkOzsbgCVLVhAff0HviyLj2n4RGRlJdHQpIiIiiImOJm1nuteRfnHS03eRtPJbAA4fPkJy8kbi46oFvZ2Gl8YRG1Mqz/UVy0Zz9a8uIjLi3K+Jad98xz1vfUqXgRMZMGEh2TmBdTQWfLuNxITLAWhzzSUs3ZiGtZboElGn2zmZmY3BXMArClxsbFmaN7+e4R/kfr5lZmaGbYU2UDnYoF8KwxhTC2gALAGqWmt3+lelA1X91+OBHWc8LMW/rNDy7bwYY0oYY+4zxrTx3+5mjPm3MeYRY0zUhTQYDD6fj+XLZrMzdTVz5y5k6bIkr6IEzLXMbwzszzPPvkROgB9K4eiBB7oya9Z8r2Pky6X9Ii0tnTfffI8tm5eyY3sSBw8eZM6chV7HKpC1lhnTx7Jk8Qwe6nGP13EK5eKLa1D/2qtZsjR89ostP+xn1srNjHj0NsY/eSc+n2H6ik0BPXbXwSNUK18GgMgIH2WiS3DgyHEA1nz/A3f8Yzx3vj6Bvnf+5rydpmCpXftX7Nmzl2Hvv8mypbMY/N4/iYmJDll7rjLG9DTGLD/j0jOP+5UBPgEet9ae1Qu0uX+RBf2vsoL2jg+AW4DHjDGjgbvI7VU1At4PdphA5eTkkNCoHRfXTqBRQgPq1r3CqygBcynzLR3bsGvXHlYkrfE6ygV75ulHycrKZszYT72Oki+X9ovy5cuRmNieyy5vwq8uvo6Y0jF063aH17EK1LLV7TS+/mY6JXbn4Ycf4DfNL2iIvciVLh3D+I+H8sRf+nHo0GGv45y2dGMq61P2cM9bk+gycCJLN6aSsjf3++rPH8yiy8CJPPr+dNbt2E2XgRPpMnAik5cmF/i89S6uyqd9uvDR43cwbG4SJzKzQvYaIiMiaNCgHoMHj6JR4/YcOXKUPmE8xByIUFRerLVDrLUJZ1yG/LRdfyHjE+Aja+2pD9wfTg0H+f/d5V+eCtQ84+E1/MsKraAJu/WstdcYYyL9DcRZa7ONMR8Cq/J6kL931hNg8ODBF5IrIBkZB1nw369o3+5G1q7dELJ2gsmFzE2bJpDYqR0dbr6JUqVKEhtblpEj3ub+B3p7HS0g9957Fx07tqH9zV29jhIwF/aL1q1/w7Zt29mzZx8AkyfP4IYmCYwZE94dxLS03KGt3bv3MmXKDBo1qs+Xi5Z4nCp/kZGRTPh4KGPHTmLy5BlexzmLtZCYcDm9bzm3E/jm79sDuXNeXhg3n2F/uvWs9RfFlib9wGGqli9DVnYOh4+dpHzps4euLqlagZiSUWxK30/dmlVC8hpSUneSkrLzdKXzk0+n0ecptzsvXgw5G2MMMAxYb61944xVnwH3A6/6/51yxvJexphx5E7UzThjeKlQCqq8+IwxJYCyQAxQzr+8JJDnsNGZvbWePc9bZbpglStXpFy5WABKlSpFm9Yt2LBhc1DbCDbXMj/X91VqXZJAncubcE/3PzF//lfOdFzatbuRvzz5MHf89vccO3bc6zj5cm2/2LE9lcbXX0d0dO6XzU2tmof1hG6AmJhoypQpffp62zYtw7ZzeKahQwayPnkTbw065w9dzzW+LJ4vVm9h36FjAGQcPU7avkMBPbZl3YuZuvw7AOas3kKjy+IwxpC69+DpCbpp+w6xbdcB4iqUCc0LAH74YTcpKWlcfvmlANx0U3PWr/8uZO39gjUD7gVuMsas9F86kttpaWuM2Qi08d8GmA5sATYBQ4E/XWjDBVVehgHJQATwHDDBGLMFaAKMu9BGf47q1asyfNhbRET48Pl8TJw4lWnT53gRJWAuZnbB6FH/pkWLG6hcuSJbNi/jxQED6dOnFyVLlGDG9NyJeEuWrqBXr2c9Tnp+ru0XS5cl8emn01i6dBZZWVmsWrmWoe9/5HWsfFWtWoWJE3IPM46MjGDcuMnMmr3A21AFaNa0Efd2v5PVa9axfNlsAJ5//lVmzJwX1HaeGT2H5Zt3cuDIcdq9+CEPt0843YG4q+mv2XPwKN3e+pQjx09ijOGjL9fwaZ8uXFqtAr1ubsQfh0zDWktkhI9n72hOXMWyBbZ5+/VX8tyY+SS+MpbYmJK8dm/uKQ6StqYzfN5KIiN8+Izh2TuaU6FMaOegPP7n5xk18l+UKBHFlq3beeihJ0LaXqh58dtG1tpFkOfs6tbnub8FHglG26agUpMxJs7faJoxpjy5vajt1tqlAbZhI0tc0GRiT2SdzB1+cyWza3nhx8wlStbwOEngTp5IAdzZzqe2cZQjeQEyHd6XXcl8Ku+xz98o4J7hI7pTbqfCwX05tIdM/UTjuJZB770sTftvkb6GwijwJHXW2rQzrh8AJoYykIiIiBSOfttIREREnBLu54gKNidPUiciIiLFlyovIiIijvNiwq6XVHkRERERp6jyIiIi4rjiNudFnRcRERHHadhIREREJIyp8iIiIuK44naeF1VeRERExCmqvIiIiDgup5hN2FXlRURERJyiyouIiIjjitucF3VeREREHKdhIxEREZEwpsqLiIiI44rbsJEpglMKF68tKiIiAqYoG7vyokZB/65N3rWsSF9DYajyIiIi4rjiNuelSDovkSXii6KZoMg6mQq4k9m1vPBj5iiHMmc6ljnT4f3CxcwlS9X0OElgThzfAbizH8OP+/KxOe95nCRw0W3+WORtFrdhI03YFREREado2EhERMRxxW3YSJUXERERcYoqLyIiIo4rbnNe1HkRERFxnLU5XkcoUho2EhEREaeo8iIiIuK4nGI2bKTKi4iIiDhFlRcRERHHFcFP/YQVVV5ERETEKaq8iIiIOK64zXlR50VERMRxGjYSERERCWOqvIiIiDhOv20kIiIiEsac67zUqBHHnNkTWL1qPqtWzuPRXj28jlSgoUMGkpayipVJc72OUig+n49lS2cxZdJIr6ME5NFePUhKmsvKlfPo/ehDXsc5r6FDBpKasoqkM/aFChXKM2P6WNatXcSM6WMpX76chwnz5uJ7D6B9uxtZ++1Cktctos9Tj3gd57wGD36dHduTWPHNnNPLrrnm1yz87xSWLpnJ/76aRkJCfe8CFqBcuVjGjRvCmjX/ZfXqBTS5vmFI2uk3ejatnn6P37406rzrt6bv477Xx9HosbcZOWd5UNo8mZlFn2HTSOw3nO7/GEvq3gwA1mxLp8srH/ovo5m3clNQ2rtQNgT/hTPnOi9ZWVk81ac/11zbimbNE3n44Qe46qrLvI6Vr1GjxnNLp3u8jlFovR99iOTkjV7HCEjdulfwYI9uNG16Cw0btqVjxzZcemktr2OdY+So8XT6yb7Qp88jzJu/iF/Xbc68+Yvo0yc8v2BdfO/5fD7eHvQynRK7U+/aVnTt2jksM48ePYHEW+89a9nfX3mOl19+k8bX38yLL77OK6/81aN0BXvzjReZPWs+9eq1pGHDtqwP0efGrU1+zX8euT3P9eVKl6LPXTdyX+vCd55S92bQ460J5yyf9PVaYmNKMrX/g3S/6ToGTV4EQJ24Sox5uhvj/9qddx65nQFj55CV7d3vC1lrg34JZ851XtLTd5G08lsADh8+QnLyRuLjqnmcKn9fLlrCvv0HvI5RKPHx1enYoTXDh4/1OkpArrzyMpYtTeLYseNkZ2ez8MvFdO7cwetY51h0nn0hMbE9o0fnfmiOHj2BW2+92YNkBXPxvde4UQM2b97G1q3byczMZPz4Kdya2N7rWOdYtGgJ+3+yX1hrKRtbFoDYcrHs3PmDB8kKFhtblubNr2f4B7mfFZmZmWRkHAxJWw0vq0Fs6VJ5rq9YNoarL65GZMS5X23Tlq7nnn+MocsrHzJgzByycwLraCxYvZnE638NQJsGl7F0w3astUSXiDrdzsnMbIwxF/CK5EI5PWH34otrUP/aq1myNMnrKL84bwzszzPPvkTZsmW8jhKQtWuTefHFp6lYsQLHjh2jw8038c03q7yOFZCqF1UmPX0XkNtBqHpRZY8TFcyV915cfDV2pKSdvp2SupPGjRp4mChwf/nL35j6+Ye8+mpffMbHja06ex3pvGrX/hV79uxl2Ptvcs01v2bFitX8+YkXOHr0mNfRTtuSvpdZ32xgxJNdiYqI4OVxc5m+LPl0pyQ/uw4cplqF3E5kZISPMtElOXDkOBXKRLNm6076fTibnfsO8fL9N5+301RUdJ6XnzDGXALcAdQEsoHvgDHW2tB0rQNUunQM4z8eyhN/6cehQ4e9jPKLc0vHNuzatYcVSWto2eIGr+MEJDl5E6//8x1mTB/DkSNHWbVqLdkelnB/jnAv1+q9VzR69ryXp57qz+TJM/jtbzsx+L1/0qFjN69jnSMyIoIGDerx+OPPs3RZEm8M7E+fPr3429/+6XW005Ym72D9jl3c81pudehEZhYVy8YA8Ochn5G65yBZ2dns3HeILq98CEC3Vg3ofEPdfJ+3Xu3qfPr8/WxJ38vzo2bRrG4tSkY5XRNwRr5b2RjTG+gELAQaAUnkdmIWG2P+ZK1dkMfjegI9AQYPHhzMvABERkYy4eOhjB07icmTZwT9+Yu7pk0TSOzUjg4330SpUiWJjS3LyBFvc/8Dvb2Olq8PRozjgxHjABgw4BlSU3Z6nCgwP+zaQ7VqF5Gevotq1S5i1+69XkfKk2vvvbTUdGrWiDt9u0Z8ddLS0j1MFLju3e/kiSf7AfDJJ5/z3rv/8DjR+aWk7iQlZSdLl+VW4T75dBp9nurlcaqzWSyJ1/+a3rc1P2fdmz1vBXLnvLwwejbDHr/rrPUXlS9D+v5DVK1QlqzsHA4fO0H5nwxdXVKtEjElS7ApbQ91L/ZmKDXc/+gJtoJqXH8AOlhrXwLaAHWttc8BNwNv5vUga+0Qa22CtTahZ8+ewUvrN3TIQNYnb+KtQUOC/twCz/V9lVqXJFDn8ibc0/1PzJ//Vdh3XACqVKkEQM2acXTu3IGx4yZ5nCgwn0+dzb335n5g3nvvXUydOsvjRHlz7b23bPlK6tSpTa1aNYmKiqJLl9uY+vlsr2MFZOfOH2jRogkArVo1Y9OmrR4nOr8ffthNSkoal19+KQA33dSc9eu/8zjV2Rpf8Su+SNrIvkNHAcg4cpy0vYENHrSsdwlTl6wDYE7SRhpdXhNjDKl7Mk5P0E3be5BtP+wjrpJ3RwrmWBv0SzgLpL4VSe5wUUmgDIC1drsxJiqUwfLSrGkj7u1+J6vXrGP5stwPoeeff5UZM+d5EScgH45+h5YtbqBy5Yps27Kc/i++frpCIMEz/uOhVKxUgazMLHr3fi5kkwZ/jtFn7AtbtyznxRdf5x//fIexY97j9w/czfbtKdzd7Y9exzwvF9972dnZPPZ4X6ZPG0OEz8eIkR+zbl14fbECjBr1b1r8pgmVK1dk86alDHhpIA//6WkGvv43IiMjOX78BH965BmvY+bp8T8/z6iR/6JEiSi2bN3OQw89EZJ2nhk+neUbd3Dg8HHaPTeUh2+5gazsbADu+s217Mk4Qrd/jOHI8ZMYY/hofhKf9r2PS6tXoldiU/74r0+x1hIZ4ePZrjcRVym2wDZvb3o1z42cSWK/4cSWLsVrD3YEIGlzKsNnLyMyIgKfz/Bs15uoUCY6JK9bzmXyKzUZYx4DegBLgN8Ar1lrPzDGVAE+sda2CKANG1kiPihhi0LWyVQAXMnsWl74MXOUQ5kzHcuc6fB+4WLmkqVqepwkMCeO7wDc2Y/hx3352Jz3PE4SuOg2fwQo0sOPKpSpE/RSyf7Dm8L2EKp8Ky/W2kHGmDnAVcBAa22yf/luIJCOi4iIiEhQFThsZK1dC6wtgiwiIiJyAYrbodLOnaROREREijcdkC4iIuK44naotDovIiIijgv3Q5uDTcNGIiIi4hRVXkRERBxnNWFXREREJHyp8iIiIuK44jbnRZ0XERERxxW3o400bCQiIiJOUeVFRETEcZqwKyIiIhLGVHkRERFxnOa8iIiIiFOstUG/BMIYc7MxZoMxZpMx5pkQv8zT1HkRERGRQjPGRADvAB2AXwN3G2N+XRRtq/MiIiLiOBuCSwAaA5ustVustSeBccBtQXpJ+TJFME5WvAbiREREwBRlY5El4oP+XZt1MjXf12CMuRO42Vr7kP/2vcD11tpewc7yU0UxYTdk/wONMT2ttUNC9fzB5lpecC+za3lBmYuCa3lBmYuCa3nzU1BH40IYY3oCPc9YNCRctpfrw0Y9C75LWHEtL7iX2bW8oMxFwbW8oMxFwbW8RcpaO8Ram3DG5acdl1Sg5hm3a/iXhZzrnRcRERHxxjLgMmNMbWNMCeB3wGdF0bDO8yIiIiKFZq3NMsb0AmYBEcBwa+3aomjb9c5LWIy9FYJrecG9zK7lBWUuCq7lBWUuCq7lDTvW2unA9KJutyiONhIREREJGs15EREREac42Xnx6nTEF8oYM9wYs8sY863XWQJhjKlpjJlvjFlnjFlrjHnM60wFMcaUMsYsNcas8mfu73WmQBhjIowxScaYz73OEghjzDZjzBpjzEpjzHKv8wTCGFPeGDPRGJNsjFlvjLnB60z5McZc4d++py4HjTGPe50rP8aYP/vfd98aY8YaY0p5nakgxpjH/HnXhvv2lXM5N2zkPx3xd0BbIIXc2c53W2vXeRosH8aYFsBhYJS19mqv8xTEGFMdqG6tXWGMKQt8A3QO821sgNLW2sPGmChgEfCYtXaxx9HyZYx5AkgAYq21nbzOUxBjzDYgwVq7x+ssgTLGjAS+tNa+7z8iIsZae8DjWAHxf96lknvir++9znM+xph4ct9vv7bWHjPGjAemW2tHeJssb8aYq8k9G2xj4CQwE/ijtXaTp8EkYC5WXjw7HfGFstYuBPZ5nSNQ1tqd1toV/uuHgPVAvLep8mdzHfbfjPJfwrpnboypAdwCvO91ll8qY0w5oAUwDMBae9KVjotfa2BzuHZczhAJRBtjIoEYIM3jPAW5ClhirT1qrc0C/gvc4XEmKQQXOy/xwI4zbqcQ5l+sLjPG1AIaAEs8jlIg/xDMSmAX8IW1NtwzvwX0AXI8zlEYFphtjPnGf/bNcFcb2A184B+ee98YU9rrUIXwO2Cs1yHyY61NBV4HtgM7gQxr7WxvUxXoW+A3xphKxpgYoCNnn2xNwpyLnRcpIsaYMsAnwOPW2oNe5ymItTbbWluf3LM8NvaXhsOSMaYTsMta+43XWQqpubX2OnJ/RfYR/5BoOIsErgPetdY2AI4AYT9PDsA/xHUrMMHrLPkxxlQgt/pdG4gDShtjunubKn/W2vXAa8BscoeMVgLZXmaSwnGx8+LZ6YiLE/+8kU+Aj6y1n3qdpzD8wwLzgZs9jpKfZsCt/jkk44CbjDEfehupYP6/srHW7gImkTuMG85SgJQzqnATye3MuKADsMJa+4PXQQrQBthqrd1trc0EPgWaepypQNbaYdbahtbaFsB+cudSiiNc7Lx4djri4sI/+XUYsN5a+4bXeQJhjKlijCnvvx5N7oTuZE9D5cNa+6y1toa1tha5+/A8a21Y/7VqjCntn8CNf+ilHbnl97BlrU0HdhhjrvAvag2E7cTzn7ibMB8y8tsONDHGxPg/O1qTO08urBljLvL/+yty57uM8TaRFIZzZ9j18nTEF8oYMxa4EahsjEkB+llrh3mbKl/NgHuBNf45JAB/9Z9JMVxVB0b6j87wAeOttU4cfuyQqsCk3O8nIoEx1tqZ3kYKyKPAR/4/drYAv/c4T4H8ncO2wP95naUg1tolxpiJwAogC0jCjTPXfmKMqQRkAo84NpG72HPuUGkREREp3lwcNhIREZFiTJ0XERERcYo6LyIiIuIUdV5ERETEKeq8iIiIiFPUeRERERGnqPMiIiIiTlHnRURERJzy/xcEvFl46IhFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(conf_matrix, annot=True, linecolor=\"white\", linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a0e5bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of model is 0.973800003528595 and loss is 0.10720863938331604\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "test_results = best_model.evaluate(X_test_tr, y_test, verbose=0)\n",
    "\n",
    "print(\"Testing accuracy of model is {} and loss is {}\".format(test_results[1], test_results[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
